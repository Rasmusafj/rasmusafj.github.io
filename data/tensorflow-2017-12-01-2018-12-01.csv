author,comment,timestamp
gokstudio,"Maybe indent the line      

  `generator_variables = encoder.variables + decoder.variables`

by one more level to lie inside the with tf.GradientTape block?",1543635351.0
crazyhh,"in the Reference ([https://www.tensorflow.org/api\_docs/python/tf/GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape)) the watch method is used.

Maybe that solves your problem.

    with tf.GradientTape(persistent=True) as g:
        g.watch(x)   
        y = x * x

&#x200B;",1543658442.0
zmjjmz,"I've had a lot of TF issues (primarily around the integration btw Keras and Estimators) get blackholed by being assigned to fchollet... I've been getting a lot of 'nagging assignee' emails primarily.

So, good luck!",1543583755.0
not_from_this_world,"I think this is opencv related, not tensorflow. You should post on another sub.",1543506136.0
mikaelhg,"OpenCV uses libav / ffmpeg for its video functionality, so you might want to look at the actual RTSP code in OpenCV for how they pass the username and password, and compare it to libav's documentation.",1543523619.0
bigbossjonbonraki,it says 10 dollars at the cart.,1543451804.0
honeybooboo1989,"https://www.tensorflow.org/api_docs/python/tf/metrics/accuracy
it returns one tensor and one operation.
accuracy: A Tensor representing the accuracy, the value of total divided by count.
update_op: An operation that increments the total and count variables appropriately and whose value matches accuracy.

This will help you i guess: https://stackoverflow.com/a/46414395/1757224",1543875595.0
reallifepixel,"Good work, dude. Keep it up.",1543202230.0
fkxfkx,"You weren’t.
What are you, 12?",1543187511.0
_guru007,"How is it gonna make a difference,please   enlighten Me !",1543219003.0
serifmasterrace,"to clarify, iterator.get_next() returns a tensor representing a batch of data right? And we can define our model on top of that tensor?",1543160572.0
weirdlyawesome,Well written! Clear and concise.,1543157335.0
Omodaka9375,Nice one.,1543158783.0
piffcty,"!remindme 1  Day
",1543165403.0
justAHairyMeatBag,"Thank you for this. Is there a way to read files from a csv in batches, pre-process it a little bit, and feed it into the pipeline using the Dataset api? I'm currently trying to read a text file from a csv, but my dataset has way too many labels to fit into memory all at once, so reading from slices is not an option.",1543903476.0
SArham,"The model/object-detection module has a script which you could use if you label your images in VOC format, XML files created via labelimg or labelme. It's a good place to start.",1543100009.0
PDNiaWdkaWNr,"so I am actually using the MateBook X Pro i7 ,16GB RAM, 512GB SSD and MX150 model, during booting Windows 10 and Ubuntu 18.04. I don't really enjoy doing dev work on Windows so I can only answer your question with my experience in Ubuntu.

1. Yes, right now I have CUDA 9.0
2. Yes, everything works as expected just like any Ubuntu machine.
3. Yes, it is, I wrote a Gist [https://gist.github.com/bryanlimy/baaac3f603001b20a705182d40c42b5e](https://gist.github.com/bryanlimy/baaac3f603001b20a705182d40c42b5e), to install Nvidia driver, CUDA and cuDNN where X is running on the iGPU so that 100% of the dGPU can be used for CUDA. I have never tried eGPU tho, as I have a dedicated system at home with GTX1080Ti to train all my large model. I only use the laptop for quick testing or small models.
4. This I am not sure.
5. Running X on iGPU to free up the vram on the dGPU makes a big difference since the MX150 only has 2GB of vram. I would use undervolt [https://github.com/georgewhewell/undervolt](https://github.com/georgewhewell/undervolt) to undervolt the CPU to prevent overheating.

I actually quite like my current setup, laptop with MX150 for quick and small model testing, ssh to my desktop at home for larger models. Let me know if you have any questions related to the laptop.",1542999364.0
rdsworkz,"I ended up going with a single RTX 2070 based on information from the following article:
http://timdettmers.com/2018/11/05/which-gpu-for-deep-learning/

Still waiting for the card to arrive...",1542901192.0
xib1115,"Depends how big your problems are but I would definitely suggest you consider the increased memory with the two card. However, you'll still have to deal with using two cards (I've never done it but I've heard it can get kinda complicated). As for the memory though, I can say my 11gb 1080ti will get capped out doing any Meta-RL stuff so I actually had to bump my systems memory to compensate. So depends how memory intensive your work is. ",1542925440.0
tinkykunk,The gradient calculation requires far more memory than the forward pass. Try reducing your batch size.,1542894275.0
OkinawanSnorkel,I'd also be really interested in this! ,1542866168.0
lab_fly,"If you visualize embeddings on tensorboard, it has the ability to run tsne on your embeddings.  But I have no idea how that TSNE is implemented, but it shouldn't take too much digging around to find it.

You can see it here: http://projector.tensorflow.org/",1542883900.0
Resolt,"I'm very new to TF and your code examples are actually quite useful to me.
But when it comes to utilization, I would assume that the keras approach has some pre built optimizations, as some of the wrappers access pre compiled elements, where as your ""by hand"" graph might not be as properly optimized.

My best guess anyway. ",1542850111.0
doktorneergaard,"AFAIK, the feed\_dict method of feeding data in TF is supposed to be very inefficient. However, my experience with TF and Keras has told me that Keras is slower in general than TF. I can't really speak for your code snippet, but are you sure you've implemented it correctly? Have you tried with the Estimator API?",1542864261.0
Metabyte2,"2.0 is supposed to be out later this year or early next year, i can't remember their blog posts mentioning anything about 3.7 support, knowing their seemingly arbitrary decision-making so far who knows. Whats the issue with just installing tf in a virtual env with 3.6?

Personally im not even fuckin with tensorflow till 2.0 because theyre totally changing their API paradigm, if you can solve your problems with other ml tools maybe go with that",1542830491.0
Resolt,"1. install anaconda
2. create env with python==3.6
3. activate environment
4. pip install Tensorflow inside invironment (or from whl from own compile)
5. feel fulfilled and do ML from inside environment
6. good job",1542848056.0
OkinawanSnorkel,Bayesian Statistics for Hackers?  Online free textbook on MCMC methods that's clear and approachable (as far as MCMC methods go). Assumes prior experience with probability though. Also may not be fully updated to reflect most recent changes to TF1.12. ,1542732990.0
jcasman,"Thanks for this information showing TensorFlow use in 360 cameras. I was at a recent RICOH THETA microconference that is mentioned in this article, and I got to see 3 different teams that used TensorFlow in their projects - (1) Recognizing cars and people to better control traffic light switching, (2) Recognizing fallen humans (older people) to help with monitoring seniors in their homes, and (3) Recognizing airplanes from their shapes (underside) to identify airplane types for aviation enthusiasts. Really cool tech!",1542662097.0
CumbrianMan,"Pointless. If you’r learning and can’t justify a GPU you can hire one in the cloud for very little, pretty much all serious work is done on GPU (or TPU) clusters.",1542662183.0
Metabyte2,"Are you changing between IDE's? Sometimes I open scripts with notepad++ and have to be careful to use 4 spaces or when I go back to pycharm the automatic 4 spaces setting will cause tab errors.

Also post your code, this seems like a python problem not a tf problem",1542599027.0
LukeArrigoni,Looks like there is a space before that line. Python doesn’t like spaces and tabs intermingled. Pick one but not both. Delete that space or make it a tab indent.,1542601076.0
_spicyramen,"Tensorflow 2.0 will be released next spring. It is a Keras first/Eager first version. I would suggest you to follow online official materials as for now books may get obsolete very fast once TF is released, it will be a world TF-Keras vs Pytorch. ",1542525563.0
Soy-Michu,As I remember in this repo you have the updated code: [Cookbook](https://github.com/nfmcclure/tensorflow_cookbook) ,1542532806.0
doktorneergaard,Are you sure your are saving summaries?,1542514320.0
jthat92,"You could try to debug by printing out the loss with each training step. If that works, there must be something wrong with how you save the summaries.",1542529302.0
gokstudio,"Is your GPU usage (use `nvidia-smi` ) / CPU usage (if using non GPU TF) increasing? If yes, then TF is doing \* something \*. Now, what's it doing exactly depends on your code and without it we can't help you with that.

About tensorboard not showing losses,

1. Refresh tensorboard (circle with arrow) on top right to make it load the latest values
2. Check if you're actually saving summaries, a. You're using `FileWriter` b. You're having `tf.summary.merge_all()` somewhere in your code c. and you actually call this somewhere :)

Aside, you can always print some kind of progress bar like `tqdm` or event just a `print` statement to check if your code is not stuck somewhere",1542572380.0
Grantmca,"Star by getting the bare bone basics of Python and from there get straight into Tensorflow, it is fairly user friendly but the thensorflow code is harder to figure out then basic Python but that being said you don’t have to know much to train your first model, I found a good tutorial that helped me starting out, https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html this is a tutorial that helped me, I highly recommend Linux if you are good with a Unix command line or even if your not. Any more questions feel free to message me",1542487630.0
redditpentester,"Research, read, and work hard.",1542487294.0
8756314039380142,"For learning Python, I would recommend [Codecademy](https://www.codecademy.com/) (it's free). As for TensorFlow, there are plenty of great tutorials around, you may want to start with the examples on the TensorFlow website: [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/). Good luck!",1542489236.0
vinowan,conda install tensorflow-gpu,1542463848.0
BaRe_Boren,"We need more information about what's wrong.
Are you compiling tensorflow from source? I think you need to do that if you want to use CUDA 9.",1542464818.0
Anishgoyal24,Also would like to know if Tensorflow would work on the Radeon Pro 555X on macbook pro.,1542444971.0
mrmnder,"If you're running linux, docker is effectively running on your computer. There's no real performance penalty, and it greatly simplifies things.",1542472162.0
Demios,To my knowledge no. AMD pushes OpenCL which I don't recall Tensorflow supporting. Methods of making it work last I checked were a giant headache.,1542482414.0
gokstudio,this might be useful [https://github.com/plaidml/plaidml](https://github.com/plaidml/plaidml) but YMMV,1542572634.0
NoodledLily,Lol might be easier to screen shot google's buildings and then train on that haha they've already done it,1542437876.0
redditpentester,"Where did you even get satellite images this shitty?

And no, this isn't really a machine learning problem. Get some images from google maps API, filter them and use openCV to identify marks on the top of buildings, count the outlines you make that are within a certain size threshold. Done.",1542481590.0
Supermaxman1,"Yes, the best way to do this would be to have both models within the same graph and session. Just take the output tensor for the first model and use it as the input tensor for the second model. It will be much more efficient, just make sure to wrap the input with a stop_gradients call to make sure your training for the second model does not produce gradients for the first model’s variables. You could go further and make sure your gradients are only computed on your second model’s variables, but the stop_gradients should be enough.

If you are concerned with variable namespaces you can always load the models within a variable_scope to make sure they don’t overlap between models.

One very similar common situation is when training Generative Adversarial Networks. GANs involve training two separate models on each other’s outputs. You should be able to find tons of examples on GitHub searching for TensorFlow GAN implementations if you need help with the code.",1542434668.0
MADscientist314159,Dont you need cuDNN also?,1542280377.0
Undecided_fellow,"you're missing a sudo on this line
>     docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi        ",1542308097.0
MogwaiAllOnYourFace,"I'm not sure of this text Gen package you are using, but I would suggest it is looking at each line of your text file as one input (ie each line is a one or two word sentence), it is then generating new names based on these sentences. If I am understanding correctly,  you would need character level generation to generate new words",1542231639.0
400_Bad_Request,"Hard to know what's the issue without the code, there could be a bug that's causing this",1542202283.0
HarambeTownley,Please provide your code,1542203805.0
maria_jensen,"If I understand you correct your output layer has Sigmoid as activation function and creates an output value of 0.9995 ? 
Sigmoid creates a confidence level between 0 and 1 and is therefore used for binary problems. 

Let us say you want to predict whether something is bad (y=0) or good (y=1). An output variable of 0.9995 then says that your model predicts that the output is good (closest to 1).

When you use Softmax activation function for your output layer it is because you have several neurons in that layer, e.g. predicting wheter a picture is a t-shirt, a sweatshirt, a bag or a shoe. Softmax provides a probability for the given picture is either one. Thererore, the sum of all probabilities of the output layer equals 1.

Or did I misunderstand your question?",1542211141.0
_spicyramen,"I would start from wav to numpy arrays then to tensors
>>> from scipy.io.wavfile import read >>> a = read(""adios.wav"") >>> numpy.array(a[1],dtype=float) array([ 128., 128., 128., ..., 128., 128., 128.])

typically it would be bytes which are then ints... here we just convert it to float type

you can read about read here http://www.scipy.org/doc/api_docs/SciPy.io.wavfile.html

",1542161893.0
dominik_schmidt,You're right.,1542160660.0
HarambeTownley,Its all great tbh. Eager will be default but I'll still use sessions if my model doesn't require eager. A lot of my code will be depreciated but they'll also provide tools to update all your code.,1542105434.0
DavidCittadini,It is a good time to consider Swift for TensorFlow..,1542130471.0
Im_int,"TF 1.6 was not intuitive at all. I get it, it's a highly specialized library, etc, but it's really not cool that after taking a course and doing exercises with tf, absolutely no knowledge was retained just one month later. In my opinion it's an indicator that something isn't quite right yet. If the next iteration makes tf more intuitive, I think it will be a step in the right direction.",1542140645.0
OkinawanSnorkel,Do you think it's over fitting? That's a pretty high training accuracy. ,1542080966.0
Supermaxman1,"How many samples is “many”? The decision to use a neural network should largely be a function of how much data you have along with how many features and how “difficult” or non-linear you expect the data and label mapping to be. Make sure you have benchmarks with something like logistic regression or decision trees so you can show the complicated process of training a neural network is necessary for improved performance. 

If you have already decided a neural network is necessary, then the next step is transforming the input data into a more efficient format, such as min-max scaling or z-score scaling. I would recommend you use something like pyplot to plot a histogram for each feature so you can better transform your dataset for your model. You may find some of the features are continuous while others may be distinct categories, which you can model better with one-hot encoding. I would also determine the label distribution and decide on the loss function based on how balanced or imbalanced the labels are. 

After that you can start architecture search by training a model with some architecture and hyper-parameters and adjusting to build a better model. Make sure you pick a strong train/val/test dataset split, or if you can afford do something like 5-fold cross validation.

Now the difficult process of architecture search begins, and you can start to discover the best architecture and hyper-parameters for your dataset. Make sure to do significant logging with something like tensorboard so you can compare experiments and make informed architecture choices. Also make sure you are using the same random seed between experiments, or if you can afford to try multiple seeds for each experiment. 

These are the steps I typically follow for new problems like this. Let me know if you have any questions!",1542061894.0
sleepy3005,"So far, I'm using this link [https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/) ",1542096581.0
pruby,"(a) realise people probably don't care about your model.
(b) make life a little harder just in case someone cares a little.
(c) develop a source of real value that doesn't get distributed (e.g. your base training data). Nobody wants a model they can't update.",1542059137.0
nckl,maybe look at https://github.com/mortendahl/tf-encrypted,1541995598.0
rumborak,"I'm not entirely certain what the actual issue is. On the one hand it sounds like a licensing problem; the best solution to that I would say is to run a license server somewhere, and while the actual data processing can happen on their servers, your recognition engine gets its license from that license server (and you charge accordingly).

The part that confuses me is the obfuscation/binary part. Would that be an attempt to stop reverse engineering your models on their side?",1541995691.0
sharvil,"Honestly, it sounds like you need to consult your legal counsel. Abiding by laws and regulations is hard not just because of regional differences, but also because privacy is a hot-button topic right now, public perceptions are changing, and there isn't always a bright line dividing what's okay from what's not. The risk you/your company take can be best explained by a lawyer.

On the technical front, I'm not sure what you're trying to accomplish. Is the concern that a trained model will store weights that may reveal personally identifiable information? If so, consult a lawyer so your business can make an informed decision about what actions you can take to mitigate the risk to a level acceptable enough for the business.",1542016652.0
bridge220,"The inception v3 feature vector module is intended to take an image and convert it to a vector of features to be used in another module. This vector is not intended to be used directly as an output and, as such, the actual values in it don't really correspond to a useful classification. You'll want to feed the feature vector into a small dense network with the desired number of classes and train the dense network on a labeled set of images.",1541956579.0
ManHuman,"Let's see what I remember and heard.

Keras if you want an ease of implementation of use and work. Easier to learn simply due to the syntax. Not as complex in language as Tensorflow. I still remember the pain it took me to learn how to carefully tread upon the tensorflow.

Tensorflow if you want to be in a complete control of your models and want to have a deeper understanding what it does. Compared to Keras, you would know what's happening within your model, but language is more complex and harder to learn.

That's all I can contribute at this point. Both languages are great. Have not used keras, but from what I have seen, it has a much simpler implementation than TF.",1541954759.0
pocketMAD,Keras is much easier to use and learn.,1541963177.0
gionnelles,"What are you trying to do with it? Are you a researcher looking to implement new algorithms or duplicate a newly published paper? Use TF. Are you looking to implement a concrete use case leveraging tested models, pretrained weights, or standard network types? Keras is probably great for you.",1541970795.0
ArgoloF,Different purposes. ,1541990701.0
ScotchMonk,"Learn Keras first, then TensorFlow.

[https://www.pyimagesearch.com/2018/10/08/keras-vs-tensorflow-which-one-is-better-and-which-one-should-i-learn/](https://www.pyimagesearch.com/2018/10/08/keras-vs-tensorflow-which-one-is-better-and-which-one-should-i-learn/)",1542023610.0
bartturner,"A lot more examples in TF.   One of the big reasons chose.   Plus seems where the momentum is at.

I also like to fully understand what is going on which you have more of with TF versus Keras.

Also TF skills more marketable.",1542031853.0
doktorneergaard,"An inportant issue is also speed. I find that Keras itself is much slower on an equivalent model than pure Tensorflow with about 12M training examples and a reasonably small model with ~430K parameters.

Furthermore, I found that for my specific example, the input pipeline with tf.data in TF was just so much faster than the Sequence generator in Keras.

However, I do find that Keras is a much better tool for doing research, as it is much much quicker to set up and train a model. 

I don’t necessarily agree with the other posters here that TF gives you better control of the details in a model—the functional API and Model subclassing in Keras is very powerful and logical.",1542518607.0
newaccountbc-ofmygf,"This is hard to read. Get rid of the commented lines and throw it on github if you want better answers.

My first instinct is to ask you about your data. If the majority of your data points are positive values then you're model will learn a trivial solution.",1541955914.0
ptrkhh,"As someone completely new, is there a noticeable performance and/or stability improvement? I got ""GPU sync error"" every now and then, that I haven't really figured out why it happened",1542793688.0
HarambeTownley,Sentdex of original deep learning series on YouTube.,1541862649.0
maccam912,"If I recall correctly TFP has some layers? DenseFlipout is one I think? Anyway just add this on to the end of a keras model as the last layer instead of a normal keras dense layer. You'll still get point estimates, but the same input put through a couple times in a row will give you different predictions and if you do that enough you'll see the distribution associated with that layer. There are only a few TFP layers though.

Another thing I can't find the source for on my phone, but a model with dropout is mathematically equivalent to a model with probabilistic weights. Keep the dropout in for inference and the distribution of point estimates you end up with will be the same as the dense flipout layer. ",1541823882.0
HarambeTownley,I don't know why you'd need that but afaik neural network classifiers outputs a probability distribution. To do that use a softmax layer at the end.,1541788818.0
_spicyramen,TF doesn't support Python 3.7. Try with a virtual environment in Python 3.6,1541778375.0
TheOneRavenous,"What type of CPU do you have?
What version of Tensorflow? (CPU only or GPU)?
What install flow are you using (build from source or pip or virtualenv)? Did you try the Tensorflow install section of Tensorflow website?",1541781756.0
Folkwang,"i7 4770k
GTX 770
Tensorflow 1.12
installed via pip, with consa virtualenv",1541781918.0
LukeArrigoni,What error are you getting?,1541786537.0
Nike_Zoldyck,Try this [https://medium.com/@snk.nitin/using-tensorflow-and-pytorch-in-pycharm-from-wsl-ec7ff7d2edef](https://medium.com/@snk.nitin/using-tensorflow-and-pytorch-in-pycharm-from-wsl-ec7ff7d2edef),1541799578.0
Folkwang,will do,1541864881.0
late_to_ml,"If you are using Keras, its available as part of the [applications](https://keras.io/applications/#vgg19)

Tensorflow implementation (unofficial)

[https://github.com/taehoonlee/tensornets](https://github.com/taehoonlee/tensornets)

[https://github.com/machrisaa/tensorflow-vgg](https://github.com/machrisaa/tensorflow-vgg)

&#x200B;",1541737561.0
TrPhantom8,I've read that it may be out by spring 2019 and that a preview of some features may be available in December ,1541708701.0
BatmantoshReturns,"side question, how much will it eat into pytorches users? Some are saying because of eager execution, there's less reasons to use pytorch",1541713588.0
_spicyramen,"My understanding is that eager is already in TF 1.10+, TF. 2.0 will be enabled by default",1541786310.0
MachinaDoctrina,"Maybe I'm asking the wrong question, I'm having a hard time finding information on how to apply custom loss functions in general. Or even how to interact with a Tensor within the Tensorflow ops (would I need to extend the Tensorflow API to do this? if so how do I start?)",1541687065.0
Cokdewer,In case you want to use custom loss better write a loss function (passing the placeholders mainly) and take the output in your cost before executing the graph,1541688440.0
HarambeTownley,Good job. Though the inference was very slow on mobile. Share the code!,1541686594.0
HarambeTownley,"If the pretrain model have only provided the frozen graph, you cannot change it.",1541678464.0
iamiamwhoami,"You have the right idea. I did something similar with Keras. I had a bunch of videos stored in mp4 format and I wanted to train a background subtracted on the data. To do this I had to randomly sample frames from the videos. ffmpeg is very efficient at decompressing video data sequentially but is very slow at doing it in random order. The solution was to have a queue of decompressed images that were populated my multiple python processes.  I used Keras’s fit_generator function and wrote a generator to do the decompression using moviepy. 

Sounds like you’re using pure tensorflow so don’t think I can be of more help but you’re on the right track. ",1541642316.0
TheOneRavenous,"AdaNet is an architecture as well as new solutions to a specific problem e.g. New math formulas that solve a problem. 

Tensorflow is an API for creating Neural Networks. You can add your own code to create new functions/methods. 

So you can add new math functions to Tensorflow to get the correct AdaNet architecture. ",1541600944.0
TsankoNL,"I am new to Tensorflow. Recently I wanted to extract feature vectors from faster rcnn resnet so I had to find the variable responsible for that. I tried to go over all variables but i did not know what to look for. Using tensorboard really helped me, it gives you an idea of what is going on for each layer. So maybe you can try that if you haven’t.",1541542643.0
Supermaxman1,Could you clarify your question further? Is the class you are interested in one of the classes the original model was trained to classify? Or is this a new object you are trying to identify? ,1541449343.0
aziz_22,"Nan values because probably you're having exploding gradients.

try to see how you initialize your weights and apply gradients\_clipping also",1541413223.0
Daniel_3_,"I think your cross entropy function is not correct. 

y\_true \* tf.log(y\_pred) + (tf.subtract(1.0, -y\_true)) \* tf.log(tf.subtract(1.0, -y\_pred) will always be a negative value, so you should do

\-(y\_true \* tf.log(y\_pred) + (tf.subtract(1.0, -y\_true)) \* tf.log(tf.subtract(1.0, -y\_pred))

to make it a positive value, so it can minimize the loss correctly.",1541424172.0
Rediwed,Is *this* loss?,1541424158.0
assembly_programmer,"Is this some kind of out of season April's joke? 
This change is probably the worst non backwards compatibility change I have seen. 

Why?
The main reason why I use tensorflow and not torch, or any other framework, is the graph and how it works. It takes a little time to understand, yes, but once you do understand, that's so sweet and useful. Oh, it also connect with tensorboard, so I can see the graph of a mode without running any operation. The graph allows for a lot of crazy models.
 
Do I want two operations that only share one single tensor? Easy. Want to completely reuse 10 tensores? Done. It is just simpler. And that's the reason I disliked eager mode when they started with it... 

The graph is the core of tensorflow, and it should stay as a priority, in my eyes.
Replacing layers API with keras is also kind of messy. I'm not even sure why tensorflow tought it would be a good idea to take another library, made using tensorflow, and integrate it into the main library. If I'm using tf.keras, why not just using keras? 
Tensorflow was always about the amout of things it allowed us to do, and I hope it does not change, or I'm just going to be sad :(",1541370625.0
LewisJin,"Graph is annoying even I understand it and can master it. A 100 tensorflow line codes I can shrink it into 10 in pytorch. There are a lot of low skill tensorflowers write hundreds lines of codes just do a tiny thing... Be note that , simple is the emphasis of evrything",1541418448.0
sharvil,"So here's a sure-fire way to know whether your training loop is using variables loaded from the checkpoint: don't run the variable initializer. If you get an error that states your variables are uninitialized, it means your variables weren't loaded from the checkpoint. If you don't get any error and training continues, your variables were loaded from the checkpoint.

The weird part about your loading code is how you manage the `Session` instance. Instead of creating it in `SaveDing` and returning it, I'd instead pass it in as a parameter. My guess is that you're not using the same `Session` instance in your training loop as you are in `SaveDing`. So basically you're loading your variables in one session and training a different session with freshly initialized variables.",1541402097.0
_spicyramen,Have you used Tensorboard to see parameters and details about the saved model?,1541360198.0
gokstudio,"check the following

1. `nvidia-smi` works and you can see the GPU on the output
2. Are other processes using the GPU as well?
3. If the right versions of CUDA and cuDNN installed?",1541352887.0
HarambeTownley,"You have 2 solutions:
1) Downgrade tensorflow
2) Upgrade Python to latest of 3.6 (or latest of 3.5)",1541388333.0
slightperturbation,"Look at the weight\_column parameter. You make a column of numbers to weight the error for each example. So, each training example from the underrepresented class might have 0.9, and 0.1 for each example in the overrepresented class otherwise. Then during training the error is just multiplied by that column.

&#x200B;

Here's a SO with example code: [https://stackoverflow.com/questions/48098951/upweight-a-category-in-tensorflow](https://stackoverflow.com/questions/48098951/upweight-a-category-in-tensorflow)",1541329529.0
DiogenicOrder,"You can do upsampling of your data, using SMOTE or Adasyn, there is a scikitlearn packages doing just that !

[Here it is](https://imbalanced-learn.readthedocs.io/en/stable/)",1541344678.0
Metabyte2,"Try undersampling*, also you should be checking accuracy on a validation set not your test set. Look into other metrics as well, it sounds like positive/negative predictive power would be more useful for you",1541343056.0
Daniel_3_,Can you post the error you get?,1541232081.0
Supermaxman1,Could you post the actual error? I don’t see it in the post.,1541213888.0
krishnab75,"I agree that it is pretty confusing. There have been a lot of changes in the \`tf.data\` api lately too. So I was not clear on how much experience you have with serializing data to the TFRecords format, so sorry if I am giving you stuff that you already know. Even I myself am relatively new to converting images to this format, but figured I would share what I have found so far. 

&#x200B;

The first thing is to understand how well you understand the TFRecords format itself. I found this tutorial the most useful, since it goes into the different TFRecords datatypes, including the BytesList, Int64List, and FloatList.  [https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564](https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564) . 

&#x200B;

Then there is another post about one common problem, which is that people will often end up with datasets in TFRecords format that are much larger than their original formats. This is especially true for images which might be decompressed before pushing them to the TFRecords format. So be careful with that. I found a good tutorial about that as well.  [https://planspace.org/20170403-images\_and\_tfrecords/](https://planspace.org/20170403-images_and_tfrecords/)

&#x200B;

Finally, I found a pretty good pipeline to emulate for creating TFRecords from images. It's funny because it seems obvious now. But it did not occur to me until I did a bunch of hunting. So the best pipeline I found for encoding images comes from Google itself. In particular, the Tensorflow developers have a suite of Benchmarking code to test how fast they can get code into Tensorflow and how fast they can decode it, etc. Here are the two links that seem most relevant. Of course, this assumes decent familiarity with the stuff above.  The first link is most relevant to creating a TFRecords dataset for Imagenet images. 

[https://github.com/tensorflow/benchmarks/blob/master/scripts/tf\_cnn\_benchmarks/test\_data/tfrecord\_image\_generator.py](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/test_data/tfrecord_image_generator.py)

[https://github.com/tensorflow/benchmarks/blob/master/scripts/tf\_cnn\_benchmarks/preprocessing.py](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/preprocessing.py)

&#x200B;

Happy hunting and best of luck.

 ",1540923679.0
kindoblue,"It's not that you convert JPEGs in TFRecords, rather you decode JPEGs and store in TFRecords.  Anyhow:

[http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/)",1540908898.0
krishnab75,"The best resource I found on this was to watch the Introduction to Tensorflow class on Coursera, which goes into the input pipeline in detail. It was quite good.  I really recommend that. The way you have it set up will not work--as you no doubt have found out. The reason is that in tensorflow the data ingestion functions like \`TextLineDataset\` will just add nodes to the computation graph. You need to create a parse function that tells tensorflow how to handle each column in the dataset. Then you need to create the batches and iterator. It is not too difficult. 


Here is an example from the Coursera course. 

```
def decode_line(row):
   cols = tf.decode_csv(row, record_defaults=[[0],['house'],[0]])
   features = {'sq_footage': cols[0], 'type': cols[1]}
   label = cols[2] # price
   return features, label

dataset = tf.data.TextLineDataset(""train_1.csv"") \
                 .map(decode_line)

dataset = dataset.shuffle(1000) \
                 .repeat(15)    \
                 .batch(128)

def input_fn():
   features, label = dataset.make_one_shot_iterator().get_next()
   return features, label

model.train(input_fn)
```

There are also some new dataset ingestion functions in the `tf.data()` api. The one that best pertains to you, and probably simplifies stuff is 

https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset

This video (which you may have seen) discusses this new pipeline for csv files. ",1540924187.0
CumbrianMan,"Good point. I’d suggest FastAI, which is built on top of PyTorch.",1540873199.0
neo_here,"Hey can you explain a little more about what you meant? Did you mean start with keras and then go to tensorflow?
",1540878661.0
antidragon,"Tried TensorFlow Lite and freezing the graph?

- https://www.tensorflow.org/lite/rpi
- https://www.tensorflow.org/lite/devguide#freeze_graph",1540779390.0
Mabb_reddit,"The only option is to split the graph in different models, but this a highly not recommend option because it will be extremely slow.

 I think what you are asking is not possible, expanding a GPU memory with the RAM is possible but expanding the RAM is not possible at the moment. ",1540800128.0
Arkhaya,Is this a custom model or a GoogleNet model?,1540826646.0
_spicyramen,Because TF is not a programming language.,1540682748.0
ScotchMonk,"Tensorflow is designed for scale - running distributedly across different servers. With eager execution, it helps early development and testing of algorithms. But during actual production, eager execution is turn off. 

[https://www.tensorflow.org/guide/graphs](https://www.tensorflow.org/guide/graphs)",1540699037.0
ArgoloF,Why should it be?,1540694081.0
nckl,? what context? idk what you're asking,1540682166.0
iamiamwhoami,It is object oriented. Things like tf.tensor and tf.variable are python objects. Maybe you mean to ask why doesn’t it force you to use OO as a method of using it? It’s true it doesn’t but it also doesn’t force you not to. In many cases it’s advisable to wrap your tensorflow code in python classes. ,1540699909.0
jiminiminimini,"You can think of tensorflow as ""declarative"". You are defining a computational graph in a declarative fashion. AFAIK this is so for performance optimization reasons. If all or most of your computations are defined beforehand as a static graph, it is easier to optimize computation.",1540710665.0
gokstudio,It wasn't but is going towards OO with Eager mode where everything is tf.keras.Layers,1540685734.0
Jandevries101,"solved

&#x200B;",1540825492.0
MrAcurite,"There should just be a standard datatype called ""motherfuckingbullshit."" It comes with no documentation, operates via actual magic, and appears in every tutorial.",1540572547.0
venka_97,I feel you man. Every tf documentation shows only Mnist examples. I wish they made a tutorial for loading your own fucking data. ,1540583662.0
psychorameses,"I would’ve liked to make a smart-ass comment like “You lost me at C#,” if it weren’t for the fact that I actually somewhat agree with you.",1540580650.0
mikaelhg,"While it's not well communicated, you do have a point.

    >>> x_train.shape
    (60000, 28, 28)

In other words, your `x_train` should be a numpy array of the shape (N, W, H) where N is the number of images in your set, W is the image width, and H is the image height. Then you just need to fill your `x_train` and `x_test` arrays with image pixel data.",1540565960.0
ephrame2,Such eloquence. Have to upvote. But I also agree that tf tutorial is absolutely useless. Have you tried keras? ,1540599293.0
SemaphoreBingo,You probably want tf.data.Dataset,1540580558.0
oopsleon,"Welcome to software engineering my man, lmao.",1540613247.0
ZodiacKiller20,"I faced the same problem so I wrote a detailed guide on how to convert any picture library into tfdata. It was some months back so it might not work but I'll still link it. I documented mainly so that I don't have to go through the hell-hole of figuring it out again lol.

https://github.com/Zod20/TF-Object-Detection-Demo-Daisy",1540593369.0
d8sconz,"[I just recently stumbled upon this tutorial from Sentdex] (https://www.youtube.com/watch?v=j-3vuBynnOE&index=2&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN) about loading your own data. I'm sorry I don't have enough time now to check it fully, but I noticed it for all the same reasons you mention: Every. Single. Tutorial. Uses the fucking mnist fucking data set. Thanks for so elegantly expressing my own feelings on the topic. Except, lay off the open source criticism. It's a fucking miracle what OS has done.",1540598118.0
Arno_Nymus,"If you have no idea what a line does, why don't you just set a breakpoint to whatever happens after that line and look what that line did. mnist.load_data() obviously returns a tuple. If you observe the tuple and do the math you will find out what its elements look like. Afterwards you just have to replace the line with lines that generate data in the same format. Or you could look at what the fit method requires as inputs. I am sorry to say this, but for a graduated computer scientist your problem solving capabilities seem a little subpar.",1540630874.0
TheOneRavenous,"Might need to scale back your tutorials to simple Feed Forward Neural Networks to understand how to ""transform"" and ""encode"" data. As well as decouple/decompose features from your dataset. 

It's actually a trivial task once you understand the process. When you understand what I'm talking about . You'll look back and go oh yeah I see why TheOneRavenous called it trivial.

If you're a CS major and C# guru I'd think you could figure out what encoding is. I'm just a regular Joe and I know how to roll my own data into a neural network.

I hope I don't make you more upset, as that's not my intention. 

My point is that you're obviously missing some step (trivial to some advanced users). Might be easier to ask for an example or what the hell goes on with function.dataload()

As a side note. Rolling your own data boils down to creating a controller the controller functions/methods should  include (now you have a wrapper for all your datasets, adjust for text or images where necessary):

1)Load data in working memory

2) rearrange data as necessary

 3)pull information from raw data (upper limits, lower limits, means etc.)

4) save data

5) delete data

6) transform data 

7) encode data

Additional controller functions/methods

8) save an output file for graphing

9) save a test input/output file for graphing or sharing and converting to other formats (CSV etc.)

10) logging sessions, i.e. epochs complete, version of network, starting parameters, date and time of session, number of features used in network, size of data used both in individual data points and raw solid state storage capacity (kb, mb, gb, etc.)

11) ability to load a trained model

12) ability to list already saved models. ",1540589211.0
exactlythatpedantic,I just found 3 non-mnist examples by googling 'github tensorflow autoencoder' - didn't even go to the bottom of page 1.,1540597683.0
honeybooboo1989,hear! hear!,1540605957.0
DeligtfulDemon,"I had a similar problem. To address it I read up from some sources and created this small tutorial,in case it helps anyone. https://github.com/ddatta-DAC/ConvolutionalAutoencoder",1540648470.0
tyler303047,"I can't tell you how much I appreciate you summing up my entire experience with tensorflow thus far so vividly. Now, I'm an idiot undergrad who needs to implement tensorflow for my embedded systems project, but every beat of your rant has been the same beat I've felt over the last two weeks.
So, my understanding of using image data is to use:
filename_queue = tf.train.string_input_producer([folderName + '/' + filename])
            reader = tf.WholeFileReader()
            key, value = reader.read(filename_queue)
            my_img = tf.image.decode_jpeg(value, channels=3)
            resized_image = tf.image.resize_images(my_img, [400, 400])
            tensors = tensors + [resized_image]
to get tensors of the images

then use:
with sess.as_default():
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)

        i = 0
        print('going into eval')
        for t in tensors:
            i = i+1
            result = t.eval()
            results = results + [result]
        print('outta eval')

        coord.request_stop()
        coord.join(threads)
to get the images in numpy arrays.
That ""worked"" for me, but I'm assuming you figured something out.",1541305895.0
Aesix,Why help someone like you? What do you do for anybody but cry?,1540590486.0
MogwaiAllOnYourFace,"Have a look at ROCm, you'll need Linux",1540557569.0
nathan_drak3,You may consider checking out PlaidML library which helps run neural nets on AMD gpus. It has limited support though. ,1540563351.0
_spicyramen,"Take a look at this:

[https://github.com/ROCmSoftwarePlatform/tensorflow/blob/rocm-v1/rocm\_docs/rocm-port-overview.md](https://github.com/ROCmSoftwarePlatform/tensorflow/blob/rocm-v1/rocm_docs/rocm-port-overview.md)

My understanding is that there is no clear support for AMD with TF, some folks from AMD may need to chip in to add more context. You should use the new Deep Learning image in GCP which adds GPU support automatically.",1540790584.0
bengt0,"I am running Tensorflow on R9 Nanos, which are performance-wise basically a RX 480 / GTX 1060, but feature only 4 GB HBM. These have worked under ROCm with various degree of success for about a year now and things have really been getting easier in that time.  I would argue that using ROCm is is actually easier now than using CUDA under Linux. Today, you basically install Ubuntu, into that Rocm and some libraries from AMD's repository and tensorflow-rocm from PyPI to your virtual environment. I recently reinstalled Ubuntu and updated my install procedure accordingly. If you only want Tensorflow, follow the sections ""Base Installation"" and from ""ROCm Kernel Module"" onwards:

https://gist.github.com/Bengt/98df20e0708c9766fc9f12f11365029b#base-installation

https://gist.github.com/Bengt/98df20e0708c9766fc9f12f11365029b#rocm-kernel-module

That is under the assumption, that you avoid some caveats. Most importantly, support is limited to a few mayor Linux distributions (Ubuntu/Debian and RHEL/CentOS), the not-quite-latest GPUs (Fiji and Polaris) and the not-quite-latest CPython (2.7, 3.5 and 3.6). More details:

https://rocm.github.io/ROCmInstall.html

https://rocm.github.io/hardware",1541347224.0
redditpentester,"Honestly if I see one more example using MNIST in the data samples, I will fucking blow a lid.

It's been almost 20 years. This isn't useful. It's not creative. It's not pushing the envelope. FFS, it's exactly what the very first TF tutorial describes.

It's not 'solving a problem'. What does anyone learn from this which is so different from Google's own examples?

This field is oversaturated with hobbyists posting the exact same thing on their blog a million times.

You'll know how I feel if you've ever tried to solve a unique problem, or feature engineer something complicated and not at all handed to you. Those are real problems that need real solutions. Literally no one cares about MNIST classification. 

Imagine if math was taught by people posting blog articles on how to multiply the same two numbers, over and over, treating it like it was a unique problem, over the course of 20 years. You'd think it was insane and pointless.",1540520436.0
caiovnv,I was looking for something like that for a while. Thanks:),1540475184.0
frenchytrendy,"The loss represent the ""difference"" between expected result and actual result.
Simplest: loss = abs(actual_result-expected_result)
Simple: loss = (actual_result-expected_result)²
There are many different kind of loss, some are more effective than others depending of the problem.",1540445215.0
n1n9n9n8,"There are functions called loss fucntions to calculate loss. One of them, witch is rly common is: loss=(real_result-compurt's_result)^2
",1540449925.0
honeybooboo1989,"You use both sets to compute the loss, separately. Loss function differs depending on your analysis. For regression, Mean Square Error (MSE) is the most commonly used loss function. for classification, Cross entropy loss (Log Loss) is one of the most famous one. Both has the same idea: find the difference between estimated value and actual value. In Tensorflow, you can choose one of many loss functions. ",1540606227.0
Brudaks,"The traditional way to compare similarities like this is to teach a single network to ""compress"" the data to some vector representation and then compare these vectors. ""doc2vec"" is a keyword sometimes used to refer to such systems.

Another slightly relevant domain is text summarization - for which a common sub-problem is to identify if e.g. multiple news articles are talking about the same event.",1540332352.0
rk39096,"did u install cuda,cudnn before tensorflow-gpu?",1540307722.0
supercorea,"Same thing happening to me as well.

No problem on my laptop(with GPU) today, but on Desktop, infinite spinning.

Please let me know when you find the solution.",1541037076.0
churchilll,"As long as you're not calling tf.gradients or invoking steps of an optimizer, no gradients are calculated.",1540152167.0
vade,"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs

Use the summarize graph tool found in here ?",1540230604.0
pgaleone,"No it's not just you.

The transition from ""plain old tensorflow"" (that I love) to the keras-like API requires a mindset change.

If you come from the plain old tf mindset, you have to relearn how to code with tensorflow. I struggled a bit on this, and I figured out that I will continue to use tensorflow in the ""define graph"" + ""execute graph"" way, but using tf.keras instead of tf.layers, since this it what will happen in tf 2.0 (and I'm not a big fan of tf.keras sincerely, I was pretty happy using tf.layers and tf.variable_scope with the various reuse=True/False when needed. But from tf 2.0 all this stuff will be removed and you have to use the objects in the pythonic way, hence using keras).

About the eager mode, I'm not used to it, hence when for the first time I tried to use the concept of ""GradientTape"" + compute gradient + apply grandient... It was like using pythorch and I was disappointed.

That's why I decided to stuck with graph def (with tf.keras) + execution in a session - it's more tensorflow-ihs IMHO",1540116358.0
Arkhaya,"I've been using mainly keras but when I started with GoogleNet, I liked having the .pb files etc which can't be saved while training and need to have a freeze graph file to make it. 

But I prefer coding on Keras as it's easier to understand and manipulate. I hope it can get better with more functionality. And maybe even support pytorch as a backend.",1540135867.0
iloveergs,Make a github project. And I will write commits. ,1539961078.0
SamStringTheory,"Read the install guide: https://www.tensorflow.org/install/

One of the steps is to install Python.",1539915260.0
MarkKretschmann,"So what about the new Tensor cores of the RTX hardware, are they supported?",1539949733.0
doktorneergaard,"Not sure if this applies, but have you checked that your machine and the notebook expects the same data format, ie. NCHW vs NHWC? Also, does your machine and the notebook both use CPU or GPU?",1539924875.0
psychorameses,"Welcome to deep learning. That happens. The first thing to realize about DL is that you cannot apply the same deterministic mindset you have in traditional programming to DL, because the cookie crumbles differently each time.

First the slowness: Even Coursera Jupyter notebooks are running on GPU instances that have at least a Tesla K80 last I checked. Unless you have a gaming laptop, you won’t have anything nearly as powerful, and even if you do, you won’t have the exact same setup. Weaker GPU / no GPU means your model will take a much longer time to train because it cannot process as many data samples at the same time. The technical term for this is that your batch size will be smaller.

Next, using a smaller / different batch size alone can cause your training outcome to be different because of something called batch normalization (if you have a BN layer). It normalizes the activations across a batch, so if your batch size is different, the normalization process will be applied to different sets of data samples, which causes the math to be different.

Beyond that there are many other reasons why even multiple runs on the same setup can be different, such as dropout regularization (randomly switching off neurons), model compression (again can be affected by batch size and/or available GPU memory space) and parallel training (batches are split randomly).

What you should do in practice is to first determine what training hardware you want to use, then optimize for that setup and try to achieve convergence there.

Lastly, training on a non-gaming laptop is only a great idea if you’re trying to melt it. Even if you can handle training at the same speed with the same batch size, exposing your laptop components to extreme heat will reduce its lifespan. Don’t do it.



",1539961931.0
psychorameses,"Fine, you want more reasons? Your default parameter initialization method may be different, Coursera’s installation might have optimizations enabled, floating point computations will be different on your laptop, etc. There is simply no end to the reasons why model training on a GPU and CPU produce different results. Heck, even the version of TF will be different between the two. You are literally running a different code path on a GPU (CUDA).

The point is that it’s a futile exercise to try to make both code paths produce the exact same results, and that thinking you can is simply foolish, unless you forego TF altogether and write everything from scratch in pure numpy. And even then there are still hardware differences that you probably cannot overcome.

As to your second question, there’s only one answer: Get a GPU.",1540000368.0
jango1502,Do the CS20 for Tensorflow! CS231n for Image (computer vision) these are standford courses and you will have to read and study daily. There are few more courses from Standford that you will be introduced in between these courses time to time. ,1539870206.0
antidragon,Go for these with one month free: https://www.coursera.org/promo/NEXTExtended,1539885534.0
400_Bad_Request,"Just a beginner in Tensorflow, why not make an api which you call from your Application... If you have a small number of clients",1539800046.0
ajmssc,You can call the c++ apis directly. https://www.tensorflow.org/api_guides/cc/guide,1539846644.0
Brudaks,"Keras is an API that executes the high-level operations using primitives from some backend - either Tensorflow or Theano.

Tensorflow has direct implementations of tensor primitives both as ordinary CPU code, and also as CUDA code for GPU acceleration.",1539761246.0
DoctorSoong,"Not stupid. It might be confusing, since Keras got included into Tensorflow when the creator got hired by Google. Keras is a higher-level API that can work with several lower-level back-ends, Tensorflow being one of them.

CUDA is the base of Tensorflow, if you can call it that. ",1539773818.0
r0bertas,"If I understand correctly Keras is an API and Tensorflow is \_one of the\_ implementations.

So you can construct your model using Keras constructs and run it on Tensorflow (or other implementation).",1539760678.0
MirrorLake,"Rolling back the clock, this [old post](https://stackoverflow.com/a/33622489) mentions details about the project. 

> The C++ API (and the backend of the system) is in tensorflow/[core.](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core)

It looks like it was written in C++ and one of the original APIs was for C++. Nowadays, there are [many APIs](https://www.tensorflow.org/api_docs/) that allow you to write Tensorflow stuff in different languages (the community favorite being Python), but that core code is C++.

You can now also install Tensorflow-gpu, which allows your computer to use CUDA to do neural net (or, more specifically, matrix operations) much faster than a typical CPU. For the fastest speeds, the computer it runs on needs a relatively new GPU.

In regards to Keras, Keras runs in/above that top layer as a way of making TF easier to use. Wikipedia: ""...Keras was conceived to be an interface rather than a standalone machine-learning framework.""",1539783106.0
Aesix,It goes like this I think:  base -> c/cpp-> python -> tensorflow that links to C/Cpp for speed but mostly you code in python -> keras for shorthand use of tensorflow (like emojis shorten sentences) ,1539783108.0
CumbrianMan,Thanks.  I found it poorly documented last time I looked (1.7).,1539721691.0
mikaelhg,"That's the example script Google would have written, if every single one of their developers wasn't so obsessed in proving how clever they were through their code.",1539722067.0
mean_king17,Godfucking bless you! ,1541719185.0
cosmic_dozen,"I've been working on visualizing how optimizers work in low dimensional spaces. You're looking at 5K initial conditions converging onto the roots of a 10th order polynomial. The video shows three different optimizers, Gradient Descent, RMProp, and ADAM. I've stylized it a bit, and ran a different set of starting points backwards to see the flow. 

Interested in how it works? Code is up on github! r/https://github.com/thoppe/DeepOptimizerViz

Feedback and comments are welcome.",1539710811.0
liftoff01,"So the solution to my problem was just taking out the outer loop. I still have a lot to learn it seems. 

        dense  = inputs
        dense = self.fc01(dense)
        dense = self.dropout(dense)
        
        for denseLayer in self.deeps:
            dense = denseLayer(dense)
            dense = self.dropout(dense)",1539608378.0
MCFF3000,The problem was solved after replacing some tf.layers by tf.keras.layers definitions in my model according to the suggested by [https://github.com/tensorflow/tensorflow/issues/23014](https://github.com/tensorflow/tensorflow/issues/23014)),1539815483.0
Rigatin,"Solved, if anyone else ever runs into an issue like this they can pm me",1539644590.0
anilmaddala,"You don't have to worry about FP16 or FP32.

You usually do majority (>96%) of object detection retraining using full precession float and then change precession to make the weights ready for quantization.

You can change the precession by modifying the pipeline.config file.  You need to add a graph_rewriter block with quantization. For example checkout the pipeline.config file for ssd_mobilenet_v1_quantized_coco.",1539374709.0
BatmantoshReturns,"post your code, we'll take a look. 

Do you want to do this to increase the number of parameters? decrease training time? etc. ",1539411469.0
joel5,"Depends on how much money you have to burn.

It's 50% more expensive than 1080 Ti in my country, and 27% (FP32) to 38% (FP16) faster according to the benchmarks in this post, so 1080 Ti is better in price/performance.

As an owner of a 1080 Ti I'm fine with passing on this one. Maybe some future update that makes better use of the tensor cores can change my mind.",1539324376.0
MrVicodin,"As long as I have enough memory for training models a 1080 Ti is fine for me, they've got the same memory so I don't see a reason to upgrade at the moment.",1539354016.0
Mrbumby,"ML is going to stay. Betting on a single framework is risky.

For a perfect carrier, you better get into academia and write 2 or 3 impactful papers on machine learning. 

For an average CV a degree, internships and some kaggle channels are enough.",1539160637.0
iloveergs,"a lot of it comes from your math background. I did Mech-eng and find my math is in use every single day without fail.  I do research in a company so and use libraries as tools.. nothing more. one week is pytorch, the next TF, then the next month might be Matlab. I find getting your head around the core of ML and learning slowly makes you language and Library agonistic. :)  but then again, there's money in implementing off the shelf models into a clients stack.. so there's a whole range of different roles... ",1539287611.0
DollarAkshay,Career*,1539196951.0
yggKabu,Use Python and aws lambdas,1539143576.0
RaionTategami,You'd could write a custom optimizer that creates slots to keeps copies of the past weights. Could be rather expensive memory wise.,1538981662.0
rjddude1,"Are you trying to infer (predict) for a given input after having trained your model?

If that’s the case, then you need to export your frozen graph as a saved model. You can use TensorFlow Serving to make requests to it using a GRPC client that you can write in Python (I wrote mine in C#). It also has Rest API available, but I chose not to use it because it has some limitations for my use case. ",1540561575.0
honeybooboo1989,"It is basically similar but make_csv_dataset reads CSV files into a dataset, where each element is a (features, labels) tuple that corresponds to a batch of CSV rows. The features dictionary maps feature column names to `Tensor`s containing the corresponding feature data, and labels is a `Tensor` containing the batch's label data. https://github.com/tensorflow/tensorflow/blob/68ebb861e916c094de934b1d10a47d905e596795/tensorflow/contrib/data/python/ops/readers.py#L34

CsvDataset creates a `CsvDataset` by reading and decoding CSV files. It is basically a class method of make_csv_dataset.",1540606964.0
tu_tan,"Try adding trainable=True when you create the variable.

Btw you should try to initialize the variable with non-zero value, normal distribution (0, 0.01) for example.",1538846250.0
znihilist,"Much simpler, more streamlined, and less 'code' to worry about.

If the models are fairly standard, and by that, I mean models that are fairly regular: CNN, RNN, etc, then Keras in 99% of the cases enough for you.  


EDIT: Let me say this if in your line of work you have to regularly use custom-made models, then learning TF is an invaluable skill.",1538744770.0
WiggleBooks,Much much much more simpler,1538748594.0
Laboratory_one,"It's allows you to perform high level operations very easily. You're also able to use the TF API along with keras. This provides TF level control when Kera alone can't accomplish the task.

&#x200B;

It's very useful!",1538770213.0
latvj,"Here you go: https://keras.io/why-use-keras/

You seem lazy. I guess no ML framework will ever work for you. Probably no framework, in general..",1538909779.0
Supermaxman1,"See my answer on StackOverflow for a complete solution, but I think your primary problem was using mean squared error over cross-entropy as your loss function on a classification task.",1538717502.0
TheCoolManz,"Not sure exactly what you're looking at. K is just keras.backend which is a useful tool for this kind of thing. If you have no clue what's going on, don't use your own activation functions... I doubt you would find that your own ones would be more effective than leaky relu or something like that.",1538657221.0
MogwaiAllOnYourFace,Are you running cuda 10?,1538608614.0
Mabb_reddit,"There is an open issue about something similar for the same function, but no response from developers. You could try to post and catch some attention from any developer:  
[https://github.com/tensorflow/tensorflow/issues/21836](https://github.com/tensorflow/tensorflow/issues/21836)",1538660320.0
crazyhh,As far as I know you have to build the graph first and then restore it (I'm doing it this way and it works).,1538554814.0
oopsleon,"Try removing the line where you run the variable initializers after restoring. A common mistake (I’ve done it too) is doing this. It will reset all your variables to a random initialization, effectively undoing all training.",1538539466.0
_spicyramen,Dataset API https://www.tensorflow.org/guide/datasets necessary when dealing with using data for training and inference,1538494905.0
Henry4athene,"are you trying to do feature selection of the 50 input features? If so, not sure what advantage tensorflow would have for this.",1538448786.0
lietheim,Are you sure it needs Machine Learning?  If you need sorting variables and find the highest profit it may be easier with traditional programming. ,1538448185.0
WrinkledTime,"I have a GitHub account with several demo programs for doing time predictions ( mostly Nasdaq and BitCoin )

Some are in TF
https://github.com/timestocome/Test-stock-prediction-algorithms

And here are some Deep Learning TF examples
https://github.com/timestocome/DeepLearning


I'm not looking for a job, but it might help your coders get started and that's the most difficult part.

I'm currently working with Keras and hope to have some more complicated examples up there in a month or so",1538448997.0
CommunismDoesntWork,What are your returns like? And can you provide proof you're getting these returns?,1538602295.0
Potatolicker,Maybe principal component analysis is what you need,1538762353.0
nckl,...can you elaborate? What error did you get? What'd you install?,1538424448.0
Microshak,"You are going to want to do 2 things. First, use a shared volume when you set up your docker container.  This allows you to map a local folder (that you can work in) to your docker container.  Then update your local file.  Next when you run Docker with exec. This allows you to run a command in the Docker container.  So if you are using Python on your container you dont need to recompile you can just call your Python code. ",1538352325.0
gevorgter,"I do not think TF works with Cuda 10.
You should download 9.x version.
",1538345237.0
mikaelhg,"Have you tried installing EXACTLY the versions of CUDA and cuDNN that the TF documentation tells you to install, instead of the newest versions which you arbitrarily decided to install against the documentation?",1538338079.0
WrinkledTime,"It's a nightmare on Ubuntu too.

On Windows I found I had to install Anaconda first, then use pip install tensorflow or pip install tensorflow-gpu to get it to work

Check the Nvidia directions, there are lots of little tools to check things along the way that will help you figure out where things broke
https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html

",1538334153.0
KjellJagland,CUDA 10.0 is several versions too new. 9.2 and 9.1 also won't work. You need 9.0. The docs feature a table wth compatible versions.,1538603689.0
nckl,"Building tensorflow from source is, in my experience, the best way to avoid any of this. It takes a while, you might have a couple issues, and you have to repeat the process for every update. But if you want maximum performance (like it sounds like you want) it's never really going to be possible to use prebuilt binaries. 

Especially if you're not using a GPU though, it's reeeealy worth considering if you even care about any of this. If you're just learning, it's IMO 1000x worth just getting into it, not worrying about max performance. I've made the same mistake before. You can build later whenever you want, but learning to ignore a pesky ""not compiled to use AVX instruction"" is worthwhile.

Make sure you're pip installing everything in a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtualenv/) - you should basically NEVER be installing to your system's python, if you can avoid it. Create a venv and pip install everything in there (this is standard for virtually (haha) all python projects, and if you don't know how to do it, it's worth learning!). I only mention this because you say it overwrote your built-from-source tf.

Good luck! Everything but the first paragraph is me making assumptions. If they're not relevant, the first paragraph is my actual answer. ",1538336900.0
captain_awesomesauce,Try out dockers containers. Intel has avx and mkl optimized versions and nVidia has gpu optimized containers. ,1538356715.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/learnmachinelearning] [CPU Tensorflow with MKL and SSE4.1, SSE4.2, AVX, AVX2, FMA optimisations. • r\/tensorflow](https://www.reddit.com/r/learnmachinelearning/comments/9k8mrw/cpu_tensorflow_with_mkl_and_sse41_sse42_avx_avx2/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1538331932.0
oopsleon,"Like you said, Estimators take care of basically everything, and TensorFlow really wants you to use them. Learn how to implement custom Estimators and then move on to understanding how hooks work, since that’s how you *really* customize things.",1538152716.0
crazyhh,"Hi,
i think making original art with ML is a very hard task. You may have to contrain yourself to making images of one category, or you may change existing images (for inspiration).

Here is a cool example for style transfer:
https://www.youtube.com/watch?v=dyzn3Fmtw-E


If you have enough data of one domain i.e. faces or any other thing which structure can be learned with a reasonable amount of examples you may create your own Generative adversarial network.

Giving samples of different paintings wouldn't work in my oppionion because the greater structure of this task wouldn't be learnable without a huge amount of samples. A sub domain like portrait paintings would work though, or something more fancy like still lifes with flowers. 
",1538120771.0
thiernodiop,GANs network are your friends. You can use any dl framework to implement it including tensorflow,1538123531.0
vandelet_industries,"What do you mean by asking if the “Tensoflow environment is best for this?” It seems to me that the framework used doesn’t have any bearing on how the model functions. 

Are you planning on doing something like linear regression?",1538086269.0
moazim1993,"Google linear regression tutorial in your preferred programming language, tensor-flow is overkill. If your a pythoner here’s the code: http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html
",1538100336.0
lietheim,Is the Output directly proportional to the input ? ,1538099145.0
MrAcurite,"Yeah, it's a bitch. Just gotta keep trying shit until it works. My setup will run Tensorflow in Spyder, but only if I launch Spyder from the terminal.

EDIT: Wait, what the fuck? 2 Tesla p40s? You have $24,000 worth of hardware, but not a bunch of IT people who aren't randos on Reddit? What the fuck?",1538056512.0
nikniuq,"Installed cuda 9.0 and cudnn 7.2?

Whats the error you are getting?",1538102867.0
Chayzeet,"It's a bit of hassle to get it working, I have 18.04 and 1080ti.

I installed 390 nvidia desktop drivers, then cuda 9.0 (I think you can also install 9.0 and then 9.1 update?). Important note is that at CUDA installation you **do not** update desktop drivers. It messes everything up quite often. Then copy the cudnn, just check version compatibility. After that, do the restart, and download tensorflow-gpu.

&#x200B;

Here is some tutorial I found online when I was reinstalling my system couple weeks ago [link to github](https://gist.githubusercontent.com/Mahedi-61/2a2f1579d4271717d421065168ce6a73/raw/7ccfa95efbe76779ecbe6629a44a8dd853b5df54/cuda_installation_on_ubuntu_18.04). It has all the commands, just make sure you use YOUR versions (this is for 384 patch).

Reply me if need any help, as the setup is quite similar, I recommend using conda virtual environments (miniconda to be specific). Create python 3.6 (newest is 3.7) environment, and install everything there.",1538132849.0
thiernodiop,To transform the string values to numeric You can use one hot encoding or embedding separately and then resample your data and only then feed it to your estimator. To recover the string you can just use a lookup table in embeddings and a simple table with one hot encoding by mapping it to your vocabulary array. ,1538005465.0
thiernodiop,Actually you would do the embeddings before all the things related to your resampling or estimator. And  use the new data with the resampling and only then touch the learing part by that i mean your estimator stuff,1538081216.0
jrkirby,"I think that often people try to plot how well some model or optimizer works on a 2D function hoping to gain insight that will generalize to real world problems. However, almost every problem that is non-trivial is high dimensional. High dimensional functions don't just behave like more complex, bigger problems than 2D functions. They have some fundamentally different properties.

Things like:

* Almost all the volume in a high dimensional space is on a thin edge or at the corners.

* Almost all points in a high dimensional space will be very similar distance distances away from each other.

* The number of directions increases exponentially with dimension.

And many more properties.

Thus, I would not expect to get much enlightenment from graphing what an optimizer does on a 2D toy problem. It does make for some nice looking pictures though.",1538000423.0
cosmic_dozen,The image shows 300 solutions to the loss function \`|z\*\*2+1|\` on the complex plane. I used tensorflow and changed the optimizer for each run. I love how you can see the momentum in ADAM!,1537997684.0
TheAINoob,"Yes, it is possible and that is how I do it. 

Update: Training is done using tensorflow and inference is done using just numpy in python. ",1537996900.0
OutOfApplesauce,"Not really a tensorflow question and is probably better for /r/LearnProgramming or /r/learnmachinelearning .

SKLearn has a “train test split” where you can separate a list or DataFrame by percentage.",1537975919.0
thiernodiop,You can use tf.dataset api to do that also. ,1538005802.0
stupac62,Here's the link: [https://github.com/uber/petastorm](https://github.com/uber/petastorm),1537902958.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/u_rfeynmann] [Introducing Petastorm: Uber ATG's Data Access Library for Deep Learning](https://www.reddit.com/r/u_RFeynmann/comments/9j5z19/introducing_petastorm_uber_atgs_data_access/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1537992243.0
jango1502,Dude you have asked for too many things at one post haha,1537916597.0
AspiringGuru,interesting concept. I can't help but wonder why it's not already incorporated into Tensorflow / Keras.,1537828394.0
rigabigadiga,This seems like a python error. Maybe you imported something incorrectly or misspelled the module when you were trying to use it.,1537640641.0
DuckDuckFooGoo,"The different methods of feature extraction are Vanilla SSD, Pooling Pyramid Network (PPN) SSD, Feature Pyramid Network (FPN) SSD, etc., and those models are included in the Tensorflow Object Detection API. What are you trying to do?",1537637713.0
ferlix90,"hei , easy enough, i used pip to install the wheel of tensorflow for rocm,  quite easy !

&#x200B;

[https://gpuopen.com/rocm-tensorflow-1-8-release/](https://gpuopen.com/rocm-tensorflow-1-8-release/)

&#x200B;

download the latest wheel from :

[https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow/](https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow/)

&#x200B;",1537623806.0
DuckDuckFooGoo,Is the reason why you are using rocm is because it makes AMD support easy for tf?,1537651700.0
kennethz3,"Check out fast.ai's lessons. They do NLP as well, however I don't think they use TensorFlow",1537555303.0
Metabyte2,"Either would work with some tweaking but fuzzywuzzy would be way easier while something like an lstm would yield better results. It would be *significantly* more work, especially starting from nothing",1537601807.0
thiernodiop,You can use seq2seq model in tensorflow or even the seq2seq lib by google which also use tensorflow to get the best response by calculating the similarity of the responses to the question. U cam also do a générative model to create even new response that are not in the dataset. ,1538006063.0
Metabyte2,"Are you asking if machine learning can be used to cluster related tickets?  Yeah of course, advertising is one of machine learning's main use cases. Is your ticket information constantly updating or are you planning in batching it? If youre batching a csv would be fine but otherwise you should look up online machine learning algorithms.

Just yesterday tensorflow's youtube channel released a few videos on natural language processing, it might be a good place to start.",1537535918.0
rigabigadiga,"I think this relationship is simple enough to be modeled with simple convolution (no encode-decode structure). That said, I think a more robust network should still perform well. One of the problems with pooling is that you loose some positional information. Deconvolution (or transposed convolution) is good at extracting this positional information. Simply upsampling will not be good at this. Another typical practice for convolution is local response normalization. Also, in this case, zero-padding should work well. So you may try a simpler model, a model with conv2d_transpose, normalization layers, and make sure you are zero-padding. Activation functions, optimizer, and loss function seem fine.",1537596826.0
MogwaiAllOnYourFace,"A transposed convolution essentially has a stride of less than one, such that the output dimensions are larger than the input dimension.

These are typically used for deconvolution, or learned upsampling if you will. The best example of use I can think of is semantic segmentation networks, however I'm sure they have uses in many encoder decoder style networks.

There are diagrams showing the fractional convolution quite clearly if you have a Google for deconvolution",1537430678.0
rigabigadiga,"Also, I'll note that if you use a kernel for conv2d, then use the same kernel for conv2d_transpose, you get the original image back. You don't have to transpose the kernel.",1537510618.0
OhmSnail,[https://github.com/vdumoulin/conv\_arithmetic](https://github.com/vdumoulin/conv_arithmetic),1537543439.0
nikniuq,Tried as Administrator?,1537426759.0
quangbd,use anaconda,1537426876.0
nikniuq,Have you tried editing the file directly to test the permissions?,1537434140.0
ZodiacKiller20,"If admin didn't work then maybe look into chmod, your downloaded file might have permissions restricted.",1537436956.0
ppwwyyxx,"In eager mode you write the ops that update the statistics as usual. And because it is eager, it is executed right away. So you don't have to worry about it later.",1537645546.0
Hak333m,"Pycharm can do that most fo the time while you're on the editor, or sometimes you need to press 'Ctrl' + Space boutton, but it do the job usually well.",1537356278.0
thiernodiop,Vscode also can and it’s lighter than pycharm and it’s also free😊,1538006632.0
thiernodiop,"Vscode is way better than spider. 
I used to use spider 🕷 but vacode is just awesome and polyglot",1538080909.0
smokrow,Is your dataset growing during your training?,1537376585.0
smokrow,Have you considered using a generator with the tf dataset api?,1537392605.0
haseox1,"This repo has a few examples which saves and restores weights using tfe.Saver() - [https://github.com/titu1994/tf-eager-examples](https://github.com/titu1994/tf-eager-examples)

&#x200B;

More specifically, the Language Model example (#8) has a few lines in the final code block which saves weights every epoch then restores the best weights prior to predictions - [https://github.com/titu1994/tf-eager-examples/blob/master/notebooks/08\_01\_rnn\_lm.ipynb](https://github.com/titu1994/tf-eager-examples/blob/master/notebooks/08_01_rnn_lm.ipynb)

&#x200B;

More recently, it is advised to use tfe.Checkpoint as a more object oriented way to save and restore weights. Checkpoints uses ResourceVariables to allow restoration of objects as and when they are created completely - i.e. a Model is \*called\* or built completely.

&#x200B;

A Models weights are built completely \*only\* after it has been called at least once, so if you want to restore via a Saver, you gotta call the model first and then restore. If you use Checkpoint, the ResourceVariable from the checkpoint will set the weights after the first call of the model automatically (I haven't tried this yet, but that's how their tutorial says it works). Reference - Object based saving - [https://www.tensorflow.org/guide/eager](https://www.tensorflow.org/guide/eager)",1537311585.0
aotus_trivirgatus,"Dude -- if you're *eagerly executing* it, you're clearly not saving it.",1537339014.0
RaionTategami,I make 1million embedding of dim 80 to be about 320mb. Maybe you are running out of GPU memory? In which case your can try pinning the embeddings to cpu so they they stay in ram.,1537247907.0
neburski,"You could check how it is done for Arch Linux. You can find the build instructions (PKGBUILD + patches) at [https://git.archlinux.org/svntogit/community.git/tree/trunk?h=packages/tensorflow](https://git.archlinux.org/svntogit/community.git/tree/trunk?h=packages/tensorflow)

&#x200B;

I tested it on my system with a minimal working example.

Python information:

    Python 3.7.0 (default, Jul 15 2018, 10:44:58) 
    [GCC 8.1.1 20180531] on linux

Minimal working example which can be found on [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)

    import tensorflow as tf
    mnist = tf.keras.datasets.mnist
    
    (x_train, y_train),(x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0
    
    model = tf.keras.models.Sequential([
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation=tf.nn.relu),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.Dense(10, activation=tf.nn.softmax)
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    
    model.fit(x_train, y_train, epochs=5)
    model.evaluate(x_test, y_test)",1537432648.0
tanzeel29,Nope for me tensorflow is only working on python 3.5,1537283370.0
theophrastzunz,no the fix you want but try creating a virtual env or conda environment?,1537226957.0
ericyue,"best choice is tensorflow-serving , check it on github",1537185680.0
_spicyramen,"Have you look at Cloud ML Engine?

[https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview](https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview)

Take a look at this example:

[https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/flowers](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/flowers)",1537247806.0
illbebacha,"I almost always use flask. It's quick and easy, but make sure you load the model only once during, and not every time the API is called. Doesn't get easier than that. 

```
from flask import Flask

app = Flask(__name__)

@app.route(""/classification_result"")
def classify():
    do_something()

if __name__ == ""__main__"":
    load_model()
    app.run()
```

Have a look at this for more details:

http://flask.pocoo.org/",1537184744.0
sd_glokta,I liked TensorFlow for Dummies and Machine Learning with TensorFlow.,1537193211.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/mlquestions] [Is there any standard book on Tensorflow?](https://www.reddit.com/r/MLQuestions/comments/9gi6el/is_there_any_standard_book_on_tensorflow/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1537168611.0
PKJY,I'm not sure which specific CNN implementation you are talking about but it could be the output filter dimension.,1537084323.0
emredog,"Tensorflow api does not contain a ""z_dim"" to my knowledge, but I saw a couple of dcgan/wgan implementations that use ""z_dim"" as the number of filters or input channels. I believe the term comes from the common use of x, y, z, as in width, height depth.",1537093161.0
zazio1000,I think a z value is weights * previous activations + biases before you put put them into an activation function so z_dim might just be an array of these values at a specific layer.,1537093856.0
kds_medphys,"Do you have a link to an example?

&#x200B;

I do CNN-based research in TF and haven't come across this phrase ever.

&#x200B;

I wager it has to do with the output feature depth.",1537126373.0
webDev_X,What kind of model are you using? And do you have a classifier?,1536947265.0
Aweza94,which library are you using? For example in tflearn its very simple. you load the model and do model.predict(img). ,1537060015.0
iloveergs,Chrome tracing [https://towardsdatascience.com/howto-profile-tensorflow-1a49fb18073d](https://towardsdatascience.com/howto-profile-tensorflow-1a49fb18073d) with tensorflow profiling. :) That's what i think you want?,1536922026.0
thiernodiop,Tensorboard with metadata activated is your friend ,1538006851.0
nile6499,"switch to pytorch like everyone is doing, [https://discuss.pytorch.org/](https://discuss.pytorch.org/) they even have forum where developers answer question.",1536803099.0
ZodiacKiller20,Look into google cloud AI. They provide online tools that your game can access to train stuff.,1536759022.0
roaming_bear,"The reason we have a training and validation set is because we want to check the performance of the model on data that it hasn't seen. However, if we are tweaking hyper-parameters and using the validation performance to select the best model, the model we choose could be slightly biased toward the validation set because it has been optimized using that set as a performance measure.

Therefore, this necessitates having another set of data that the model hasn't seen, and which hasn't been used to tweak the model, in order to assess the final performance of the model.",1536708532.0
fdren,"From SO:

https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set",1536706188.0
tossedsaladbowl,"While this does not answer your question directly, you might want to have a read http://hunch.net/?p=22",1536784673.0
thiernodiop,"Both are used to verify the goodness of the model by not using the data used to learn. However validation data are used during training by changing the hyper parameters to have better accuracy on the validation data, it means that after few iteration the model may also overfit the validation data. That’s why you need a test set at the end to check if your model is not overfitted on the training and validation set. ",1538007122.0
Metabyte2,Do you get paid or does those articles look good on youre resume? Honestly man that was a super low effort post.,1536696802.0
nikniuq,Javascript seems to be another popular one.,1536622581.0
watty_dude,Have you used Keras? It’s a higher level neural net framework that uses tensorflow as a backend. Makes it very easy to built models by layers. It has predefined layers that are commonly used. And you can also define a custom layer in tensorflow and use that in your model if you want.,1536640137.0
robertbowerman,"To do deep learning TFLearn on top of TensorFlow is excellent - it makes the API so much simpler, so much more understandable.  The way NN are built up is more intuitive.  Fitting and Predicting are easier.  Its not so good for Deep Reinforcement Learning though.  Better appears to be TensorForce - its on github — unfortunately its not as mature as it ideally would be and its documentation is a mixture of long and hard to grasp, but it appears to be the foundation of what we need for DRL on TF.  

And of course if you are writing in TF then the way to do it is with Python, as you explain.  I would argue that (based on Github stars) TF is the way to go and Python is its friend.  Best don't be distracted by other programming languages, but rather go into DL deeply. ",1536623729.0
MogwaiAllOnYourFace,[https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf](https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf),1536592501.0
iloveergs,"Interesting. Out of interest to learn, what do you see as the advantages over TPUs? ",1536663784.0
mortonjt,"Just conda install python=3.6 

https://conda.io/miniconda.html",1536531396.0
redditpentester,"\>I cannot roll back Python to 3.6 (could not find a way) 

&#x200B;

What? Which OS are you on, I'll send you like 3 commands to fix that.",1536537075.0
alew3,Use conda with a virtual environment.,1536533899.0
X--tonic,I would use docker with latest working python tensorflow combo.,1536535454.0
not_from_this_world,"What you need is a [virtual environment](https://realpython.com/python-virtual-environments-a-primer/). People tend to use a virtual env together with a package manipulator like pip or anaconda. If you go with anaconda I recommend you to use miniconda instead, it's the same this but with less space/download required, perfect if you're gonna use it just for TS.

They all work in a similar way,  installing (a different version of) python in a separate place, leaving your OS python alone, and handling all the dependencies.",1536586430.0
thejazzroot,"I don't know what is more complicated: reverting to 3.6 or compiling tf from source.

But if you *really* need to keep the 3.7, you can try the second option.",1536531512.0
oopsleon,Have you read the guides on Tensorflows website? There are a few on RNNs.,1536509714.0
Mabb_reddit,"First of all let's clarify a thing. The idea of the Tensoflow package is to use a GPU to speed up operations that in a CPU will take a lot of time, like any matrix operation for example.

So the first two questions you have to ask is:

\- Do you have installed the tensorflow GPU and do you have compatible GPU?

\- The operations that I want to use are suitable to be computed in a GPU?

Looking into the code, k-mean algorithm is not a easy algorithm to use in a GPU aside from the distance calculation. Therefore most of the operation will be computed on the CPU.

&#x200B;

Another point is that sklearn have a really good low level optimised algorithm which most sure beats that Tensoflow code using generic operations.

&#x200B;

Then judging the code that you linked is really bad optimised and constructed, but this a personal opinion, and I think that is not a good reference to start programming Tensorflow. You should take a look into the official [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/) which provide a high level API tutorials.

&#x200B;",1536575827.0
EthanPhan,I’m training my model on a Dell G7 inspiron (some time on my ec2 instance) so i’m not sure how to respond tho. ,1536483886.0
pahtrel,Are there any trade offs to using eager vs normal? Is normal faster? If not why wasn’t it made like this all along ,1536503114.0
PKJY,"Are they any good? Compared to fast.ai,..?",1536478825.0
xib1115,I just bought these. I think it's a great deal considering I spent $70 for two of the 15 you get. ,1536504797.0
R3ddit_Is_Trash,"The twitter link is a paid reference link of some kind, the URL at landing has a partner=game143.",1536540380.0
frenchytrendy,The link https://www.humblebundle.com/books/machine-learning-books,1536484364.0
caffeine_potent,Transfer Learning,1536378117.0
PKJY,"You would probably want to ""retrain a bottleneck layer"". Basically you keep the entire network structure as is, except the final layer(s) which you can change however you want (add additional output neurons but keep the weights of the existing labels) and then you train only those new layers.",1536358568.0
theslt,"It's called""transfer learning"" and you can also use first layers in a not training form. Means you can block to kernel weights and only let the gradient update the weights of Upper layers. This way you can use the general feature extraction layers and train the model faster for your own situation.",1536430501.0
WarrantyVoider,"Hi there, im trying to train an object detector with tensorflow to detect cars.

I got 16k annoted pictures from [here](https://ai.stanford.edu/~jkrause/cars/car_dataset.html) and followed [sentdex ](https://www.youtube.com/watch?v=srPndLNMMpk)tutorial to prepare the training data and retrain an existing model.

I cant really remember which base model I used specifically, but I think it was one of the ssd_* models, is it maybe not useful for this kind of task?

Do I just need to wait longer with training?

Why doesnt it work on the overview pictures with a lot of cars?

Thank you in advance for any help

greetz

EDIT: please click title to get to imgur gallery with examples",1536341392.0
sd_glokta,"This code creates a TFRecords file containing four integers. Then it reads the file's data into a dataset:

    # Create an example containing four integers
    int_list = tf.train.Int64List(value=[0, 1, 2, 3])
    feat = tf.train.Feature(int64_list=int_list)
    container = tf.train.Features(feature={'feat' : feat})
    example = tf.train.Example(features=container)
    
    # Write the example to a GZIP file
    opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)
    writer = tf.python_io.TFRecordWriter('ex.tfrecord', opts)
    writer.write(example.SerializeToString())
    writer.close()
    
    # Function to parse TFRecords
    def parse_func(buff):
        features = {'feat': tf.FixedLenFeature(shape=[4], dtype=tf.int64)}
        tensor_dict = tf.parse_single_example(buff, features)
        return tensor_dict['feat']
    
    # Create a dataset from TFRecords
    dset = tf.data.TFRecordDataset('ex.tfrecord', 'GZIP')
    dset = dset.map(parse_func)
    iter = dset.make_one_shot_iterator()
    next = iter.get_next()

&#x200B;",1536322159.0
newaccountbc-ofmygf,"For readability, use the embedding_lookup. It's very clear what you're doing at that step ",1536279362.0
transhumanist_,There’s a tutorial on the official tensorflow website...,1536329321.0
X--tonic,"TPU is just an underlying processor for your data. It shouldn't have any tutorial, unless you're looking to modify a TPU and fabricate a new one of your own.

If you're interested in making optimizations to your algorithm to meet the best practices of TPU, using tensorflow, and [tf.data](https://tf.data) will already solve this for you. Tensorflow is probably the only framework to support TPUs.",1536219975.0
jthat92,I recently working a lot with TPUs. The best I could find is the documentation itself which is [this small overview](https://www.tensorflow.org/guide/using_tpu) and some examples regarding different usecases which are located [here](https://github.com/tensorflow/tpu).,1536326358.0
Mabb_reddit,"If you have the dataset split in training and validation is possible that the training set is not a good representation of all the dataset, probably missing some classes or important examples.",1536150902.0
R3ddit_Is_Trash,cool af,1536018757.0
serbotec,Berry cool,1536046810.0
lietheim,Did you considered the color for the training set? ,1537058502.0
Tots-Pristine,Your labels being 120x50x3 images is pretty unusual - care to expand on what the use case is here? ,1535916692.0
ZodiacKiller20,"You do have to only change the graph.pb and strings.txt. If you trained it properly with the mobile_ssd settings then it should work. I have a custom eye detector working like that. Post the error you get on android when you try to use your custom trained graph.

Edit: Note the size of the parameters in the android app has to match your graph train parameters. Things like size etc.",1535880707.0
akmaki,"There is the lower level tpu.rewrite APIs, I'm not sure if it's well documented. That's what TPUEstimator uses under the hood. 

But honestly it's probably a lot more work to figure that out compared to moving over to Estimator. ",1535862104.0
BatmantoshReturns,Have you figured this out? I'm just starting on this. ,1540357471.0
transhumanist_,"Pretty sure you can use TPU on most of the layers. Create a simple model, train and then look for the graph on Tensorboad. There will be an option to colour the nodes according to TPU compatibility. To me, most conventional and advanced layers and nodes are TPU enabled. What you need is access to the hardware.",1535831600.0
iloveergs,"what website? what code? what traceback? what hardware? what flags? help us help you!

&#x200B;",1535727605.0
arya_minus,Check you input\_layers and output\_layers,1535807657.0
PhoebusElpollo,"I already fixed it, I misunderstood what I needed to fill in, thanks for you help though",1535972172.0
Metabyte2,Lets call it an image or is it an image? Pillow has methods to reduce image size. ,1535667091.0
Gh0st1y,"Maybe just build it yourself? I don't mean that in a bad way, just that you'll spend a lot of time looking for and setting up a project, but it sounds like you already have grasp of what you want to do. Just read the names instead of the whole file, and randomly split them up as the data like you'd normally, then load images from the bins you generate. I would think scipy or keras would have utilities to bin up data like that, so you just need to write a utility function that translates a bin. 

There are probably better ways to go about it, maybe, so it depends on the scope of the project, but if its a small thing for yourself you can probably get away with it",1535677062.0
Mabb_reddit,"Ttensorflow has the option of loading data from a list of files. You can create a iterator that is feed from this files, and tensoflow will manage the pipeline depending on the actions you want to do, batching, shuffling, etc.  
More information in this link: [https://www.tensorflow.org/guide/datasets](https://www.tensorflow.org/guide/datasets)",1535712805.0
truthseeker1990,"If you have defined the architecture already, what else do you need to know? Fire it up and see what you get. Then you can try emulating the architecture of some famous models. There are tons. Look for leaderboard of computer vision competitions of recent years. ",1535615967.0
Dragon-Lord365,Try alexnet or resnet based models and use keras or tflearn to build your models. Tflearn's image preloader is really easy to use ,1535615599.0
Arkhaya,What platform are you using tensorflow or pytorch?,1535640342.0
oopsleon,"Browsed through your code and nothing stands out (on mobile right now). I’ve got to ask though, why are you using such low-level TensorFlow? Reminds me of way back before Estimators and tf.data.

Or why not even using a SavedModelBuilder (instead of the much older Saver)? Take advantage of the newer APIs, they are significantly more user-friendly.",1535596482.0
Mabb_reddit,"The first error that I found, when you load variables from a saved model you must not initialise again the variables. Because initialising  again will reset to the default value all this variables.

You can check this with a small example. Loading a model, running a variable to see the value. Then initialising and you will see that the value change.

Check this link: [https://www.tensorflow.org/guide/saved\_model](https://www.tensorflow.org/guide/saved_model)

I hope that solves your problem.",1535611414.0
akmaki,"I think this sequence of code
```
sess = tf.Session()
new_saver = tf.train.import_meta_graph(launch + '/TumorOUT_no_core/20180829-142646/model.meta')
new_saver.restore(sess,tf.train.latest_checkpoint(launch + '/TumorOUT_no_core/20180829-142646/'))
sess.run(tf.global_variables_initializer())
sess.run(tf.local_variables_initializer())
pred = uNet2D(X, .1, 3,is_training)
```

What you are actually doing is:
1) loading the graph from the meta_graph
2) restoring variables of that graph from a checkpoint
3) overwriting those restored variables again with the initializers
4) creating *new* variables in your uNet2D function, which you are not initializing.

What you want to do is either use import_meta_graph and then get tensors by name from the graph, or just don't load the meta_graph and just re-build your graph how you did when saving it and just call `saver.restore` on it. Checkpoint loading just works by string matching.",1535863475.0
Dragon-Lord365,"Try coco dataset, includes many more classes than just cars",1535558446.0
znihilist,Did you make sure to follow the installation prerequisites?  I believe the NVIDIA drivers they need are not the normal ones you'd install for yourself.,1535498790.0
nikniuq,"Did you go to the site it listed? You need the correct (not latest) versions of cuDNN, CUDA, display driver and python.

If you install the latest version of any of those it will not work.",1535499125.0
triployd,seems like a cudnn problem. i suggest you check out your cudnn version.,1535510445.0
dfcHeadChair,"I think your best bet for high res will be to download the data and recreate the charts using Plotly, Seaborn, or your favorite viz tool",1535429584.0
emuccino,Could you just take a screen capture? Or are you looking to retain the dynamic interface?,1535394617.0
akmaki,"There is a checkbox that says something like ""Show download links"" and you can get the CSV, then you can recreate the plot in any plotting system. 

I assume that's what you wanted, otherwise you can just screenshot? ",1535865996.0
smokrow,You can go overkill and use d3 js 😂,1535570191.0
sd_glokta,"By default, it optimizes all of the variables associated with cost.fn in the current graph. Not all of the tensors, just the variables.",1535378237.0
ady_anr,"What about placeholders. Placeholders are variables too right?
",1535379065.0
triployd,"what I would do is use the checkpoint file you obtained from training (.ckpt-10000-etc....) to make a script (python preferably) to run inference and set the batch size to 1.

somewhere in your inference code, you need to save a checkpoint file ([saver.save](https://saver.save)(sess, ""./your\_inference\_checkpoint.ckpt"")).

after you have saved checkpoint file, freeze the model like you did it last time then it is done. 

you don't need to retrain your model.",1535354958.0
grimzorino,"Speaking of converting models to TFLite, which python/tensorflow are you using? I am struggling to make TOCO work to no avail, both on windows and linux. ",1535391810.0
MrAcurite,"Tensorflow is kinda weird. Ordinarily, when you code, what you're doing is giving the computer instructions. ""Do this. Then add x to y. Then print 'beep'. Then annex the Crimea."" and so on. With Tensorflow, you're not giving instructions as much as building a datapath, if that makes sense. In the same way that you can't really understand a car one gasket at a time, you can't understand Tensorflow one line at a time. You've really just gotta fuck around with it. Try changing around the activation functions, the number of layers, the output schema, whatever.",1535306715.0
RRumpleTeazzer,"There are different levels of abstraction. The mnist example is indeed awful, it teaches you nothing besides ""it does run"".

What it doesn't tell you, the tensorflow architecture is centered around the most important problem: you cannot program a GPU like you do a CPU. 

What you can do with a GPU (say you run CUDA): transfer memory blocks from cpu-ram to gpu-ram and vice versa. Schedule the GPU to perform a (massive parallel) operation (most often matrix multiplication) on its ram. Poll for completed operations. That's it.

So tensorflow is more of a compiler with a fancy preprocessor (python). It keeps track of the variables and operations you want to run, it manages this internally with its computational graph which you can interact with python. Nothing is computed here though. When you finaly ""run"" the graph, tensorflow creates the neccessary memory transfers, schedules the order of Cuda operations, and collects results.

The beauty still is the graph, it allows the GPU be simulated, or accessible elsewhere over network, or saved. It also keeps operations in a symbolic form, and can generate derivatives (heavily used in ML).",1535314125.0
TheOneRavenous,[http://www.deeplearningbook.org/contents/intro.html](http://www.deeplearningbook.org/contents/intro.html),1535937096.0
MrAcurite,"Personally, looking at Google's long-term corporate strategy, it's way too heavily focused on cloud-based computing. Google docs. Chromebooks. CoLab. It's all going towards ""Pay us to give us your data, and pay us to look at your data,"" with the end user never actually purchasing any capital for keeps. I don't support it, because it's going in a direction that I'm not comfortable with.",1535306006.0
kei_kuro,"I thought it was kind of slow to interface with. Was that just me? Recently, I have just been spinning up a pre-emptible VM and running jupyter notebooks on that. My current configurations goes about $0.12 / hour, and if I need to run longer jobs, I can turn off the preemptibility.",1535316901.0
arya_minus,"1) Limited Memory

2) 12 hour limit",1535293009.0
Garybake,"It's amazing. Maybe a way to upload data easier would help. Finally it's really simple to set up, something I'd happily pay for a more powerful instance to run on.",1535310805.0
Metabyte2,"We can't come up with your project idea and solution for you. Go practice, if you have more specific questions come back.",1535293128.0
Arkhaya,Go search for codelabs. It's Google's tutorial list. That might help you.,1535296833.0
TheNASAguy,"It's Really Cool of You guys to offer such a thing, Thanks on behalf of the Tensorflow community",1535273378.0
fernandocamargoti,"This seems cool, but how do you plan to make profit out of it?",1535244444.0
GoofAckYoorsElf,"I'm wondering how you (and others who offer such clusters as a service) deal with data privacy. I work at a company that does some big data deep learning stuff and we have to deal with an ethics committee that has very, very strict rules when it comes to data that is even remotely personal. Handing that data to an external company is just so much work that it takes longer to go through the bureaucratic process for using an external service provider than to just use what hardware we have locally available for model training. ",1535267684.0
arreu22,As a student training in a mediocre gaming rig. Thank you.,1535313753.0
jiwidi,"First of all thanks for this! but i have question., i'm trying to launch a job but al tensorlets are busy, is this normal? or probably overload with the reddit post.",1535314141.0
amuchand47,Thankyou so much. Definitely It will help people .,1535251554.0
dfcHeadChair,"This would be ""supervised"" learning and it is only one branch of machine learning. There is also ""unsupervised"" learning such as KMeans. 

Using tensorflow for something like this may be overkill for what you're looking to do. I would look into XGBoost and LightGBM if you want to get into heavier algorithms. ",1535233464.0
RRumpleTeazzer,"In principle you start by some model f(x, m), where m are model parameters and f is a suitable function where you hope it will cover most features of the data.
You then minimize some objective function, e.g. u(m) = <|f(xi, m) - yi|^2>, where <> is an average over your training data pairs (xi,yi).
At minimum m0, you take f(x, m0) as your model solution.

Of course, the choice of f and u as well as the numerical minimization scheme is the difficult part, while getting representative training data is usually the expensive part.",1535239020.0
ady_anr,"I'm facing the same problem. The problem is we only create placeholders for the weights between layers. The bias variables and the weights of the fully connected layers are set automatically by tensorflow. Even if i wanted these variables, after training, i cant save then because i dont even know what they are called. I asked a bunch of people and it seems you can save the graph along with all of the saved parameters and load the graph when needed so as to run forv prop and make predictions.",1535375810.0
akmaki,"You can just session.run all the trainable variables and get them in numpy. There is a TF function to get all of them. 

Although for any variables management, you want to be using checkpoints. You can load checkpoints into subgraphs, etc. ",1535866234.0
R3ddit_Is_Trash,"This is really funny, and neat.",1535144836.0
Arkhaya,"First, what kind of data set are you working with, numbers, images?

Second, there is always a way to split the train and test dataset. I don't think you need to create individual batches. You can. To a train-test split and make it take in the data in batches of 10 or whichever no. Suits you best.

And, this is my opinion, don't care about the training accuracy because that is validated by the validation you do after the the training.

Because you train the model to be better with the training split that you have made. That's a really useful when the model is relearning. 
So to accurately measure how good your model is at the end look at the cross-entropy loss for both split and then make a validation test set to test how your model handles itself. If you get good accuracy, then it's fine. ",1535124447.0
sd_glokta,"Please tell us what errors you're getting when you run **pip install tensorflow**. Also, please mention which version of Python you've installed on your system.",1535104525.0
Rebbit_and_birb,Alternatively to pip you could use conda. It's easier imo,1535114140.0
jambez001,install Anaconda,1535115704.0
insulanus,What a great end-to-end test. You are flippin' awesome.,1535071900.0
teidenzero,"This is beaitiful, and your lab / room makes me jealous in a really nice way.",1535137033.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/deeplearning] [Looking to retrain tensorflow inception resnet v3 on animated GIFs.](https://www.reddit.com/r/deeplearning/comments/99ali1/looking_to_retrain_tensorflow_inception_resnet_v3/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1534915164.0
Dragon-Lord365,"Use tflearn, it's very easy to use and has a great image preloader, just place all the images of a class into a class named folder and give the root directory  and set categorical labels to true. Tflearn already has alexnet, resnet, inception and more in examples",1534874329.0
sd_glokta,"Before you can pass data to a CNN, you need to package the data in a tensor. To create a tensor from JPEG data, you need to call `tf.image.decode_jpeg`. This code gives an idea of how it's used:

    queue = tf.train.string_input_producer([""baybayin.jpg""])
    reader = tf.WholeFileReader()
    _, jpeg_data = reader.read(queue)
    img_tensor = tf.image.decode_jpeg(jpeg_data)",1534843004.0
Jonas_SV,One approach is to read the images with OpenCV or Pillow. Then pass the raw pixel data through a placeholder :),1534861598.0
Arkhaya,Go try the tensorflow for poets tutorial. It will help you learn how it all works and allow you to train your own dataset on a pre-trained model.,1534864339.0
Dragon-Lord365,"You can use the tflearn image preloader, pretty straightforward and easy to use",1534873768.0
slashcom,Looks like your loss isn't changing. Check your learning rate.,1534782057.0
truthseeker1990,"Like the other guy said, the learning guy should at least be moving around a bit even if its stuck in a valley. Something seems off.",1534783872.0
drsxr,That’s non convergence.  If you see that after the 20th epoch it’s never going to improve.  Check your code & libraries.,1534785910.0
ket0ma,apart from the learning rate you cxould check your regularization adding or deleting some of it could help,1534786595.0
Alliat,"The tutorial estimates I should be getting around 80% accuracy in only five passes, but as can be seen above,  I'm only getting around 20%.",1534781408.0
nikniuq,Maybe post your code? Something is wrong and that tutorial worked fine for me.,1534993433.0
CheML,You need to post at least a minimal working example of your code. It's too hard to tell what the problem is by very general descriptions like this. Also posting the error traceback when it fails would be helpful too.,1534770226.0
GChe,This may help you: https://www.quora.com/How-exactly-does-neural-network-batch-training-happen-on-a-GPU-Does-the-network-get-replicated-batch_size-times-and-the-replicated-nets-do-forward-and-backward-passes-in-parallel-with-some-shared-parameters-stored,1534816452.0
nigamelastic,wow thats awesome,1534700078.0
tlkh,"Yeah, TensorFlow doesn’t automatically run the training on all GPUs, you need to write code that informs TensorFlow how it is supposed to distribute the training. 

Also, you can try nvtop to see GPU usage in a prettier format ",1534641066.0
,[deleted],1534635149.0
drsxr,"Yup, you didn't institute multi-gpu.  Just check the wattage in nvidia-smi.  If you are idling at 17 watts, you're not doing anything.  When you are using both GPU's you'll be pulling >100W with each more or less.  Check nvidia-smi a few times during your run.

As per the TF Docs:

>If you would like to run TensorFlow on multiple GPUs, you can construct your model in a multi-tower fashion where each tower is assigned to a different GPU. For example:  
>  
>  
>  
># Creates a graph.  
c = \[\]  
for d in \['/device:GPU:2', '/device:GPU:3'\]:  
 with tf.device(d):  
    a = tf.constant(\[1.0, 2.0, 3.0, 4.0, 5.0, 6.0\], shape=\[2, 3\])  
    b = tf.constant(\[1.0, 2.0, 3.0, 4.0, 5.0, 6.0\], shape=\[3, 2\])  
    c.append(tf.matmul(a, b))  
with tf.device('/cpu:0'):  
  sum = tf.add\_n(c)  
# Creates a session with log\_device\_placement set to True.  
sess = tf.Session(config=tf.ConfigProto(log\_device\_placement=True))  
# Runs the op.  
print([sess.run](https://sess.run)(sum))  


Keras' implementation of multi-GPU is a bit easier but wonky post 2.1.3 IMHO.",1534647863.0
clarle,"You can do it in pure Python, and then use `tf.convert_to_tensor`.

    import tensorflow as tf

    array = [num for num in range(5) for reps in range(3)]
    # [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]

    tensor = tf.convert_to_tensor(array)",1534608307.0
kei_kuro,"I'm not sure if you can call this ""elegant"", but here's one way to do it:

    import tensorflow as tf
    import numpy as np
    
    N = 10
    rep = 3
    
    arr = np.arange(N)
    # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    
    arr = np.tile(arr, (rep, 1)).T
    # [[0, 0, 0], [1, 1, 1], ..., [9, 9, 9]]
    
    arr = arr.flatten()
    # [0, 0, 0, 1, 1, 1, ..., 9, 9, 9]
    
    tensor = tf.convert_to_tensor(arr)",1534611033.0
RRumpleTeazzer,"Get tensor [0,1,2,3,...] and an outer product to [1,1,1]. You end up with [[0,0,0], [1,1,1],...]. Then simply flatten.",1534624567.0
doktorneergaard,"What is it about the output that you think is incorrect?

For the record, it looks alright to me. The first part of the output tells you that you could gain some performance boosts by compiling TF from source, but I don’t know how large a boost that is. Next part just tells you that it has found a GPU and gives you info on that and how it can communicate, and the last part is your output hello world. The ‘b’ character in front of the string tells you that it is in bytecode, if you want a ‘regular’ string, you can do

    print(sess.run(hello).decode())",1534536068.0
Vamshi_Goud,"Try this [Tutorial](https://www.youtube.com/watch?v=yX8KuPZCAMo&t=216s), Great explanation... ",1535268761.0
nikniuq,There is an environment variable that can suppress the info prints if you need.,1534993872.0
Arkhaya,"It's fine. It's all correct. Don't worry. I can see you are using TF GPU. That's why there is a lot of stuff with the cuda etc. 

But it's fine, it printed b'Hello World'",1534549705.0
Metabyte2,"Its a soft warning about the resources tf is using. Youre good, especially if youre not using it professionally.",1534562209.0
kei_kuro,Hvass Labs has a great YouTube series with Jupyter Notebooks. That was a really good resource for me to understand the basics. [https://www.youtube.com/watch?v=wuo4JdG3SvU](https://www.youtube.com/watch?v=wuo4JdG3SvU) ,1534525813.0
WrinkledTime,"The Google ones are very good

[https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)

And Tensorflow for Poets is a great starting place

[https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0)",1534526128.0
ReactDOM,See if you find some of the [Tensorflow tutorials](https://reactdom.com/tensorflow) useful. ,1535403274.0
Arkhaya,I can't completely diagnose your problem but I would uninstall everything related to TF. And then I'll install anaconda on path as well. Then pip install tensorflow and see if it works.,1534518857.0
sd_glokta,The msvcp140.dll library is part of Microsoft's Visual C++ Redistributable. You can download it directly from [Microsoft](https://www.microsoft.com/en-us/download/details.aspx?id=48145).,1534519364.0
sd_glokta,"Are you sure you installed the 64-bit version of CUDA 9.0?

If you did, are you sure the directory containing cudart64\_90.dll is named in the PATH variable?",1534475221.0
pm_me_your_403b,"Sounds interesting, do you have any more details?",1534467988.0
vipercmd,You may want to look at [https://www.deeplearning.ai/](https://www.deeplearning.ai/) and complete all five specialisations.  The fifth specialisation explores sequence models and you get to define a model to create a Jazz improvisation.,1534477274.0
nikniuq,Have you looked at magenta?,1534993910.0
MannyManifesto,Nice Demo.,1534439783.0
nigamelastic,awesome,1534492427.0
Metabyte2,S S S SPAM! Enjoy your ban!,1534411242.0
ME_PhD,"Follow the tutorials the same except make your own function for producing (x,y) batches. x is an array of a bunch of images (height, width, 3 <- if color image, batch_size) and y is just one-hot labels (you can do it by chopping rows out of an identity matrix or any other way.",1534311836.0
Beazlebubba,"Have you tried looking into the omniglot dataset?
https://github.com/brendenlake/omniglot",1534310654.0
Arkhaya,"Making is going to be really hard and tough. You can maybe look at retraining already built models.

But if you really want to make the network yourself you can research more into learning how weights, biases, placeholders are coded in tensorflow and maybe that way it could be easier.",1534315153.0
WrinkledTime,"Tensorflow is fantastic at re-creating popular networks. Make any changes and it rapidly turns into a nightmare.

I'd recreate the MNIST example, then make adjustments so it'll handle the size of your data. I've often had to go layer by layer but I've found it the fastest way to do it.",1534343520.0
The_Kraken-Released,"Do you have everything working in MNIST and want to move to your character set? Or are you trying to learn on your character set? If you don't have MNIST working, I recommend learning on it before moving over.",1534442872.0
WrinkledTime,"That's not a lot of data for a CNN

You might try using 'data augmentation' to build up your data set size.

It's just a fancy term for taking your images and skewing, noising, rotating and otherwise slightly altering copies ",1534292566.0
Maciekism,"I figured out a solution but it is pretty useless to me since it hinders performance by a lot.

I can almost half the time by executing [sess.run](https://sess.run) on each of the matmul operation and then converting to list.

The solution uses tf.map\_fn if anyone is interested though

`import tensorflow as tfthree = tf.constant(3, shape=[1,1])two = tf.constant(2, shape=[1,1])one = tf.constant(1, shape=[1,1])four = tf.constant(4, shape=[1,1])list_a = [three, three]list_b = [two, four]list_c = [one, three]`

`result_a = tf.matmul(list_a, list_b)result_b = tf.matmul(list_a, list_c)`

    result_c = tf.map_fn(lambda x: tf.matmul(x[0], x[1]), elems=[result_a, result_b], dtype=tf.float32)

`with tf.Session() as sess:sess.run(tf.global_variables_initializer())print(sess.run(result_c))`",1534337199.0
PM_ME_UR_MASTER_PLAN,"Have you investigated the memory allocating using tf.GPUOptions? I used to have a similar problem before I set allow_growth to True

https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory",1534190715.0
cosmic_dozen,"OP here. This is an art-project-in-progress, so I welcome any feedback! If you get some time, you should all definitely play with the [Lucid](https://github.com/tensorflow/lucid) library, it's awesome!

The goal was to visualize the movement between layers of a neural network set to music. While Lucid makes beautiful images, independently training and interpolating between them leaves the animation disjointed. This is because the locally minimized regions of the CPPN are far from each other for each sample. The trick was to reuse the initial coordinates from the previous model to train the next. This provides continuity to train one image into another.  


Code: r/https://github.com/thoppe/DeepMDMA",1534180828.0
TheWolfOfTheNorth,Great article!,1533996064.0
sd_glokta,"I've never analyzed a YouTube video, but if you're interested in image recognition, you'll find a number of tutorials that explain how to analyze the MNIST and CIFAR datasets. The MNIST dataset contains grayscale images of handwritten digits (0-9) and the CIFAR dataset contains RGB images of different types of objects.",1533906467.0
SlothyJoe,"You don't really need tensorflow to really do this. You just have to get the video frame by frame, and from there compare it pixel wise to the thumbnail of the same resolution. You could do it as a % type thing, so if thumbnail >=90% similar to 1 frame of the video = not clickbait",1533927512.0
janixwow,"It's a really complex problem with ML.   


\- With traditional way you can check every frame in the video and if some part of the video (24-48 frames in row) has 60-80% match with the thumbnail it can be a good sign.  


\- With ML at first you need to recognise some part on the thumbnail like a Face,Animal,Object,Logo etc. and then looking after them every screen and if you find them matching them. For this you need a really extense system.  
",1533916543.0
roaming_bear,Doesn't really seem like a machine learning problem ,1533927786.0
supercyberlurker,"Something like that might be more simply implemented as a histograph of images. Compare against those histographs and if similar enough, mark as clickbait.",1533930917.0
uksspy,"You could look at it as a classification problem. Given a video and a thumbnail, decide if it is clickbait or not. You would need to gather a lot of labeled data for that approach, but the rest of the implementation would be quite straightforward. ",1533937096.0
grcodeman,Looking forward to more generations,1533849259.0
Mabb_reddit,"It works in all games? Like PKM GO, old GameBoy games? Or only in a specific drawing style?",1533883882.0
bharddwaj,is there a way i can see your neural network code? I can't seem to find it on your github,1533954088.0
clarle,"Line 253, inside of `load_weights` - `self.parameters` is being passed into `sess.run`, which starts the [TensorFlow execution flow](https://www.tensorflow.org/guide/graphs#using_tfsessionrun_to_execute_operations) and initializes the network architecture into the session.

If you look at the main method, the session is reused when evaluating the network on test data. ",1533840553.0
txrxfx,Appreciate the affiliate discount but interested in what folks make of this Udemy course. ,1533818785.0
roo00oo00oo,"Look into existing CNN architectures like VGG16, resnet, SSD etc.. good depends on what you are trying to do.",1533805251.0
0rsinium,Wow! Thank you. It's what I try to find whole last week.,1533723335.0
tektektektektek,"Trying to predict the sharemarket is a fool's errand. And the reason why comes down to basic engineering theory under the heading ""[control theory](https://en.wikipedia.org/wiki/Control_theory)"".

Basically everybody is trying to second-, third-, fourth-, and so-forth, guess each other. Short-term trading is a zero-sum game. Thus if somebody else can guess your behaviour they will take action to maximise profit by altering their behaviour - and you will do the same thing.

Sure - there are biases involved - and if you fed in enough data - such as news feeds and weather data to take account of emotional responses - then you could approximate what the average punter might try and do.

But the risk is that someone else does something *unpredictable*. And, thanks to the [butterfly effect](https://en.wikipedia.org/wiki/Butterfly_effect), that could have enormous ramifications.",1533692991.0
MrAcurite,"I feel like ML + Crypto is a great way to get tons of eager investors, and then lose all their money.",1533590016.0
janixwow,"Unfortunately make any long time crypto asset which can overperform significantly BTC is impossible. It is the base theory of modern portfolio investment, you should make your portfolio more diversified on other markets like SP500...  
",1533676249.0
alkasm,"Presumably, it's the average error in the validation set. Remember that validation is not used for training; it's a dataset that you use to measure how well the model is performing on data it hasn't seen yet. So training loss is used on the training set to tell the model how to take the next step through back propagation and so on. Validation error is a measure of how well the model is doing categorizing data it has not been trained on.",1533573565.0
Nytra,https://en.m.wikipedia.org/wiki/Mean_absolute_error,1534128188.0
jojek,It’s too old. The CUDA Compute Capability is too low.,1533539430.0
RRumpleTeazzer,"In the end you want to run your TF graphs on you GPU. Python is essentially a C wrapper, while JavaScript is not. Take a guess which one gives you access to your GPU.",1533529390.0
Metabyte2,"Stick with python, especially if you don't want to laboriously build every model. TF is heavily developed for python and it's more of an afterthought in other languages.",1533509214.0
ootsby,"The APIs are very similar. I would warn that the Javascript implementation runs via WebGL as of time of writing and has a potentially large performance hit compared to Python. 

With this in mind I'd say it's only really suitable for deploying pre-trained models to browser apps or for initial studying and toy problem solving in Machine Learning and not for building and training large models. Those uses are a big chunk of what people use Tensorflow for though so it's still a great project, particularly if you're familiar with JS and just want to ""have a look at this AI stuff"". ",1533544979.0
cinnamon_oat_squares,"Very similar, especially at the tfjs layers/keras abstraction level. ",1533510643.0
xtan,almost identical and designed to be compatible.,1533520222.0
Visual-mov,Nice videos! Keep it up!,1533686698.0
elslooo,"Try:
 
```
scale = tf.Variable(np.ones(4), dtype=tf.float32)
loc = tf.Variable(np.zeros(4), dtype=tf.float32)
samples = tf.distributions.Normal(loc=loc, scale=scale)
sample = samples.sample()

# ...

for j in range(i):
    sess.run(sample)
```

The reason your code slows down is because you're adding a new operation (the sample) to the graph in each iteration. A good idea is to freeze your graph before any for loop: that way you get an error if you accidentally add operations to your graph in the for loop.",1533401965.0
Category_theory,"There are a lot of other frameworks you could use for this problem, scikit learn being the obvious Python choice, that have built in time-series algorithms.  Why TF then?",1533350535.0
Brudaks,"If you're doing time series prediction, then ""ys"" inevitably is an array containing the predicted values. ""xs"" may vary depending on context - it may consist on all kinds of relevant features, but it may be that it's just the exact same array offset by 1.

E.g. xs[0] is the first known value of the sequence, and both ys[0] and xs[1] is the second value in that sequence. In that manner you're attempting to learn how to go from Nth value to the N+1st value, taking into account (through RNN) all the history as well.",1533340350.0
Maleficus187,"This easiest way? I don’t think so. I’ve installed CUDA on 14.04, 16.04, and 18.04 many times. Always has been easy to install on all three versions.

Install the Nvidia driver from the graphics-driver ppa.

Download the CUDA run file and run it, select no when it asks you if you want to install the driver.

Download cuDNN. Move the library files into the right location inside the cuda directory, and chmod a+r all those cuDNN files.

pip install tensorflow-gpu. Done.

I’ve done this on my laptop both running 16.04 and 18.04, and multiple desktops at work running 16.04 and 18.04. I don’t get why some find it so hard.",1533246964.0
Notjeffjeff,Thank you for posting this.  I've been trying to figure this out for a while now. ,1533269765.0
shyrzaza,"To clarify, this is my model until the prediction:

  
    num_labels = 3
        if (mode != tf.estimator.ModeKeys.PREDICT):
            labels = self.reshape_labels(labels)

        # Input layer
        input = self.getInputTensors3D(features, labels)

        splitted_data = tf.unstack(input, axis=1)

        # RNN Layer
        cell = tf.nn.rnn_cell.BasicLSTMCell(self.num_hidden_units)
        outputs, current_state = tf.nn.static_rnn(cell, splitted_data, dtype=tf.float32)
        output = outputs[-1]


        w_softmax = tf.Variable(tf.truncated_normal([self.num_hidden_units, num_labels]))
        b_softmax = tf.Variable(tf.random_normal([num_labels]))


        logits = tf.matmul(output, w_softmax) + b_softmax
        # logits = self.reshape_logits(logits)


        # Predicitions
        predictions = {
            # Generate predictions (for PREDICT and EVAL mode)
            ""classes"": tf.argmax(input=logits, axis=1),
            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the
            # `logging_hook`.
            ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")
        }

        if mode == tf.estimator.ModeKeys.PREDICT:
            return tf.estimator.EstimatorSpec(mode=mode,
    predictions=predictions)",1533201626.0
gavinfernandes2012,"The actual computations done in tensorflow, is done by the part of it that's written in C++, CUDA for GPU's and Intel MKL ops for Intel CPUs from what I remember. All of these languages provide some form of parallelism or multi-threading, which allows tensorflow operations to execute simultaneously.

The python side of tensorflow we see is just an interface, an API that creates your model/computation graph and sends it to the natively compiled part of tensorflow for execution.


Tl;Dr Tensorflow is written in Python, C++, CUDA and MKL, and hence can use and (is already written to use) parallelism.",1533196949.0
whirl_and_twist,"well, I just downloaded python 3.6 and tried to install TF with pip, no success again. I'll use anaconda and report back",1533170662.0
Maleficus187,"A simple way to do this would be to feed in two placeholders, where one of them is 1.0 and the other is 0.0. Then multiply each loss function by one of the placeholders and sum them up. The placeholders are just used to zero out the loss function you don’t want this iteration and keep the other.",1533076737.0
cr7__FTW,https://www.tensorflow.org/api_docs/cc/group/math-ops,1533064290.0
heap42,"I ""came up"" with this code, but this does not run and throws and exception: https://pastebin.com/FXGp5huk",1533074816.0
cr7__FTW,"> inds = np.random.randint(0, 479, (batch_size))

inds = np.random.randint(0, 478, (batch_size)) #change 1

> x_b[:,i,0] = x[ind:ind+nb_steps]

x_b[:,i,0] = y[ind:ind+nb_steps] #change 2

y_b[i \* nb_steps:(i+1)\*nb_steps,0] = y[ind+1:ind+nb_steps+1]#let it be as is

I think you should consider the fact that you don't need the x values to approximate the function x\*sin(x) + 2\*sin(5\*x)

You just have to feed the LSTM {x:previous sequence token, y:next token(targets)} token to make it learn next sequence token.

Having said that I don't think you should use LSTMs for this function approximation task. You can use a simpler perceptron.
",1533043801.0
fflores97,Not natively. TF for GPUs currently works on CUDA which is nVidia software and hardware. I can see other computing APIs becoming useful and popular in the near future though,1533059103.0
cranq,"There is work ongoing to Port TF to opencl:
https://stackoverflow.com/questions/43670292/does-google-tensorflow-support-opencl

",1533037957.0
gavinfernandes2012,"[This](https://github.com/tensorflow/tensorflow/issues/22) might be interesting to you, specifically the 4th last post. I haven't tried it myself.

I personally have an unsupported Nvidia card, but an intel CPU and a linux machine, so I built tensorflow with intel MKL support and I get the same performance with lower CPU usage (yeah I don't know what's the deal with that, but I'll take it). ",1533202568.0
grandoldmikaduki,"If You have a AIB w/ Vega or Polaris arch, Worth trying Radeon groups branch.

It works on Linux only, but IMO it is very easy to install.

[(Link: How to install Radeon GPGPU platform called ROCm)](https://github.com/RadeonOpenCompute/ROCm)

[(Repo of Radeon Open Compute branch)](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream)

and, it also provides prebuilt binary .

[(Link of pypi )](https://pypi.org/project/tensorflow-rocm/)",1534514633.0
serbotec,"For my project I used this example 

[https://github.com/sourcedexter/tfClassifier/tree/master/text\_classification](https://github.com/sourcedexter/tfClassifier/tree/master/text_classification) 

Concept of the project was:

\- build a neuronal network model that will be trained with huge amounts of song lyrics

\- You can choose a playlist of which you want the tracks to be categorised (Spotify)

\- the trained model takes the songs with the help of an API, scrapes theirs lyrics, predicts its category and allocates the songs to the Spotify Playlists automatically",1533027205.0
LilShotaBoy,"The low ram might be a problem, all the data needs To go the ram/Vram so upgrading ram would be good.",1532959783.0
gaiusm,What about the cpu? ,1532987249.0
ajmssc,Can you share your code and data? And also what gpu are you using?,1532938065.0
iamrndm,"Try, disabling and then re-enabling your GPU. 
",1532969315.0
sebchris,"No, I wouldn't think so. It would be easier to just use a traditional programmatic approach. The trouble here is that you would either need a model that was already trained to identify these shaded boxes in your questionnaire, or you would need to train it on your own questionnaires. Depending on how many questionnaires you're going to be giving out, this may be pointless as it would require manually checking which boxes were shaded for hundreds (if not thousands) of questionnaires in order to train it just to be able ask it to check the rest of the questionnaires.",1532925532.0
mlkrun,"I'm very fascinated about tf.js especially with the fact that it can be used with UI frameworks . However I have no idea what kinds of problems should tf.js solve in browser.  How can I implement linear/polynomial regression or categorization... so that with combination with let's say React , I can achieve some good user experience ?

I understand that categorization can be used in drag and drop images and so on but I'm looking for solutions which are kind of new, sophisticated, overwhelming and can solve problems in a new manner.
I would be thankful for any suggestions

Thanks for post.",1532876677.0
k9thedog,"If you have a pretrained a model with a fully connected layer on top, drop it and replace it with one more convolutional layer with a 3x3 kernel and the same number of features as you have categories. Top it with a global pooling layer to remove the spatial dimension. Now freeze all the old, pretrained layers and train only your new convolutional layer on your dataset. 

After it more or less trains (this is serious science, we use words like ""more or less"" here), visualize the output of the convolutional layer you added, on the feature channel corresponding to motorbike. You should see a blob where the motorbike is.

If for whatever reason you don't want or can't re-train even the one convolutional layer, google CAM (Class Activation Mapping) on how to get the heatmap without any retraining.

Hack (from my experience): if the last convolutional layer's activation function is a softmax (on the feature axis), it will converge faster and you'll get nice heatmaps. Softmax will force the network to assign only one category per pixel.",1532861531.0
sebchris,"So basically it is a classification problem. The data points consist of positions and numbers (which are represented as colors on a gradient, with -1 represented as orange and +1 represented as blue). The idea is that, although we already know the numbers associated with the positions of the input data, how could we create a function that would classify new data? If we were given a position on the grid, what color should it be? The neural network is trying to answer that question, and it does that feeding each input data point's position into its network and getting an output for its predicted color. The output in the beginning is basically random, so the points that should be predicted to be blue are predicted as orange, or somewhere in between. However, it uses the difference between what the output should be and what it actually is to change the network. Basically, it takes the degree to which the input was misclassified to change the network.

The network is built up of neurons which are just cells that can hold real number values, called activations. The neurons are connected using weights, which are just real numbers, and each neuron also has an associated bias, also just a real number. The way that an output is produced based on an input is by using the input values (real numbers) to activate the neurons in the first ""hidden layer"" of the network. In a fully-connected neural network like the one in the example, each input value is multiplied by the weight (shown as a line) connecting it to a neuron in the first layer. These values are computed for each of the inputs that the neuron is connected to, and then the sum of these values plus the neuron's bias becomes the neuron's value or activation. This is done for all the neurons in the first hidden layer, then the process repeats for the neuron's in the second hidden layer, except that now the ""input"" layer is the first hidden layer. So on and so forth until the last layer, the output layer, has all of its neurons activated. In this example, the output layer just consists of one neuron and that neurons value (between -1 and +1) is the color that the network predicts that the given position should be associated with. Depending on the values of the weights and biases, these predictions can be anywhere from perfect to useless - given random weights and biases they will almost always be hopeless.

So, how do we find the right weights and biases? This is the core of deep learning and it's not an easy question to answer. The typical way is to use a method called Stochastic Gradient Descent with backward propagation in order to find the optimal weights and biases. I assume that's what's used here, and it basically amounts to some Linear Algebra and Multivariable Calculus. The important thing is that once the network is ""trained"", that is it has ""learned"" the correct weight and biases, then it can classify points outside of the data set used to train it and create a picture that is shown after you hit the Play button in the example. Each point that is not highlighted is a prediction from the network and it shows that the network has learned certain boundaries for areas that should include blue points and areas that should include orange points. This is the essence of deep learning and machine learning in general: Take data and use it to learn how to handle situations outside that data set.",1532813379.0
jameschee,It is just x and y axis. The color represents z-axis. I believe blue is 1 and red is -1... I might be wrong. If anyone has a better answer or see something to correct I am welcome.,1532779859.0
tejan24,"Blogs like dataaspirant, medium and the most important one ‘machine learning mastery’ and lastly search logistic regression on kaggle You’ll find a bunch of them",1532751203.0
ManHuman,"Dogs vs Cats:

[https://www.kaggle.com/c/dogs-vs-cats](https://www.kaggle.com/c/dogs-vs-cats)

Chihuahua vs Muffin:

[https://medium.freecodecamp.org/chihuahua-or-muffin-my-search-for-the-best-computer-vision-api-cbda4d6b425d](https://medium.freecodecamp.org/chihuahua-or-muffin-my-search-for-the-best-computer-vision-api-cbda4d6b425d)",1532394653.0
FaceDetector,"You can use IMDB-WIKI dataset for boy/girl classification:

[https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)

Datasets with animals:

Stanford Dogs Dataset:

[http://vision.stanford.edu/aditya86/ImageNetDogs/](http://vision.stanford.edu/aditya86/ImageNetDogs/)

Caltech-UCSD Birds 200:

[http://www.vision.caltech.edu/visipedia/CUB-200.html](http://www.vision.caltech.edu/visipedia/CUB-200.html)",1532412258.0
LilShotaBoy,If you are using tensorflow the mnist dataset is great. It is a dataset of hand written duvets from 0 to 9.,1532548199.0
Supermaxman1,"I believe this happens when the code is running a session profiler and your CUDA path is not set properly. See this thread: 

https://github.com/tensorflow/tensorflow/issues/17101

TL;DR: make sure “C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin” is in your path variable and that the “cudart64_90.dll” is in that folder.",1532306599.0
b3by,"I always compile tensorflow from source code, then install it in a virtual environment. Same goes for the GPU version. The benefits of that are that you have the package tailored to your system with the source compilation, and a minimum of system isolation with the virtual environment. On the other side of course, this takes time, and a lot of fidgeting around.
I don't really like anaconda, can't really say what's the hype about it. So far, pipenv is all I need!",1532331099.0
wild_thunder,"* Docker - reproducible environment for better portability between machines.
* Pip - basic install, easy to do.
* Anaconda and VM - isolated python packages to prevent dependency conflicts between different projects. Anaconda seems to make windows installs easier, although works in other OSes as well.

I use the VM install personally because it's a nice balance of isolation of my dependencies and ease of setting things up. Anaconda looks good, I'm just used to virtualenv",1532321739.0
RRumpleTeazzer,"You probably alternate between two different networks, yet report to the same logging object.",1532284439.0
Supermaxman1,"Perhaps try placing the update op in a tf.control_dependencies scope to ensure the random update happens before the agent update?

See: https://www.tensorflow.org/api_docs/python/tf/control_dependencies",1532307231.0
,[deleted],1532242926.0
wild_thunder,"I'm not sure if the issue is with your keep_prob or your architecture. Dropout can certainly decrease your accuracy though, especially on your training data. You should see an increase in test accuracy though since it makes your model more generalizable and robust.

As an aside, check out Google Collab notebooks for free GPU training in an online jupyter notebook editor. CIFAR 10 should train much faster there.",1532234225.0
aakova,"Just a guess based on /u/wild_thunder's mention of ""randomly guesses the class"", but I'd take a look at a couple of examples of 'data' before and after calling 'clean(data)', to ensure that there's something useful there after the call.",1532293242.0
iRecognize,"Do you mean training accuracy drops or testing accuracy?

> But when I add a dropout in a dense layer, the training accuracy decreases to around 12%(60->12%...?) 

Dropout layer helps avoid local minima as well as stopping overfitting, among other things. I'd suggest save weights from previous run and then initialize weights to those values when you retrain with dropout. 

On a cursory glance, I do not see a validation dataset in your code. Training and evaluating on different parts of the available data may help you not overfit ie not get 100% training accuracy but only 60% testing accuracy. You may not need dropout at all. 

Do let me know if I am wrong.",1533297870.0
Maleficus187,It depends on your loss function. It seems you have two separate networks with two separate outputs? Do you add the loss function for each one together? Or are the two outputs combined somehow before applying your loss function? What size are your outputs exactly from each network?,1532198521.0
jadore801120,So you are looking for a way to decoupling the data input pipeline with the training operation? The FIFOQueue is not enough for you? ,1532112094.0
RRumpleTeazzer,Without thinking I would use a fixed binary vector only containing 0 or 1 in tf.float32 alongside every weight vector you will use in your model. Numerical gradients of unused weights might probably still contribute to training time. Depends on the model size if a model rebuild is cheaper....,1532106047.0
rigabigadiga,"you can reshape the data with the width as the innder dimension, run conv1d, reshape back to 2d, transpose to get height as the inner dimension, reshape to lower dimensionality, run conv1d again, reshape, transpose.

or you could use tf.layers.conv2d with a kernel_size of [1, x] and again with kernel_size of [x, 1]",1531861861.0
omgitsjo,Neat!  Thanks!,1531922024.0
xtan,"Begin with this example.  Play with it and see if you can get it to work with your data.
https://github.com/tensorflow/tfjs-examples/tree/master/addition-rnn",1531880113.0
CognitiveDiagonal,"You could store the value of `get_next` in a variable, use it in the `feed_dict` until you want to move on, and then repeat the process.",1531764826.0
cr7__FTW,"you need to add an extra projection on top of your current network to match the training data's dimensions or modify your current FC layer to match [,1960,1]",1531748080.0
Berlinsk,"Since this is an example used in a tutorial video and posted on GitHub, I'm assuming that the code was run and worked before it was posted, so since I can't seem to get rid of the errors I'm starting to suspect that the problem might be elsewhere.

Are there any known issues with tf.js with respect to node versions, GPUs, operating systems etc?

I'm working on an older macbook pro 13"", running npm v  6.1.0

I know that this integrated GPU is not so friendly to CUDA and the likes. Can I force CPU calculation to test that theory?",1531749272.0
Maleficus187,"Not sure what the issue is, but have you tried loading and just evaluating on your train or test set to see what the accuracy is without continuing to train? Would be easier for you to debug it this way.",1531683066.0
stealthx9,"So it turned our the issue was in the creation of the training data. I used a scaler which I dumbed to the disk, an when creating my traindata out of a pandas dataframe there was a issue with the column order. So my scaler messed up the new column.

The code I posted above should be fine :). Maybe somebody can use it. ",1531945953.0
AusCro,If you need more info let me know,1531631623.0
EthanPhan,Maybe you can just download the file manually,1531635736.0
RRumpleTeazzer,"The problems is, for each x you would need to do a lookup through your training data to get y. This is slow of course.

Try to reorganize your data flow. My guess if you use x along already, drag y with it, then
f(m_i, x,y) = y, m_i+1is trivial.

",1531643874.0
throwaway775849,"there's a method like ""initialize_state"" where you give it a c_state and h_state in a tuple",1531554378.0
MrAcurite,"I think the interesting part of this would be using GPU acceleration for the parallelized workload. If you could find some way to translate your game into a form of Linear Algebra, that would get you along beautifully. What year of schooling are you in? ",1531403484.0
gionnelles,"It sounds like you are describing agent-based simulation which unless your agents require trained behaviors, TF and deep learning is not suitable for. Lots of ways to slice agent based simulations, but I'd look up that field for the next step.",1531446851.0
rigabigadiga,"I use tensorflow for image processing as well as deep learning. The main advantage is that I can do low-level operations while taking advantage of GPU acceleration and NOT learning anything new. It is the right level of abstraction for me. I would hate to have to program in CUDA.

It is a huge framework and is developed for more than deep learning (Although I haven't seen anyone use it like a game-engine). I'd recommend eager mode as it feels more like regular programming and you can go in and out of tensorflow on-the-fly. That said, most deep learning frameworks [don't support OpenCL](https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software)
So you may be stuck simulating on nvidia graphics cards (or on CPU).

That said, I've wanted to build an economy simulator for a while. My main goal is like a city sim except without mandatory interaction, just some hyperparameters for the agents and resources. Of course, I'd also like to hop in the game and interfere. 

I used Unity for a while for the rendering, path-finding, and ability to export to different platforms. I wonder if you could use both.
Would this project be public or private?",1531415812.0
CognitiveDiagonal,"I had the same problem. Use a placeholder to feed either *True* or *False* in the *feed\_dict* when training or validating.

    #Create placeholder
    is_training_holder = tf.placeholder(dtype=bool, name='is_training')
    
    #Create net
    net_fn, end_points =  resnet_v2.resnet_v2_50(X, ..., is_training=is_training_holder)
    
    #In each epoch
    ... = sess.run([train_op, ...],
                   feed_dict={is_training_holder: True})",1531569994.0
EthanPhan,Finally I found the bug. I was using the same LSTM cell for both layers of the decoder but they should be different. I will delete this post soon. Thanks everyone.,1531065668.0
theredknight,"If you're going to make a GUI from scratch, I recommend looking into the UI from Blender's node editor. If you could make it half way as useful / powerful as that, it would be amazing. You could also color code the outputs between things to take in: images, text, tensors, etc. 

Here is a tutorial example:
https://www.youtube.com/watch?v=f5Gb1VK98Wc&t=17:58",1530972189.0
select,What is the difference from tensorboard? ,1530965135.0
Jonas_SV,Have you looked into this.. https://azure.microsoft.com/sv-se/services/machine-learning-studio/ ? I believe it has similar functionalities ,1530980683.0
iamiamwhoami,What’s the masters in? It seems like a cool idea but I’ll voice the one objection I have with general GUI abstractions over programming languages. Who is going to use this? I feel like code is already an excellent abstraction over the underlying algorithms. What value does a GUI bring? You would still have to learn the underlying concepts and it’s usually easier to learn them through learning the code because there’s and established community and pedagogy for teaching them this way. A gui can be valuable because it can be easier to learn and use than the underlying code but will you actually get that advantage in this case? Not to say you shouldn’t do it but I think these are important questions for you to answer. ,1530983221.0
IdeasRealizer,"I had this idea once and even started the project (abandoned it for now).

Personally, I think, this is a good idea because it helps even those who are not comfortable with coding (children, others) to get into machine learning. It is also useful for people from other fields who have data but no experience with programming.

Even though I had the idea of reusing code from Blender's node editor, I postponed it to later part of the project. Initially, I wanted to make it look like MATLAB Simulink.

Now, the ideas that I wanted to implement

1. Code generation:

* learn from different repositories in [GitHub - Tensorflow](https://github.com/tensorflow) for quality code generation ideas.

1. GUI:

* automatic creation of blocks based on available functions or documentation
* ability to enclose connected blocks into a parent block
* colored nodes for recommended connections visualization
* on screen dimensions of matrices (useful for CNN, kernel size may change the output size)
* abitlity to attach summaries to any block
* lauch session by selecting node(s) to be computed
* launch tensorboard (to view summaries after a session is run)
* control variables which are shared with all blocks, modified globally: either user-created or default ones
* connector types
   * curly
   * rectanglular
   * ray
* 3d effect for nodes: to avoid confusion on overlap
* two way: graph to code, code to graph",1531036336.0
scmmishra,Looks like a good idea to me,1530956081.0
kite_and_code,"Why might you not need this?

Are you maybe just copy and pasting your code from other projects and therefore, don't write the graph code from scratch each time?",1530965944.0
Supermaxman1,"This is really useful, thanks! I’ve been training and using a separate word2vec model, and have been translating words to embeddings before sending those embeddings over the feed_dict. It worked fine for my small project, but as soon as I started to scale the performance was abysmal. Can’t wait to try this out!",1530936576.0
,[deleted],1530641856.0
hastor,One issue I'd have is that I'd have to know that I'm dealing with a reputable company.  Getting my models stolen is not worth it in order to save a few $.,1530657989.0
tlkh,"Hardware wise, I’m not sure how many PCIE lanes your 1080 Tis run off. If it’s less than X8 it could bottleneck the GPU. You’ll also need reasonable fast and large storage for the training data and checkpoints (think around typical SATA SSD speeds). 

I also hope your CPUs aren’t Celerons. i5 and above would be good. You’re also looking at 1 CPU per GPU, or per 2/4/6 GPUs you’re renting out. Each rental needs it’s own CPU (or core/thread, if you know how to provision that) 

If both of the above are met, your service could be attractive for students/hobbyists or small-time researchers! Here the main considerations is price and quality of access. 

Beat GCE’s hourly pricing for the P100 by around 10% and you could attract students or even smaller startups to use your service. With a 1080 Ti adequately cooled you could be offering slightly higher performance at slightly lower the cost. 

Quality of access means if I SSH in I don’t have to wait 2 seconds for a keypress to register. It’s really annoying. ",1530672898.0
MrAcurite,"I think the first one that was really looked at was far more general diagnostics. Plug in a ton of miscellaneous information about the patient, have it spit out a diagnosis.",1530627783.0
tamen,Finding tumors in scans is also being researched right now. ,1530618923.0
Maleficus187,There’s some research in trying to generate new drug candidates. Look into Vijay Pande’s work.,1530628981.0
TheNASAguy,check this out http://adityaimagingit.com/,1530672488.0
ScienceAndRock,"I find genetics a particularly interesting topic to throw some AI on. Our ""source code"" is on our genes, so whatever will happen to your health is coded somehow somewhere into your genetic code. It's currently impossible to decode it and understand it with our technology but we can treat it as a black box.

So,  imagine that some people responds very well to a given cancer treatment but some others gets even worst or dies when takes it. You can think of their genes as the black box and the pill as the input. If you, somehow, could predict the output, then you can run  a genetic profile test on your patient and give him a treatment based on that data.

You create a good AI system , put the genetic profile of your patients as the  dataset to study and an observed disease, response to a treatment or whatever you want to predict about their  health as the target output . I have a very strong feeling that many many things are gene-encoded and so patterns are there to be found and this may actually work.

Imagine in a future you go to a doctor with a set of sympthoms, he runs a genetic test , put that on an AI system and then he gets a probable diagnostic with the specific treatment he should administer, in an optimal calculated dosis,  a prognostic about your recuperation and , basically , all the stuff related to that disease that will happen in the future.",1531286283.0
watty_dude,"I just installed 18.04, but I haven't gotten a chance yet to set up my environments. I can let you know how it goes when I do. I just searched a bit and found various guides for this exact question.  I am assuming were talking about the GPU install that requires CUDA/cudnn from nvidia. The tensorflow package install is trivial with anaconda. You might find this guide useful.

 [https://askubuntu.com/questions/1033489/the-easy-way-install-nvidia-drivers-cuda-cudnn-and-tensorflow-gpu-on-ubuntu-1](https://askubuntu.com/questions/1033489/the-easy-way-install-nvidia-drivers-cuda-cudnn-and-tensorflow-gpu-on-ubuntu-1)",1530624301.0
CyberneticBrain,"I have installed cuda 9 , no problems there but I did encounter some issues while compiling tensorflow, even after downgrading GCC to 4.8 it wouldn't compile. finally installed it via pip .",1530629291.0
Brudaks,"One could argue that if you want to avoid the recurrent computations for the 'sequence encoding' task, then the proper mechanism for that wouldn't be multi-resolution CNN but rather self-attention (""attention is all you need"").",1530541994.0
apockill,"This is great! The more labeling tools, the better.",1530504098.0
HKL0902,"1.	There is a tutorial on the TensorFlow website. The MNIST and CIFAR tutorials should be sufficient. If not, try using a higher level API like Keras
2.	I suggest looking into signal processing (i.e. noise filtering) before attempting an ML solution. ",1530321432.0
RRumpleTeazzer,"Close comparison to what exactly?
Of course you can read of numbers and letters off a photo from some license plate. Of course you can put that information into an excel file.
What is the relation to tensorflow here? 
",1530251915.0
aakova,That data will already exist somewhere in machine-readable form; the trick is to find it.,1530255351.0
Supermaxman1,"Very cool! I share you passion for awesome visualizations. I’ve been working on Deep Learning projects in TensorFlow at work, and many of my co-workers have asked about using TensorFlow solely for the TensorBoard visualizations. It really helps to be able to visualize various model statistics or equation outputs over time or over different inputs. Keep up the great work! ",1530238237.0
iamiamwhoami,Try google colab ,1530065786.0
Maleficus187,"Very much depends on your task and the complexity of your network. Networks with lots of complexity and neurons will certainly require a GPU. Smaller networks with simpler tasks and fewer neurons may do fine on a CPU. Try it on your laptop first.

If it is doable on your laptop without a GPU, you may benefit from compiling tensorflow from source as most of the optimizations you can make benefit your CPU and not so much your GPU.",1530083643.0
the_cat_kittles,"try it on your computer first and find out of course. but probably not! gpu's are nice because they have a million cores, your cpu probably has at most 4. and its a slow cpu.",1530065808.0
optixlab,"Look at Intel's OpenVINO platform. Input: (TF/Caffe/MxNet) trained model -> Output (Movidius, CPU, embedded Gen GPU target) optimized model.

The [documentation](https://software.intel.com/en-us/openvino-toolkit/documentation/featured) is fairly robust and will help guide you towards model optimization. I think the latest release covers many topologies, including RNNs. ",1530050731.0
masterbruno11,The article is full of abstract and scientific. What is the practical purpose for this procedure?,1530010687.0
manicman1999,"I certainly don't think it's beyond the scope of what is possible. With consistent footage and a well built model, this could likely be quite possible. At the very least you could build a classifier to watch the footage and determine which bits it THINKS are valid, then one would only watch those bits of footage rather than all of it. I would say go ahead with it. If you're pretty fresh to computer science and looking more for the practical side of ML, I would recommend trying out Keras to make it a little bit easier for yourself.",1529984145.0
IdeasRealizer,"Another idea: (No training required)

Attach something colorful and non invasive to the fish (red color at front, blue color at tail)

Then, you just need to do image processing (OpenCV with python)

It is easier this way because if you choose the colors carefully, you can simply calculate the angle. (few lines of code and it is up and running without any training process)

By careful color choice, I mean that, you should be able to differentiate them. It is hard to separate light green object from green background but it is easy to separate a red object.

The only hard part is attaching those to the fish :-)",1530014787.0
wassimseifeddine,I would definitely go with keras. It’s now integrated inside tensorflow main repo & seems to have the largest community(which is VERY improbable),1529923788.0
robertbowerman,Use the Tf Saver class and create a checkpoint for all variables which is the default.  It saves index and metadata along with checkpoint file in /etc iirc ,1529872799.0
bmarsauto,"Yes, I’ve been able to pick it up but I have very specific questions and time constraints that I would prefer an individualized tutoring setting.",1529840718.0
TheRoboticsGuy,"If you have a masters in computational physics, this should be rather easy to pick up. ML has gotten significantly easier to learn since 2016.  

In addition, if you have worked with orthogonal arrays/LHS, combinatoric design, or regression, this will be extremely easy to pick up.",1529827398.0
ZodiacKiller20,"Check your batch size and settings. Even if you supply a small amount of images, there are lots of transformation taking place like random crop, random resizing, random rotation, generating negatives from mistaken detection etc. This increases the size of your dataset. From your error it seems like your batch size is too big for your GPU 12GB memory. Start with 6 and then test it out till you get a decent filled up amount.

Edit: It could also be the fact that you installed tensorflow-cpu and your GPU isn't being used at all. So the integrated Intel graphics chip can't take the 3.03 GiB.",1529729467.0
itsklaushere,"512 x 512 rgb? Is this recomended size? cause for my project, i only use 28 x 28.",1529734418.0
pgaleone,"The tensorflow's default behaviour is the get all the available GPU memory.
You can change this behaviour, passing a configuration to the session: https://www.tensorflow.org/programmers_guide/using_gpu#allowing_gpu_memory_growth",1529757472.0
Maleficus187,"Uninstall CUDA 9.2 and install CUDA 9.0. Also make sure you install the correct version of cuDNN (v7.0).

Alternatively you can build tensorflow from sources, which allows you to specify which CUDA and cuDNN version you have, but I find this to be more hassle than it’s worth, especially when using the GPU version.",1529682683.0
k9thedog,"Tensorflow docs define a scalar as arank 0 (0-dimensional) tensor:

[https://www.tensorflow.org/programmers\_guide/tensors#shape](https://www.tensorflow.org/programmers_guide/tensors#shape)

so your test is accurate.",1529663114.0
,"Scalar, vector, and tensor. Different dimensions, 1d, 2d and 3d+ normally in mathematics. Essentially in Tensorflow, a tensor can represent a vector or any higher dimensional structure. ",1529661268.0
RRumpleTeazzer,"einsum() is your friend.
If I cortectly remember the syntax:
einsum(""abcd,ce->abed"", a, b)",1529636096.0
Supermaxman1,"Check out the tf.image module:

https://www.tensorflow.org/api_docs/python/tf/image

It has a bunch of useful image manipulation functions. 

If you want to apply these functions to a batch of images you can utilize tf.map_fn to apply the image function to each element in the batch like so:

    margin_crop_ratio = 26/32
    tf.map_fn(lambda image: tf.image.central_crop(image, margin_crop_ratio), batch_tensor)

Additionally, you also seem to have the problem of having the image as RGB 0 to 255 uint8 values, but your model utilizes standardized images. You can standardize a batch of images with the following function:

    tf.map_fn(lambda image: tf.image.per_image_standardization(image), batch_tensor)",1529538937.0
iamiamwhoami,"Assuming you're images are stored in numpy arrays, you can cast the array to be a float32.

    cropped_images = cropped_images.astype(np.float32)

You could also crop the images in tensorflow after you feed them into the placeholder tensor.",1529543082.0
balsamictoken,"Not sure if I understand your question so don’t be too hard on me:)

At the 2018 dev summit they announced eager execution with dynamic graph support for their swift for tf lib. Pretty early in development but I got it running and it’s pretty cool, worth looking into for dynamic graphs.",1529544173.0
RRumpleTeazzer,"Could you state again your question?
So you have a 6x2 tensor, and got a 6 index tensor.
Maybe give like explicit numbers you would expect?",1529439954.0
ad_abstract,Have you tried with [tf.gather](https://www.tensorflow.org/api_docs/python/tf/gather) followed by a tf.reduce_sum?,1529442067.0
nile6499,"Answer provided by one of the users is 

tf.unsorted_segment_sum() for future help to someone",1529632948.0
Azzu98,Can you post the NumPy code? It'll help understand the question better.,1529463085.0
BeautifulJesus,All I need from you is a dataset of sermons and the quoted verse of any book or idol.,1529357592.0
gionnelles,Is it diverging periodically and then slowly converging with additional epochs? Also do you see the same behavior without the attention? What does your learning rate look like?,1529258977.0
tensorgirl,Have you looked into using NLP as a classification solution after the OCR is done?,1529254509.0
smart_dumb_smart,"It a good project. The model you need is a seq2seq, do some research on it (quite powerfull), and previous implementations in tensorflow. About encoding letters, i would use a tensor with 1's or 0's for each letter, but theres is probably a better aproach. Good luck on your project. Reach me if you have trouble. ",1529154047.0
ramML,I’m game!,1529105225.0
KangCepot,I am also interested.,1529307620.0
alegan54,I am interested too,1529648631.0
throwawaylifespan,"Silly question probably: no relation to the mind-mapping author, are you? Perhaps I have the wrong spelling.",1529123185.0
Henry4athene,"it looks like tf.gather_nd might be what you're looking for. Check out the documentation: https://www.tensorflow.org/api_docs/python/tf/gather_nd

looks like using that you'll want your index to be
index = [[0, 0], [1, 0], [2, 0], [3, 1], [4, 1], [5, 2]]",1529035979.0
Juice_DGGR,"[https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq\_kaG2P55YRn5v](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)

I'm not sure if this playlist will have what you're looking for. I know that somewhere on sentdex's page he goes through the entire MNIST tutorial and he's really good at making it easy to follow along, so I hope this helps! Sorry I have an exact link but I'm sure what you're looking for is either somewhere in this playlist or on his channel somewhere. Good luck!",1528948748.0
GEMISIS,"Something that might be of help is a repo I worked on for fun: https://github.com/GEMISIS/machine-learning/tree/master/Fun/TurkeyOrHand

It saves the model and can reload it later, as well as take custom images to use as inputs. I made this back in November, and was still learning a ton then too, so the code isn't super great, but it's a start at least.",1528991942.0
,"What you are looking for is ""inference"". Google will direct you to some ways to do it.

I'd recommend to use keras.predict() . Keras really helps if you're not too familiar with NNs.",1529008723.0
paglaindian,"MNIST takes its input as a 28x28 pixel matrix. As long as you ensure that your images have the numbers in the centre of the image, maintain an aspect ratio of 1:1 and resize the images to 28x28 pixels, you should be able to get results. 
I'm guessing your input shape to the network is 28,28,1   .
There could be other use cases where you might have to use a 1d array rather than a 3d tensor.",1528952394.0
mortonjt,"Normally, you have to create your own prediction method.  See the word2vec example [here](https://github.com/tensorflow/models/blob/master/tutorials/embedding/word2vec.py#L436)",1528993820.0
scouza08,Check out a video by Angular Firebase using tensorflow.js,1528937068.0
scouza08,Check out a video by Angular Firebase using tensorflow.js,1528936896.0
smart_dumb_smart,I have seen people use numpy in gpu for expensive calculation https://stsievert.com/blog/2016/07/01/numpy-gpu/ give it a try.,1528931737.0
wookiecontrol,maybe Julia? https://docs.julialang.org/en/latest/stdlib/SparseArrays/,1528919299.0
jayjaymz,"I use pytorch svd for hundreds of thousands multidimensional vector's and I've found it really easy to use. I have to note there's a bug right now in the partial matrix svd calculation, which is probably a strain for gpus and really big calculations. I recommend you try it, it's easy to pickup:

u, s, v = torch.svd(matrix)

edit: also sparse matrices (haven't used them): [https://pytorch.org/docs/master/sparse.html](https://pytorch.org/docs/master/sparse.html)",1528932473.0
Maleficus187,"https://www.tensorflow.org/performance/performance_guide

See the optimizing for GPU section.",1528892300.0
Supermaxman1,"The issue with live training a system like this is that it would be terribly inefficient. Modern image classification models are typically trained with mini-batches, where multiple examples are utilized to train the model at once. First you would need to live classify something like 64-128 images before you made a single parameter update in your network, and it could take millions of parameter updates before the model even starts performing reasonably well. You would also need a data source for these images, which begs the question: why not just manually label the images, or already have the images labeled? You could always record the statistics about how the model was performing during the training if you wanted to observe how the model progressed during the learning process.

TL;DR super inefficient and probably a difficult first project. Try building a model which does this without manually labeled images first if you really want to stick with this idea.

Here's a dataset of labeled images, including gender: http://vis-www.cs.umass.edu/lfw/",1528851907.0
practicalize,"[Google’s Teachable Machine demo](https://teachablemachine.withgoogle.com) uses transfer learning on ImageNet with KNN to do quick image classification. Might be what your looking for. 

EDIT: The methodology, I mean. It's a JS implementation rather than Python. You can tell from the demo that it's a very ""light weight"" approach.",1528867280.0
LewisJin,Does this support train process?,1528860404.0
assliquor420,Nice ,1528820041.0
The_Zobe,More than it would cost for a graphic designer to photoshop an image in them.. sorry,1528773677.0
zhwu,Sounds like what Houzz is doing rn,1528817088.0
XononoX,"For anyone who is now experiencing this same error, I eventually determined that the error was not happening because of a problem with the neural network, but because of how the .png images that I was feeding to the network were encoded. 

The problem images were produced in Visual Studio using the bitmap.Image.save() function. Switching this process to a different function, I can't remember which off the top of my head, did fix the problem. Sorry I can't be of more help. ",1531700335.0
SparePlatypus,"https://github.com/tensorflow/models/commit/165506347729d4641c3cd6e74b8cce9477992c21

Should of fixed problems with parsing from the protobuf  re:random_crop_pad op args

   min_padded_size_ratio: [0.0, 0.0]
   max_padded_size_ratio: [2.0, 2.0]

Try with above example variations on your protobuf config. Is error generated mentioning: *aspect_ratio_range*?

",1529278404.0
RRumpleTeazzer,"Design of a net is an artform.
Of course you can label everything, and mash it together in a large enough fully connected layers. That's kind of a brute force approach. The downside is, the number of variables will explode, and you need an even more exploding number of training data.

If you, the net designer, already knows parts if the desired solution, like the net for your pre-exam data is vastly different than the net for your post-exam data, then try to keep net topology separated and combine them at a deeper level. Don't let the brute force net figure that out all alone.",1528624928.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/u_machinelearning147] [TensorFlow Custom Estimators • r\/tensorflow](https://www.reddit.com/r/u_machinelearning147/comments/8ptvyz/tensorflow_custom_estimators_rtensorflow/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1528561547.0
TallSkinny,"Check out [semver](https://semver.org). Basically, there's no higher chance that 2.0.0 would follow 1.9.0 than there is of 2.0.0 following 1.999.0 or 1.1.0. Think of it as three independent numbers.",1528543953.0
tlkh,It is entirely possible for them to realise tensorflow 1.10? Hahaha ,1528542253.0
,"Probably. Because, if not, why lift the version to 2.0? The first digit in a version number is a major release. That should include some major changes. 

Admittedly, I don't know about TensorFlow 2.0's changes in detail. So I cannot tell particularly for TF 2.0.",1528529143.0
kalokagathia_,"A major release (left-most number) in semver indicates breaking changes, usually. At least it's the only time you can have them in semver.",1528668590.0
pgaleone,"Hi, I summarized all the known (for now) changes that Tensorflow will bring here: https://pgaleone.eu/tensorflow/gan/2018/11/04/tensorflow-2-models-migration-and-new-design/
I hope it helps",1541790442.0
,[deleted],1528484816.0
RRumpleTeazzer,"In hardware: a chunk on onedimensional memory. 
This chunk can be efficiently structured into dimensions of fixed sizes. Since the number of dimensions is not terribly important, they were all named same. ""Multi dimensional array"" would certainly fit equally.",1528490441.0
pahtrel,Regression?,1528430192.0
GamerMinion,"One thing you could do is encode the labels to not be exactly one-hot but kind of like a histogram on a normal distribution with the mean being the correct answer.

As an example, if a person is 25 you would set the label for 25 to 0.7, the label for 24/26 to 0.1 and the labels for 23/27 to 0.05

That way classes next to each other are kind of ""related"", although practically, this would rather seem like a regression problem.

Another possibility would be to hierarchically encode the outputs and targets.

So you have one output (with softmax) that outputs bins of 10 year spans, and then 10x(10 independent (softmax activated) outputs for each of the subclasses of each 10-year span.)

Then, you multiply the probability of the span with the probability of each subclass and get a rough and a more granular prediction.

So your model learns P(age=25) by learning P(age ∈ [20,30]) * P(age=25 | age ∈ [20,30])

Good luck!



",1528445146.0
trialofmiles,"You are describing ordinal regression. There are several recent papers related to formulations of loss functions for ordinal regression problems.

The most basic approach is just to phrase it as a L2 regression, but there are better approaches.",1528460942.0
grumbelbart2,"You could try and make it a regression instead of a classification. The network would then output the age as number instead of a class, and you could use a standard L2-loss.",1528438288.0
specialpatrol,Do you know how to program computers? What is it you want that those tutorials aren't giving you?,1528146651.0
hey_look_its_shiny,"Based on your comments here, it sounds like you are trying to create a program that learns from the web in a way that is analogous to a human being. And, it sounds like you'd like to do this with the goal of creating consciousness.

So, at a high level, here's what you should know:

1. There are a large number of researchers that have been working on these types of problems for many decades and have amassed large bodies of research and theory.

2. Yes, you can train learning systems on web data. There are a nearly infinite number of ways that you could do that. Google's search engine is an example of an extremely intricate and sophisticated model for ingesting general web content and making some sense out of it.

3. If you want to create consciousness, you may first want to start by defining what you believe consciousness actually is. This is not an easy question; humans have pondered it for centuries and we still don't have good answers. However, if you don't define what it is, you'll have an extremely difficult time trying to actually create it, or even evaluating whether it exists once you see it.

4. Many universities offer degrees in Artificial Intelligence and Cognitive Science. Since the human brain is among the most complex phenomena in the known universe, seeking to recreate it is no small task. These degree programs therefore tend to be multidisciplinary and often cover the following topics: computer science, psychology, philosophy, and linguistics.

5. Check out the book The Master Algorithm by Pedro Domingos. It gives an excellent high level overview of the state of the art in Machine Learning and does not require technical knowledge. However, it only touches the learning component and does not delve meaningfully into general intelligence or consciousness.

As to the nitty-gritty of your question re TensorFlow: the first place to start is with basic computer programming. If you want to use TensorFlow, you should probably learn Python. There are lots of resources for this, including the SoloLearn phone app.

From there, you have to learn to walk before you can run. There are three good beginner resources for Machine Learning:

1. Google's Machine Learning Crash Course, which is focused on Tensorflow using Python

2. Siraj Raval's YouTube channel, which gives ultra-fast overviews of how to build different types of learning algorithms (generally using Python and sometimes TensorFlow)

3. Coursera's Intro to Machine Learning course, which covers similar material but is way more in-depth and doesn't use TensorFlow. It starts from the ground up with the mathematical underpinnings and uses MATLAB/Octave.

Good luck, drf0rd (relevant username, I see!)",1528269592.0
CumbrianMan,"Can I suggest you do learn some of what Tensorflow can do.  The MNIST classification task is a good start because it will give you a flavour of what’s possible.

To understand the state of the art I’d suggest the Alpha Go paper.  That will give you an idea of how complex a state of the art system is.

This advice assumes you have basic programming and computer science skills, they are really a pre-requisite to learning anything substantial.  

Good luck and enjoy your studies!",1528148789.0
ZodiacKiller20,"You sound new, but it is already being done. See Alexa, Google, Siri. The problem is the data on the world wide web is haphazard and unsorted. So you have to write programs that can sort and sometimes it is so diverse there is no way but to do it manually which takes a lot of time. Additionally it takes a lot of computing time and power to tensorflow train even a image recognition algorithm. We are talking months to years.

But we are getting there and you can see Siri, Alexa, Google getting smarter everyday. They are starting to even be able to talk to us like humans.",1528149444.0
waaltergarcia,You should definitively take a look at Siraj Raval's channel on youtube. He's very good at explaining and their videos are amazing: [Webcam Tracking with Tensorflow.js](https://www.youtube.com/watch?v=9KqNk5keyCc),1528153191.0
Mabb_reddit,"You can record outside tensorflow graph variables using this:

`accuracy = 0.5`  
`summary = tf.Summary()`  
`summary.value.add(tag=""val_accuracy"", simple_value=accuracy)`  
`writer.add_summary(summary, batch_index)`

If you only want to log only one variable probably this is the best option.

Logging different tensorflow variables in different times I did a few time ago but now I don't remember. If I find the code I will post here.",1528123424.0
sneakersneakersneak,"Maybe just use an if statement that checks if the remainder after dividing num steps by 500 is 0 like this?

if num_steps % 500 == 0:
  store accuracy and histograms",1528058986.0
GamerMinion,"You may want to look at `tf.print()`

Another possibility would be to add your tensor to the run call, i.e: 

    sess.run([loss, train_step, ... embed], feed_dict={...})",1528045434.0
FIeabus,Even with the misleading title: 7-12% faster is still quite good. Although I'm using 1.4 still so I might still be classed as a caveman (The updates are moving so fast!),1527814528.0
hastor,"The title is misleading: ""Compared to CUDA 9 Toolkit with 7.0.5 cuDNN, the latest CUDA 9.2 is around 7-12% faster.""

The 37% is when compared to ancient technology used by cave-men only.",1527800969.0
CumbrianMan,"Using Ubuntu 16.04 you will need a PPA for Python3.6-dev.

sudo add-apt-repository ppa:deadsnakes/ppa 

sudo apt update

Per the instructions here.
https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa",1527776479.0
scmmishra,"From my blog: https://cobaltai.in/tag/tensorflow/
Hope you find this helpful",1527617426.0
sankit123,"Here are some good basic to advance tutorial. http://cv-tricks.com/tensorflow-tutorial/

Start here:  http://cv-tricks.com/artificial-intelligence/deep-learning/deep-learning-frameworks/tensorflow-tutorial/
Next this: http://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/",1527641699.0
HarambeTownley,I think siraj raval has a playlist for it.,1527668904.0
rishiarora,Udemy Tensorflow by Jose Postelo,1527731625.0
janithwanni,"Is there a pattern to the elements that you want to classify?
Like name ssn followed by name ssn and so on
I'm going tu assume that there is no pattern and tag elements are always present in the style of tag_elem: and that you know all the possible the tag elements that could be present in any line. 

The dirty way to do this would be to split your line by spaces and then iterate through the list (assuming that the first item is a tag element) taking the first tag and going through another loop until the next tag is found collecting the elements along the way and combining them in the end to one value and making dictionary with the tag and value

Hope you understood that. You should better ask someone with algorithm expertise to get an even more efficient solution ",1527561790.0
neo_su,"if you are not doing some research purpose work or developing some special kind of neural network , then go for keras . It's easy to build even very complex models in keras .",1527521575.0
,Does it have as many breaking changes as the previous versions? I find it kinda annoying that I have to install multiple TF and CUDA versions because one of my projects uses libraries linked to different TF versions which themselves are only compatible to different CUDA versions. ,1527481936.0
FIeabus,You're doing the lords work. Thankyou,1527476538.0
TheNudibranch,"Hey Lad,

So I can assume that you have frozen your graph and have it in .pb format. What your gonna want to do is create a separate script and copy the ""load\_graph"" function. From there, load in your function like this

    import tensorflow as tf
    import os
    
    def load_graph(model_file):
      graph = tf.Graph()
      graph_def = tf.GraphDef()
    
      with open(model_file, ""rb"") as f:
        graph_def.ParseFromString(f.read())
      with graph.as_default():
        tf.import_graph_def(graph_def)
    
      return graph
    
    graph = load_graph(os.path.join('your_path', 'your_model.pb'))
    print(graph.get_operations())

From there , you gonna get an output that looks something like this 

    [<tf.Operation 'import/**your_input_layer**_input' type=Placeholder>, ...]

So when you are defining the input layer, use the name '\*\*your\_input\_layer\*\*\_input'. Or you can just look for the layer that has the operation ""Placeholder"", and use that name.

**BUT**, do not start dancing yet, you have to find the name of the output layer. Well, your in luck, scroll towards the end of the list and you should see something similar to:

    [<tf.Operation 'import/**your_input_layer**_input' type=Placeholder>, ..., <tf.Operation 'import/**your_last_layer**/**your_final_activation_function**' type=**your_final_activation_function**>, ....]

So, if your final layer was a dense layer with a Softmax function, you would define the out\_layer parameter as dense/Softmax. **Make sure you are not including the actual word 'import' when defining the output or input layer**. Hope this helps. Let me know if you need help freezing your graph.

\-Your friendly neighborhood tensor ",1527466351.0
sirfuzzycarl,"Check out the info on You Only Look Once. 
It should answer most of your questions and give you a good idea how to approach the problem. 

https://pjreddie.com/darknet/yolo/",1527452365.0
rishiarora,Search Yolo tutorial by Siraj on YouTube.,1527508067.0
aquamarlin391,https://www.quora.com/How-does-batch-normalization-behave-differently-at-training-time-and-test-time,1527325557.0
,Awesome! Good job,1527237710.0
ScotchMonk,"Nice work, but don't start training your model on it. It will take ages... 😀. RasPi is good for inferencin work though. ",1527313101.0
DecipherTechnic,"Did you installed CUDA toolkit prior to running 'pip install tensorflow-gpu'? It will be better if you install tensorflow-gpu on an anaconda environment, it works flawlessly with out such compatibility issues. For better clarity, you can follow https://youtu.be/MnMYCPc82xI",1527225194.0
ericp63,Also you have a list of supported GPU on Nvidia website,1528282905.0
doodeoo,You haven't written it yet :),1527183615.0
craigglespuss,"That ease of use (generally) comes at the cost of flexibility. Tensorflow is immensely powerful and flexible, but it is not horribly easy to use. Also, ML is almost never drag-and-drop easy, because the input data is messy, or needs preprocessing, or both. So, having an ML platform that is a part of a more sophisticated data pipeline is generally more desirable than having a desktop drag-and-drop interface.

Disclaimer: I'm not an ML engineer, so I could be talking out my ass on all of this. Curious to hear dissenting opinions.",1527185073.0
RockJake28,"`pip install tensorflow-gpu`  
What's the problem?  
",1527188463.0
real_mark,"There’s a ton of stuff like this. Most are cloud platforms, many allow you to even import tensorflow code into your models. But there are also non-tf programs that are similar to what you ask. These include Weka and Mathematica, both of which have positive and negative aspects compared to tf, but they are easy to install, relatively easy to use and have some GUI which can help you model. Don’t think you won’t need to code though. However some of these online cloud services come with their own models which you can train on without coding. Off the top of my head, I can’t remember the names, and I am still researching them so I can’t offer any recs yet, but there are several around, just search and see what you find, they exist. ",1527189431.0
hhllcks,"You maybe want to try a tool like rapidminer. There you can drag and drop your datasets or ml algorithms or feature manipulations. 

Its very easy to use and it is always my first recommendation if someone wants to start with ML. ",1527190437.0
alpacalisp_now,"Tensorflow does not install like a windows program because it is not a windows program. It is a software development library, which means you require two things to use it: A software development environment and code to consume it. It doesn't sound like you're a developer, which if that is the case, tensorflow isn't going to be much use to you.

The problem is, ""one-size-fits-all"" doesn't exist in machine learning. Every dataset is different as much as every problem is different. It isn't a matter of just dumping all the data you have into a hat and waiting for a rabbit to jump out. Data preparation and feature selection as well as model architecture and hyperparameter tuning are specific to each problem. There are pretrained models for certain tasks, but transfer learning is still problem-specific. You can't use a pretrained imagenet model to discern terrain features from satellite imagery.

If you're looking for an application to help you learn about ML building blocks, take a look at Azure Machine Learning Studio. It's not going to give you production-quality models or teach you anything about the algorithms themselves, but it will let you play around with some of the basic building blocks and see some tangible results.",1529591128.0
SM1boy,"Yeah despite being a strong Microsoft advocate I actually decided after 30 minutes of trying to install it on windows that it would be easier if I just span up a linux VM and installed it on that.
It's pretty much one or two lines to install on linux and worked perfectly.
I think that it's not the easiest install for windows especially if you get an error whilst installing.
",1527187637.0
specialpatrol,"Broadly Yes, tf graphs get saved out to a protobuf format that can be saved and loaded in different language implementations. You might need to look closely at the language implementation; they are not all capable of all of tf's functionality. Eg I'm using the c api and that's not capable of training, only running inference. Sometimes not all ops have been written for all implementations.  I don't know how full the sharp version is.",1527197297.0
iamiamwhoami,Did you install CUDA? The fact that you don't have nvidia-smi means you probably didn't.,1527132818.0
pkScary,"This is one of the first cards to offer cuda cores, is it not? I'm interested in seeing how much enabling it will change your processing times.",1527134112.0
anikethake,"Try to install cuda 9.0 and cudnn which is compatible with that, if you didn't installed it already ",1527142126.0
not_from_this_world,"First you must use the proprietary drivers, then install cuda for the tf version you are using, then if you are using pip remember to install tensorflow-gpu package and not tensorflow package.",1527167226.0
pendragonn,"Which cuda and cudnn version did you install?
",1527168219.0
drsxr,"Having worked through a similar problem myself, here are my thoughts:

1.  I think the problem is not that you are using CUDA 9.0 but cudnn 7.1 which is not compatible with tensorflow yet.   Try downgrading to cudnn7.0 and you might find a ready solution.  Its there on NVIDIA's site \- you just need to dig a bit for it.
2. with that said, I'm not sure the geforce 870m which has a lower compute capability of 3.0 is going to be compatible with CUDA 9 and cudnn 7 to use TF version 1.6 or higher.  You might need to go down to CUDA 8.0 and cudnn 5.1 instead and use a TF version 1.3 or 1.4 \- need to check the specs.  
3. Make sure to set cudnn and cuda paths as specified in the docs.   To make it permanent you need to modify something like profile.rc I think.  [You can check out the article I wrote about my build and how I installed these](http://ai-imaging.org/building-a-high-performance-gpu-computing-workstation-part-iv/).  

Don't worry about the ""Your CPU supports instructions...""  \- That doesn't matter since you are not building from bazel.  

Good luck!!!",1528633810.0
Phylonyus,"I know Blizzard did the work to expose that type of info for SC2: https://github.com/deepmind/pysc2

I think you can make your own games in the sc2 editor and have an agent learn in those contexts.",1527126464.0
ZodiacKiller20,This sounds very interesting. Is there any projects or links that I can look into?,1527097463.0
Garybake,If you can get access to the memory you can use the 'action replay' method. http://garybake.com/mario-environmental.html#mario-environmental   (hopefully I'll get time to write the rest of it up soon),1527109638.0
not_from_this_world,I thought making a NN AI meant never have to find game states in the first place! You just capture the screen and let the network figure out the states by itself by training it. The only relevant classification is the victory/defeat scenarios.,1527094413.0
ParzivalCuber,"Do you have the GPU version installed? If so, HOW? I've spent hours trying. A concise tutorial would be much appreciated :)",1527099930.0
pandadata,"What does f\_fum stand for in this context? Thanks!

`hidden_1_layer = {'f_fum': n_nodes_hl1,`  
 `'weights': tf.Variable(tf.random_normal([784, n_nodes_hl1])),`  
 `'biases': tf.Variable(tf.random_normal([n_nodes_hl1]))}`",1530204334.0
dxjustice,"Hello everyone, playing around with retraining TFLite!

Out of curiosity, what happens if your input images are not 224x224, or completely square? ",1535960894.0
gokstudio,Could you describe what exactly the mods are planning to have in the wiki? Might help for the community to suggest what they want to see  ,1542572484.0
drsxr,"I think when you install anaconda you are using the version of python and its packages in Anaconda.  You installed TF 1.8 via anaconda but your python version you are using might be 2 (did you type python3 and pip3? as your commands?)  

I found it really hard to use tensorflow through anaconda and removed anaconda, installed it all otherwise and it works fine.",1528634370.0
SuborbitalIndian,"Alternative to pip install use anaconda distribution. 
use 'conda install tensorflow-gpu=1.4' or 'conda install tensorflow=1.4'",1527066701.0
MF-Dilla,"take the [crash course] (https://developers.google.com/machine-learning/crash-course/)

then take your pick of [tutorials] (https://www.tensorflow.org/tutorials/)

depending on your mathematical background your next steps will probably involve implementing [various papers] (http://www.arxiv-sanity.com/)

you'll want to start a pet project or two; if you like making music/art maybe build a GAN to [perform attribute transfer] (https://liaojing.github.io/html/data/analogy_supplemental.pdf)

if you want to go any farther than research and personal use you'll want to gain experience with [designing data pipelines] (https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198) and [serving production models] (https://towardsdatascience.com/how-to-deploy-machine-learning-models-with-tensorflow-part-2-containerize-it-db0ad7ca35a7)",1526944960.0
pkScary,"IMHO, it's wise to learn the fundamentals of machine learning and data science first. For example, fully grok linear regression, k-nearest neighbor, gradient descent, Bayes rule/probability/odds, neural nets, etc. If you don't know what these things are, learning TensorFlow is like building a house on a sand foundation (IMHO).",1527044264.0
pengo,"Yes, it's for you to organize your code and so you can reuse parts of your code without manually renaming everything.

As the Tensorflow docs explain:

> Variable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.

The [docs also give some examples](https://www.tensorflow.org/programmers_guide/variables) where they have multiple ""weights"" and ""biases"" variables in different scopes.

It's considered best practice in programming (in general) to NOT use global (i.e. unscoped) variables, so as to prevent you accidentally reading or writing to the wrong variable. 

In most programming languages scoping come more naturally: you declare the variable within the scope of the other code it belongs with (e.g. inside a class, function or a loop) so you hardly notice you've set a variable's scope.  In tensorflow's declarative paradigm it's more explicit, but it's really just the same thing.",1526864070.0
Squirrl,"Take as an example reinforcement learning. Many approaches include two networks: the ""training"" network, which is updated by gradient descent according to some loss/cost/reward function; and the ""target"" network, which is of identical structure to the ""training"" network, but whose weights are low-pass filtered versions of the ""training"" network's weights (e.g. `target.w0 = 0.99*target.w0 + 0.01*training.w0`). This target network can be used to help stabilize the training process (how exactly depends on the algorithm you're using for RL).

In such an example, we have multiple instances of one network, whose variables are structured and named the same. In this case it makes sense to use scoping in order to avoid naming confusion. For example, one way to structure the above problem might be:

1) A class to define just the network structure. This class implements all the variables that one network needs, without specifying variable scope (ie. just gives the variables a name)

2) Another class to define the ""training harness"", which would:

- define a variable scope for the ""training"" network and then construct the class from (1) within this scope
- define a variable scope for the ""target"" network and then construct the class from (1) within this scope. Note that the class in (1) just named the variables. Without variable scopes this would cause naming confusion.
- define what ever operations might be necessary to train the training network and update the target network
- define a saver to save the weights of the target network (now explicitly addressable since we have a variable scope). We use the target network for inference, hence why we want to save it's weights explicitly.

3) Another class to define the ""inference harness"" if we wish to run inference independently from training. This class defines a single variable scope named as the ""target"" network and constructs the class from (1) within this scope. Now we can directly load the target network's weights into the harness in order to perform inference without the added overheads of having to have the entire training harness in memory.

Just an example as to how variable scopes can help to organize and address variables. Another example in the context of RL would be Double Q-learning",1526894993.0
patopeking,"I agree, I enjoy Tf but it is a really poor “language”, most languages out of Google are horribly painful and feel like alphas for their entire existence.",1526863595.0
Microshak,"You can train with docker in the cloud then use Flask to create a restful service to expose that to say website. If you are wanting to do a low latency and big data, the newest version of Spark supports distributing Tensorflow amoung nodes. ",1526870639.0
scmmishra,You can do it with Tensorflow Serving! Basic Tutorial: https://www.tensorflow.org/serving/serving_basic,1526833843.0
thundergolfer,"This blog post, [*'How Zendesk Serves Tensorflow Models in Production'*](https://medium.com/zendesk-engineering/how-zendesk-serves-tensorflow-models-in-production-751ee22f0f4b), could be interesting to you. ",1526880717.0
ZodiacKiller20,The time-intensive part of tensorflow is training which can take many weeks (if not using pretrained points). The output is a graph which can be used to predict and that can be quite fast. You have API for all popular languages that can take this graph and make a prediction so it is quite easy to serve to end-user.,1527063009.0
Microshak,For self driving cars you can push your models to your IoT device.  Just Google Tensorflow Rasberry Pi for a tutorial.  ,1526871067.0
Im_int,"I think it's either a version issue or something Ubuntu-specific. I'd report it on github. I've compared TF1.5 pre-compiled with TF1.5 custom-compiled (to enable the vector instructions) on a mac, and the custom-compiled TF was slightly faster. Check if TF1.8 from pip is also slower.",1526828876.0
mikaelhg,"Chrome has never worked for me on the NVIDIA dev site login and downloads, but Firefox works. I suppose a small company like theirs can't really be arsed to test on marginal browsers like Chrome.",1526726112.0
D49A1D852468799CAC08,I had problems with the site too - it was extremely buggy. Tried a few different browser/OS combos and eventually it worked. ,1526731608.0
nikhilio,"That will work fine!

Tensors themselves are immutable. We prefer ""const"" in our documentation and examples just because we are trying to prevent ourselves from reassigning to that JavaScript variable in that situation, however in your case where you want to repeatedly do something, using ""let"" or ""var"" is perfect acceptable.


Just make sure to wrap your computation in ""tf.tidy()"" or call "".dispose()"" on tensors because otherwise you will introduce a GPU memory leak since Tensor memory must be manually managed.
",1526868233.0
Thomas-K,"Hi, I'm willing to help you out (fellow student here, collecting data and finding participants for experiments is the worst) but the site says I have no permission:

""You need permission

This form can only be viewed by users in the owner's organisation.

Try contacting the owner of the form if you think that this is a mistake.""

Update me when you fixed it, I'll take the survey then :)

 ",1526424274.0
abhirammv,"Try Word or sentence Embeddings? If you want to cluster other texts based on similarity, that might be a good approach. (I’m pretty new to this field as well - correct me if I’m wrong) ",1526339175.0
janithwanni,"Here's how i would try to do this
First get the Wikipedia glove embeddings and try to embed the word tokens that i got from the tweet tokenizer and then run k means our k nearest neighbours on the data
However selecting the right amount of centroids can be tricky. For that you can start from a random number of centroids then make a small optimization algorithm that sums the total distance from all the centroids to the points in their respective cluster and tries to minimise that distance sum using gradient descent by changing the variable of number of centroids ",1526394247.0
Edstraneous,"What do you mean by similarity of the short texts? If you want to cluster short texts that have the same topics, you could look into topic modeling algorithms.

If you want semantic similarity you can look into word/sentence embeddings and determining similarity from those",1526313543.0
alpacalisp_now,"I have worked on this problem before, specifically with topic clustering based on subject lines which were typically 3-6 words in length. The most effective solution I came up with was to use doc2vec embeddings on the subject lines then DBSCAN for density-based clustering. 

Rather than use pretrained embeddings, I built my own based on the full corpus because there was domain-specific terminology and abbreviations that needed to be captured so unknown tokens would constitute information loss. 

I used DBSCAN instead of K means because for this data set there was no way to predict the desired number of clusters. You still have to choose a magic number (epsilon in this case), but it's easy to scan for optimal epsilon if you want maximal separation because you just optimize for max number of clusters. Optimizing for cohesion is trickier and heirarchical DBSCAN might work better for that, but I haven't tried it.",1529591667.0
SlothyJoe,"ValueErrorTraceback (most recent call last)
<ipython-input-1-a275826c166b> in <module>()
    117     input_fn=train_input_fn,
    118     steps=20000,
--> 119     hooks=[logging_hook])    

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    361 
    362     saving_listeners = _check_listeners_type(saving_listeners)
--> 363     loss = self._train_model(input_fn, hooks, saving_listeners)
    364     logging.info('Loss for final step: %s.', loss)
    365     return self

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc in _train_model(self, input_fn, hooks, saving_listeners)
    841       return self._train_model_distributed(input_fn, hooks, saving_listeners)
    842     else:
--> 843       return self._train_model_default(input_fn, hooks, saving_listeners)
    844 
    845   def _train_model_default(self, input_fn, hooks, saving_listeners):

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc in _train_model_default(self, input_fn, hooks, saving_listeners)
    854       worker_hooks.extend(input_hooks)
    855       estimator_spec = self._call_model_fn(
--> 856           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
    857       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
    858                                              hooks, global_step_tensor,

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc in _call_model_fn(self, features, labels, mode, config)
    829 
    830     logging.info('Calling model_fn.')
--> 831     model_fn_results = self._model_fn(features=features, **kwargs)
    832     logging.info('Done calling model_fn.')
    833 

<ipython-input-1-a275826c166b> in cnn_model_fn(features, labels, mode)
     74 
     75     # Calculate Loss (for both TRAIN and EVAL modes)
---> 76     loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)
     77 
     78     # Configure the Training Op (for TRAIN mode)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/losses/losses_impl.pyc in sparse_softmax_cross_entropy(labels, logits, weights, scope, loss_collection, reduction)
    851     losses = nn.sparse_softmax_cross_entropy_with_logits(labels=labels,
    852                                                          logits=logits,
--> 853                                                          name=""xentropy"")
    854     return compute_weighted_loss(
    855         losses, weights, scope, loss_collection, reduction=reduction)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc in sparse_softmax_cross_entropy_with_logits(_sentinel, labels, logits, name)
   2044                        ""should equal the shape of logits except for the last ""
   2045                        ""dimension (received %s)."" % (labels_static_shape,
-> 2046                                                      logits.get_shape()))
   2047     # Check if no reshapes are required.
   2048     if logits.get_shape().ndims == 2:

ValueError: Shape mismatch: The shape of labels (received (100,)) should equal the shape of logits except for the last dimension (received (625, 10)).
",1526306446.0
alkasm,"This seems relatively easy to do without machine learning. Just estimate the homography between your reference image and the query image with sparse features. If the images are of the same place with mostly the same features in the same place, the homography will be (close to) a 3x3 identity matrix.

The only part of this that wouldn't be covered exactly in the above is blurriness, which would not be detected well by most image similarity metrics (non-blurred images are quite similar to their blurred version by feature location and pixel value). However you could run a separate test to check blurriness. Gaussian blur at least shows up as a low-pass filter, that is, if you check the Fourier transform of a blurred image you should see little high frequency content. So you can check the sinilarity of the frequency response of the reference vs query image.",1526196777.0
RRumpleTeazzer,"I would try to simply calculate the cross a correlation between your reference and life image. These are invariant of different lightening, and small portion different on the screen. If you want control about shift/rotation/slight perspective you need a spatial cross correlation spectrum.",1526211886.0
smart_dumb_smart,Why exactly do you want a substitute for softmax? Softmax works very well. We will need more info about the objective to find a substitute.,1526233771.0
RRumpleTeazzer,"You can use any positive function:

p_i = f(x_i) / sum_j f(x_j)

will always produce a valid probability distribution (positive and sums to 1).
Softmax is simply f(x)=exp(x).

I would use a function which is computationally simple, shows a good slope on the p->1 end, and has simple to compute derivatives. exp() seems a good choice already, but you could try x^2 as well.
",1526211444.0
dbusbridge,"It depends what you actually want to do:

If your objective is to output probably of class membership where any input belongs to one class only, then softmax on your logits should be equivalent to any other differentiable function acting on logits that produces elements that sum to 1 (since your model before the softmax can model almost any function in principle, then a choice of a final layer other than softmax is equivalent to the final layer being softmax with a slightly different previously learned function).

If you are wanting to solve a different task than single class membership classification, then there is usually a clear activation you should choose. For example, if you want to multi class classification then you should probably use something like sigmoid rather than softmax. My above comment about alternatives to softmax also apply to alternatives to sigmoids etc.

Of course, all of this is in theory, but in practice there might actually be better functions than softmax or sigmoid for convergence or generalisation properties - if this is what you are getting at then good luck and I am very interested in the results!
",1526208529.0
terrrp,"You could try a hinge/margin loss, or learning a metric with outputs that are vectors and encouraging same classes outputs to be close. Look into Siamese and triplet networks",1526216230.0
lcswillems,"You may be thinking that this script is useless. This is one use case where this script saves me a lot of time (I would like to get your insight on if I missed some easy way to do it):


Let's say that for each run, you get 5 plots with 5 different random seeds. So when you want to compare 5 runs, you have two possibilities without using this script:

* You put all your runs in a specific folder X, then you do tensorboard --logdir X. To compare both plots (with 5 plots each), you have to open two Tensorboard webpages, then select the plots of the first run with a regex and the plot of the second run with another regex. This has two issues:
    * Because you have to put all your runs in a specific folder, all the runs will be loaded in the Tensorboard webpages. Your computer will probably suffer every time it opens a Tensorboard webpage. Actually, I have nearly 40 runs so nearly 200 plots and it is the case with my computer.
    * Because you have to select each run with a regex, it requires that the name of each run is explicit enough to be identified by a regex, but it takes also time to write each regex. If you want to compare 5 runs (that is nearly always my case), it takes a considerable amount of time.
* You don't put all your runs in a specific folder X, you just start several Tensorboard servers for each run. In this case, you avoid both previous issues but you have to start 5 different servers, i.e. to do tensorboard --logdir dirX --port 0 for each run in different terminals, then click on the links to open the different webpages. The issue is that it may also take a considerable amount of time:
    * You have to specify the name of each folder that can be painful if you have a lot of runs in different directories.
    * You have to execute several commands and click on several links that is also painful.
With this script, you just have to select the 5 runs in your file explorer, right click and open them in Tensorboard, that's all! I always use this script and I save a lot of time.",1526134307.0
MikeDoho,"For number 2, you can look into tensorboard. It can help you look at how certain parameters update and allows you to look at calculated values like activations. Sorry I dont have a good link because I am on my phone. Hope that helps a little. ",1526037036.0
Tally914,Hi all! I found it. Just add the layer you want to your prediction dictionary for your EstimatorSpec. Very easy API,1526854533.0
gromexe,What's happens when you print?,1525953416.0
ppwwyyxx,"> How does it know the activation I'm going to use?

It does not.

> The initialization parameters depend on the type of activation function.

This initializer in tensorflow do not depend on activation.",1525969669.0
Arno_Nymus,Do you have negative examples? To me it sounds like all examples are positive. ,1525871558.0
WiggleBooks,Do you have negative training samples (i.e examples that do not have the logo)?,1525873884.0
boilerup800,"Nope. The first message means that your CPU doesn’t support a certain class of Intel vector extensions in which case TF will just not use those instructions which will only matter for specific matrix operations on your CPU. Hopefully you’re running things on a GPU. The second message indicates that you are, in fact, doing that and TF has found a GPU - GPU 0. The 0 is just a 0 index. If you had 4 GPUs the last one would be “GPU 3”.",1525830630.0
mortonjt,"I haven't put in the effort to get tensorflow working with amd cards.

But there are efforts in doing so \- definitely worth checking out tf.coriander: [https://github.com/hughperkins/tf\-coriander](https://github.com/hughperkins/tf-coriander)

Note that this is a very important problem \-\- especially now that Nvidia is threatening to sue people for doing computation on gaming graphics cards.  The sooner we can start moving compute over to AMD cards, the sooner we can start breaking up this damned monopoly.",1525802578.0
joexner,"The main issue is tracked at https://github.com/tensorflow/tensorflow/issues/22 , but there hasn't been much (apparent) movement on it from the big G. See also /r/MachineLearning/comments/85iwyj/",1525792713.0
tlkh,"If you really want to get into deep learning but have an AMD GPU, take a look at https://github.com/plaidml/plaidml ! You can use it as a backend for Keras. ",1525793349.0
Onlyhalfjewish,ROCm support is coming on the newest Linux kernels.  Having you considered running something more bleeding edge?,1525808657.0
ferlix90,"ok, thank you very much for all your advice !
i will try to set up something this weekend and i will keep you updated !",1525869154.0
ferlix90,"Right !

i understood that the best thing i can do is to build tensorflow from source.

i manage to get Tensorflow working with my CPU but when i try to build it with the option "" --config=sycl "" return an error :

tensorflow/contrib/lite/kernels/BUILD:128:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels:builtin_ops' failed (Exit 1): computecpp failed: error executing command

i ve installed computecpp downloading the files from the official website 
(ComputeCpp-CE-0.8.0-Ubuntu.16.04-64bit.tar.gz)

am i missing something ?

thanks !",1526639739.0
ferlix90,"I manage to build Tensorflow from source and make it running on my compute !

so here what i have done :
install drivers from amd for my GPU ( vega FE )
driver AMD radeon 18.20
https://support.amd.com/en-us/kb-articles/Pages/Radeon-Software-for-Linux-18.20-Early-Preview-Release-Notes.aspx

install computecpp from https://auth.codeplay.com

add env variable with 
export LD_LIBRARY_PATH=/usr/local/computecpp/lib

i used this branch of tensorflow :

https://github.com/lukeiwanski/tensorflow/tree/dev/amd_gpu
checking it with 
git checkout dev/amd_gpu

i used bezel 0.11.1

it seems to compile fine with he support to computecpp and SYCL OpenCL

I still need to test it properly, but at least is a step forward !

",1526811906.0
MrAcurite,"I'm imagining one of my CS professors, with a very serious face, making some remark about the jizz of a given vector.",1525559484.0
mikaelhg,"Try writing 8008 on your calculator, and then turn it around. Hilarious, am I right?",1525560023.0
TheRealRap,How else would you shorten “cumulative sum” to be reasonably invoked within code. Not really that funny...,1525556427.0
,[deleted],1525502676.0
smart_dumb_smart,"Unless you are testing and researching, the global init is perfectly fine, but i had a bug (1.1 i think) where the global didnt initialize one variable, no clue why. A past bug.",1525994448.0
smart_dumb_smart,"When you create a variable it is added to a list that builds the graph (use tf.global_variables() to get this list, print to see). The global init is the same as calling tf.variables_initializer(global_variables()). What is happening is that the method iterates through the graph variables list and sets all variables values to 0 (by default).

",1525994921.0
tryredtdy,How does the pricing $ work?,1525414629.0
SlothyJoe,"Is your test set drastically different from your train/validation set? If the pre\-trained network for example is trained on oranges and apples, and you try to classify a watermelon it wont work. But your second method ""re\-learns"" the watermelon over top of the apple/orange net  thus having a higher accuracy.

Edit: Also, what are you trying to classify?",1527111062.0
tinkykunk,"That's the definition of the gate function: it depends on the current input and the previous hidden state. For example, look at all the definitions in https://colah.github.io/posts/2015-08-Understanding-LSTMs/.

I'm sure that tensorflow concatenates for convenience. If they hadn't, the code would be something like 

    matmul(inputs, self._kernel_1) + matmul(h, self._kernel_2)",1525331770.0
pie_oh_my_,"Replace the values of w with w_real and it should get your results. 

Right now your calculations, by hand, use w_real. But the tensorflow code uses w, which is initialized to zeros. 

Also in your loop, you’re doing 2 steps and not one. So that will impact your results as well.  Change to range(0,1). ",1525272233.0
ajmssc,"Seems like you don't have permissions. Try with sudo or use ""pip --user install ...""",1525248410.0
CumbrianMan,"Better asking this question on Stackoverflow.  Good luck.
Edit: or GitHub.",1525246676.0
nile6499,"Remove the virtual environment where you're trying to install.
Create new virtual environment, install just Python 3.6, and then pip install tensorflow.

Never install tensorflow on global environment.

What's your cuda version?",1525276038.0
Maleficus187,"I use separate routines for generating the graph for training/testing and for evaluating once my network is trained. The two routines are mostly identical, but the evaluation graph doesn’t have the optimizer, loss functions, or any other ops which are really only necessary for training. Loading using the checkpoint doesn’t have any problem with this, it seemingly just ignores any tensors/ops in the checkpoint which are not defined in the new graph.

You can also load a checkpoint file and explicitly set each tensor in the checkpoint to a tensor in your graph one by one.

Though I don’t think having unused ops for an evaluation will cost much if at all.",1525230450.0
Maleficus187,"I think you mean the feed_dict. If x is a placeholder, then when you call sess.run you have to give it a feed_dict which should be a python dictionary with the key as the placeholder and a numpy array as the value. This is the simplest and most straight forward way to get data into the tensorflow graph. See the documentation for a tf.Session object.",1525177025.0
not_from_this_world,Is there any specific reason to use eager execution? What are the results without it?,1525128214.0
mortonjt,"Have you tried plugging in RunMetadata into your session?  That'll give you timings for each module, which can help diagnose your slowest module.

",1525133647.0
newaccountbc-ofmygf,"If you're not doing a lot of pre processing then using the tf.data is not as fast as using feed_dict. Give that a shot and you might see an improvement.

I had switched from feed_dict to tf.data for a U,V decomposition problem and watched the time per epoch increase from 15 seconds to 80 seconds. Needless to say I switched back. (This was with gpu training btw)",1525161169.0
biasOfLearn,Maybe q bit overkill but it lets you run some models at once increasing the number of experiments good luck!,1525113035.0
Maleficus187,"I think your bottleneck will be reading from the SSD. That is a fast read/write speed for an SSD, but anytime you can hold something in memory it will be faster to access. Since your dataset is 90 GB and you only have 32 GB of RAM you’re going to be reading from the SSD a lot during training.",1525126661.0
typingdot,Look for OpenNMT for tensorflow. You can use that as summarizer also.,1525123436.0
HarambeTownley,"I just have a folder called saved_models where I store every model. Each version goes into different folder so I don't overwrite checkpoint file.

Also you should use one hot output rather than -1 0 +1.",1525069151.0
Brudaks,"The way that works is that you have a single configurable version of code that you extend while keeping it capable of generating all the past models you care about.

I.e. you don't add/remove another dropout layer, you add code that checks for a flag add_dropout_layer or num_dropout_layers or whatever, and then never go back through git history but flip a flag in the config file. You don't *change* the input representation, you add configuration so you can switch between ""input style A"" or ""input style B"".

And you keep an experiment log - what parameters you used, what results you got and (it the training is time-intensive) the trained model.  This can be as simple or as sophisticated as you want; I usually just have my code print out a standard template in the end with the parameters and results, and copy-paste it to a plaintext experiment log file, possibly with some comments on why I ran it and what I concluded from the run.",1525078402.0
KrisSingh,I tried to answer on stack\-overflow.,1524987034.0
bluenova4001,"Correct me if I'm wrong, but Udacity, MIT Open Courseware, Andrew Ng's content, etc. addresses popular data sets with different algorithms. I'm not seeing the hole in resources implied by the title or how this is going to fix it. ",1524889082.0
nile6499,Pandas,1524870477.0
HunterTom94,"I tried the example provided by official tensorflow website:

[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/estimators/abalone.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/estimators/abalone.py)

The accuracy is still around 0.25. Is it the case that this dataset you are not supposed to get high result in the first place?",1524867625.0
HunterTom94,"NVM, I checked this website:

[https://machinelearningmastery.com/standard\-machine\-learning\-datasets/](https://machinelearningmastery.com/standard-machine-learning-datasets/)

says:"" The baseline performance of predicting the most prevalent class is a classification accuracy of approximately 16&#37;.""",1524868030.0
nitred,"Here's two very verbose examples of how to use tensorflow Dataset and Iterator classes. These examples are useful especially if you intend to use image data from filenames. However they are quite verbose and if you are new to Tensorflow and machine learning, you may find them more complicated than your current needs.

* Importing image data from filenames: Single iterator for both training and testing datasets: [Link](https://gist.github.com/nitred/34f9f7bb5d405b8cfc170f85b28c8b65#file-tf_dataset_single_iterator-md)
* Importing image data from filenames: Multiple iterators for training, eval_training and eval_testing datasets: [Link](https://gist.github.com/nitred/34f9f7bb5d405b8cfc170f85b28c8b65#file-tf_dataset_multiple_iterator-md)",1524851545.0
Jonas_SV,"Never Mind I just noticed that im using RELU and it can't go below 0 and that im getting the best possible answer, my bad! :) Question about recommended data pipeline sitll stands!",1524832101.0
alhparsa,"Add batch normalization to each layer before using activation function, add two or three conv layers, and one more max pooling. Make sure you have a dense layer before the first layer as well.",1524709470.0
LiveInIxora,"Plants simulated in TensorFlow, rendered in Blender. More details here! [Ixora](http://www.ixora.org)",1524597972.0
Bulbasaur2015,how? that looks real,1524603591.0
tektektektektek,Very clever. Is it limited to particular types of trees? Could one take a photo of their backyard and use this to predict what it would look like in twenty years?,1524611932.0
LiveInIxora,"360 panorama: [http://www.ixora.org/demo/](http://www.ixora.org/demo/)
Higher res video: [https://youtu.be/0m0vpcGKTtk](https://youtu.be/0m0vpcGKTtk)",1524614451.0
Luke_Bavarious,"They both run locally, the javascript imported in the script tag is simply downloaded and executed by the client browser.",1524733794.0
LiveInIxora,"Plants simulated in TensorFlow, rendered in Blender. More details here! [Ixora](https://www.ixora.org)",1524592317.0
stegrazz,"I-th component

Yi =
 f(x1,..,xn) =
 1/(1 + exp(-wi1x1 + ... + winxn + bi)
I think it is not an invertible function
",1524591641.0
dbusbridge,Yes. You can always compile TensorFlow from source providing your CUDA version >= 7.0 and cuDNN version  >= v3. See https://www.tensorflow.org/install/install_sources.,1524551386.0
alhparsa,"You can train your model on images, no need to use videos to train model. May I know which model are you using, normally you can retrain the last few layers instead of training the whole model. Usually people just retrain the last connected layers and they don’t touch the conv layers.",1524468178.0
CumbrianMan,"Check out TFRecords and TF.data video from the 2018 conference.  It’s not easy, I found github the best place to learn it.",1524356804.0
HarambeTownley,"The simple way is to use something like PILLOW or opencv to read images and put them in a list. Its like:

from PIL import Image

Imgs = []
for i in range(number_of_images):
    img = Image.open(""file_path/file_name.png"")
    Imgs.append(img)

Also note it better if you images have indexed name, like 1.png 2.png.. etc. If its not, you can write a script that does this for you.

Lots of images are expensive to put all in RAM so its better to mount only the batch size and keep updating the the batches every iteration.

Also an important thing you should know is that you should resize every img to a specific size before appending to imgs cause images have to have same dimensions.",1524426460.0
vade,you sure dont have an off by one simple prediction index -> label index? ,1524256641.0
mikaelhg,"RGB data in training, BGR data in inference?",1524260110.0
numpad0,Do you see the difference between them in the input when you look at those logos at the input scaling? ,1524269943.0
truthseeker1990,"Do you understand how RNNs work? I dont but if you dont know how they work and the theory behind them, if you dont have the background then you are really just wildly groping around and not much can be done. Give yourself a solid foundation and then get to the code. ",1524120985.0
mikaelhg,Watch Brandon Rohrer's [Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM)](https://www.youtube.com/watch?v=WCUNPb-5EYI).,1524124856.0
buaahsh,keras? Easy to build kinds of simple models,1524141625.0
Kirkland_Light,"Did you find out what was wrong? Your problem seems pretty interesting but I'm not really a windows user so I don't know if I can help. My guess is that your model is running slowly because the number of parameters is actually huge, you have a limited memory bandwidth on the GPUs and if you exceed it, then things are gonna go pretty slow because your computer will be spending time loading data onto the GPUs instead of computing (it hit a bottleneck). It could also have to do with your input pipeline.l",1524050063.0
CumbrianMan,"I had a very quick look at your code.  What I think is happening is that your GPU isn’t being fed the data efficiently.  There are two videos on Tensorflow 2018 summit to look at:

Firstly a description of the problem and whilst it’s talking about large setups I believe the principles apply to you.
[tensorflow 2018 training performance](https://m.youtube.com/watch?v=SxOsJPaxHME) 

Secondly you will benefit from using TFRecords as an input pipeline.  You’ll need to checkout examples on GitHub as its non-trivial and the documentation in TF 1.7 isn’t great.  Another YouTube video will explain more.  [TF data Fast flexible and easy to use input pipelines](https://m.youtube.com/watch?v=uIcqeP7MFH0) 

Good luck!  I’m on the same journey by the way, just a week or two ahead.  TFRecords should solve your problems.",1524348688.0
ElSarcastro,I have a similar problem on my threadripper 1950x with a 1080ti. It takes 30+ minutes to start the learning while the same thing takes just a few minutes on an old 4770 and a gtx 1070. I'm really puzzled ,1523989083.0
,[deleted],1523969436.0
pcp_or_splenda,Mine is similar. Maybe 1-2 min. 1070 gtx on xubuntu 16.04.,1524031422.0
Mabb_reddit,"In my work setup, HP OMEN GTX 1070, compute capability 6.1. TF 1.5, CUDA 9.1 and CuDNN 7.0.5.

The same process as yours only takes a few seconds, less than 5.",1524035123.0
mohanradhakrishnan,This are some problems with this code that I fixed and it is working.,1524641949.0
Maleficus187,For loops in general are a very slow way to do things. From my experience this can be even worse in tensorflow. Your best bet would be to avoid a for loop all together if you can.,1523727851.0
truthseeker1990,"If the drop ratio is 0.2, you randomly replace the outout of 20% of the nodes by 0 in each iteration",1523690627.0
rigabigadiga,"I can think of three options

1. You can make the pad function yourself by using tf.concat

    height_padded = tf.concat ([tensor[50:100][:][:], tensor, tensor[0:50][:][:]], axis = 0)
    
    padded = tf.concat ([tensor[:][50:100][:], tensor, tensor[:][0:50][:]], axis = 1)

2. maybe you can flip your tensor and use that as the symmetric padding?

3. when you cross correlate, it is like convolution with wrap padding",1523552541.0
omgwtfbbqfireXD,"Look up TF learn, I'm under the impression skflow turned into TF learn",1523625759.0
Methematician21,"I learned tensorflow through Stanford's  class notes and homework they post online. They also have slides posted and incomplete models as HW.


http://web.stanford.edu/class/cs20si/",1523534774.0
CastleNtheSky,"I’m in the same boat. I’ve been trying to really get hands on for the last 4 weeks but it seems like every other line of code throws an error and I’ve got to google why.
Oh eager executions is a test function only available in nightly builds? Cool. Thanks for telling me to install the vanilla api. It makes it hard to get the basics down. :(
I’m stuck.",1523528607.0
Pwego-HR,Yeah i agree. I find it annoying that it leaves many holes in my knowledge about that framework. There is none actual full and decent tutorials on the internet. I actually needed to buy mutiple books about it and i still find myself unknowlingly dumb.,1523529628.0
omgitsjo,"I love TensorFlow and I completely agree.  The documentation mistakes quantity for clarity.  I had an easy enough time building my model and generator but couldn't get the Estimator export method to behave, despite following directions.

After two days of fighting I scraped it and used Keras.  Done in twenty minutes.",1523544657.0
teh_mICON,"Absolutely agree. I find the API terrible and confusing and the documentation does a pkss poor job of explaining how the thing works. Much less how to use it.

Meanwhile they release videos showing Joe Shmoe using it to predict how much coffee he will need this year like it's plug and play.

I currently use it under Keras but can't get it to run for a simple fucking thing either. 

No IRC channel for help doesnt impeove the situation. I'm considering going back to DL4J cause the docs and community are great

(typed on mobile)",1523560789.0
Maleficus187,"I don’t find it necessary to use the dataset API. Maybe if you’re really trying to eek out every bit of performance you can it would be worth it, but just using feed\_dicts is sufficient. I haven’t tried using it since they did away with the old way of loading the dataset, which was very inflexible and complicated, so I don’t know much about the new dataset API, but I find the feed\_dict highly flexible and easy to use.",1523534283.0
nitred,"I think I'll defend Tensorflow here. I started using TensorFlow again recently after 6 months. Most of my old code is unusable because the API has completely changed since then, which is obviously frustrating. But after re-writing my code with the latest API, my code is much more readable and better structured.

There seems to have been one release every 1.5 months and each of these releases are non-trivial and they definitely have breaking changes or backwards incompatible changes to some parts of their code base. What is really under appreciated in the developer community is how long it actually takes to write good documentation for a piece of code. For me personally, writing ""production ready"" documentation for a function/class can take upto three hours making sure I cover all the caveats and writing documentation for a feature is at least a day long task. Therefore with their speed of development, I can see how it's so hard to document their work well. On top of that tutorials usually cover larger portions of the code base which is even more prone to having outdated content. Their priority will always be fix bugs > develop feature > write documentation > write tutorial > fix tutorial. Usually in such circumstances you'll have bloggers put up excellent tutorials where ever Tensorflow's tutorials are lacking. But I've seen that even their tutorials are outdated within a couple of months.

However there's some light at the end of the tunnel. After using it for the last week, I got the sense that the API is reaching a mature and finished stage and we may actually see more up to date tutorials and more in-depth tutorials soon (that's my optimistic opinion). The only reason one would use Tensorflow directly instead of Keras / TF-Estimator is because one would like to have more low level features. But anything that is low level is always going to be a murky mess. So I would recommend taking your time to learn TF slowly and with patience. Also consider contributing the tutorials and the documentation yourself :)",1523573945.0
Mabb_reddit,To be fair the eager execution is a new feature added a few versions ago.,1523614160.0
mikaelhg,It's trashing because your Chrome reserved some GPU memory which was previously available for your dataset?,1523403238.0
throwaway43572,I have similar experiences with chrome boosting performance of GPU (although with eth mining instead of tensorflow). I thought it was because chrome would put the GPU in another power state but I failed to prove that so I'm puzzled. Sorry to not contribute actual information - just thought I'd add that it seems to be present other places than just tensorflow.,1523991156.0
nile6499,init_fn() is function to load slim library here inception,1523400169.0
janithwanni,What exactly are you trying to do here? Generating pythogorean triplets? ,1523803351.0
HarambeTownley,Have you tried the same code in earlier versions? Also try mini batches when feeding. Don't keep everything in ram before hand. Make a db.,1523354897.0
Geeks_sid,"Try reducing batch size to 1 or 2 ,it could help.",1523357511.0
Maleficus187,"Check how much memory is free on the GPU when you’re not running the script. I’ve had tensorflow scripts sort of get stuck, and never deallocate the memory.",1523362553.0
drsxr,"Check Nvidia\-smi.  I have noticed sometimes when I am running experiment after experiment (which I'm honestly not sure is a good ldea because of reproducibility \- maybe I should reset my kernel after every experiment but I'm not clear on that) that occasionally the GPU processes won't reset or get killed.    


This ends up with you having a precipitous drop in memory and inexplicable OOM events/ crashes in TF.

Other thing to watch out for is if you are modifying your model, *particularly FC layers which blow up parameters and require lots more memory*.  Obviously in that setting just drop your minibatch size.",1528635326.0
NoPants_McChance,"Hi,

I'm just wondering if you ever sorted this problem out (and if so, how?).  I'm getting the same problem when trying to train a simple ConvNN on the MNIST data.  I'm also running an Nvidia 940M GPU (2GB VRAM), so I'm quite interested that you're also hitting the memory limit with the same hardware.  As an aside, my GPU shows all the same behaviors that you described (i.e. ' my dedicated GPU Memory always goes to 1.7/2 GB when TensorFlow is doing anything, but my shared GPU will be at 0.2/16 GB ') and the GPU 'Compute\_0' spec in Task Manager jumps up to about 98%. Also, the damn thing gets SUPER HOT anytime I run TF for more than a minute or so, I'm talking too hot to hold comfortably on my lap.

&#x200B;

I searched Stack Overflow and the TF docs, tried both:

config.gpu\_options.allow\_growth = True 

\-and- 

config.gpu\_options.per\_process\_gpu\_memory\_fraction = 0.5

but neither seemed to remedy the situation.  My code still runs thru all the epochs and then throws the OOM error message right at the end instead of ending cleanly with the expected output.

So if you've found a way around this short of replacing your video card, please post an update. 

&#x200B;",1535934077.0
Iklowto,"I think your understanding is correct, but I'll try to elaborate a bit: 

The input matrix, as you correctly described, is an [N, M] matrix where M is the number of features and N is the ""sequence length"". When you run such a matrix through the RNN, it will unfold itself N times along the time-axis. 

The batch-size, in this case, is how many [N, M] matrices you want to pass through the network before propagating back again. For example, if your batch size is 64, your network will propagate 64 [N, M] matrices forward through the network before propagating back again, correcting the weights in the network. 

Hope this helps.",1523401646.0
ajmssc,Dude where is your code? You only posted the stack trace,1523352492.0
George_Zhang,"guess developers switch to kubeflow, TFS seems stopped?",1523331174.0
iamrndm,"Hello,  I am having similar troubles, Tensorflow serving tutorials are hard to find. 
Let us know what you finally decide. Good Luck :) ",1523987493.0
anon00089,"I made a web app for a model of mine using a Microsoft AZURE VM. I just installed a lamp stack, installed tensorflow, and created a php script to run the image classification via shell_exec then spit the results back through a regex function to return JSON like a basic API. Then I can call the api from my website. 

I didn’t want to deal with running all the crap I had seen people setting up to serve models. People might say it’s not as efficient but honestly on a basic 4 core server with 8gb of ram I can handle hundreds of requests per second with eval times below .2 seconds.",1528827810.0
rigabigadiga,"Image channels should always match input_channels, or there will be a mathematical error. tensorflow will check the shapes before performing the operation. If you have the tensor formatted wrong, you can change data_format argument to a different order, or call tf.transpose to match the default format.",1523292033.0
Maleficus187,"Probably the gradients are too large, so it’s taking huge steps and going to NaN right away. Try turning down you learning rate.",1523284250.0
Maleficus187,"No it’s not that high in general, but could be high for your specific application. I’ve used learning rates of 0.00001 for certain networks. Check for ops which have unstable gradients. Tf.norm is a common one.",1523287215.0
rigabigadiga,"Python has a large community and tensorflow is the most popular deep learning framework, and has python as its preferred language. Python also has many libraries for ML, image processing, and natural language processing. These are robust and supported enough to built production complex systems. Tensorflow has some high level operations. Their layer module lets you create layers with one line. They also have entire architectures like VGG, and Inception. For complex things, however, it still allows for low level design. If you already have programming experience, you can dive right into learning these. Also, whether this will solve all your problems is dependent on what you are using it for. All my programs use Numpy. I work with computer vision and so I also use PIL, and opencv. Pandas and scipy is also popular. You will also likely need some ""expert knowledge"" or domain specific knowledge to know how to handle and whats important about your data. What kind of data do you plan on using?",1523252317.0
WrinkledTime,"That is sufficient but it may not be the easiest path. You haven't provided enough information.

You can do anything with Python, and there are tons of libraries to bootstrap you up. Tensorflow is fantastic for writing any known neural network but turns into a nightmare if you try to do something new",1523274191.0
Methematician21,"Have you tried downloading the CPU version first?

I think you can go back and install the GPU version later. It just makes it easier to debug.",1523234908.0
itsmerandymarch,"You need six (version>=1.9) which is not installed. To install run:

sudo pip3 install --upgrade six",1523239130.0
nile6499,"I am running version 17.10 from last November, and it's awesome.
For tensorflow you need to build from source code. If only you are using cuda 9.1.

You need yo search for tensorflow source code for cuda 9.1.
 Cuda driver is latest one for me.",1523281633.0
rigabigadiga,can I see how you define loss?,1523252404.0
rigabigadiga,"Tensorflow has a 'layers' module. This is great for beginners because you can make a convolution layer with one line of code. There are default arguments for parameters which you may not yet understand. If you follow their MNIST beginner tutorial, you will construct a simple CNN.

As for building on top of (or parallel to) another network, you can look at tf.concat and tf.stack. [This](www.tensorflow.org/api_guides/python/array_ops#Slicing_and_Joining) page goes over many useful tensor (and vector) manipulations. You can also skim through the [math](www.tensorflow.org/api_guides/python/math_ops#Matrix_Math_Functions) functions to see what you can do.",1523253153.0
gionnelles,Whatever Python IDE you are comfortable with. I use PyCharm.,1523155535.0
epangelia,I am also using PyCharm. Great IDE tool for Tensorflow up to now.,1523188006.0
CumbrianMan,"Check out TensorBoard as part of your development cycle.

It hooks into the training and let’s you inspect and compare what’s going on during training, graphing losses and accuracy is just the tip of an iceberg.   

It’s also got a plug-in community.   Enjoy!",1524348961.0
alpacalisp_now,"Visual Studio Code has solid Python support, is cross-platform, and has a ton of extensions. The debugger is pretty good as well. The question is, what do you mean in terms of tensorflow support. It has autocomplete, which also shows you inline docs. I use it for pretty much everything except legacy .NET projects. ",1523199368.0
rigabigadiga,"I think tf.where is what should be used.

    loss = tf.where(tf.less(label, 0), 0, prediction-label)
    loss = tf.reduce_mean (loss)

You could also modify the dataset beforehand. or you could do something tricky like:

    loss = loss * (label + 1)
",1523254812.0
kishore_ugal,Everything will be made positive and normalised to scale when you softmax. It hopefully shouldn't affect your output class. Any reason you want it removed ?,1523079703.0
ramsey202,"I want to recommend Feedster app. All news from social networks and other sources in one feed! Convenient, easy to use and saves tons of time on news reading. Download here: [thefeedster.com](http://thefeedster.com)",1523002721.0
FOOLS_GOLD,Doesn’t load :(,1523057586.0
itsklaushere,"ValueError: Cannot feed value of shape (48,) for Tensor u'Placeholder_2:0', which has shape '(1, 48)'


Seem like you need to reshape your input",1522994338.0
smart_dumb_smart,"The thing is that you need to reuse the variables when creating the second discriminator. 

So the function that creates the model should recive a reuse bool and passes it in 

""with tf.variable_scope(""discriminator"", reuse=reuse bool): [model here]""

This github project is a simple and great example: 
https://github.com/pr0crustes/PsychoGAN",1522965801.0
MutedPermit,"I haven't tried it out and it doesn't use tensorflow, but maybe this repository can help you:
https://github.com/fzliu/style-transfer",1522910409.0
nile6499,"Or anyone needs code for pointing mistakes, I will be happy to provide the code which I am using.",1522848215.0
rigabigadiga,"What do the dimensions represent? like [example, time, features]?
I have used it with images in the following way:
[height, width, example, features] X [height, width, features, output features]

with the result being: [height, width, example, output features]

The last two dimensions are being matrix multiplied. The rest must have the same size.
The sizes should look like this: [A, B, C] X [A, C, D] = [A, B, D]

Also, you probably need to use tf.transpose instead of reshape. I can tell you how once I have some more information.",1522814005.0
Kirkland_Light,"There's no such thing as a ""rank 3 matrix,"" I think you mean tensor. There are some things you could try like tensor contraction, or perhaps an outer product, but unless those entries are sparse (ie. most have value of 0) I would suggest against the outer product as it will be overly intensive on both memory and computation.",1522843583.0
Mabb_reddit,"The problem could be in the line:
backstep_update = [(tf.convert_to_tensor(g, np.float32), v) for g, v in zip(rollback_grads, rollback_vars)]

The most probable is that you are adding new nodes to the graph each iteration of the loop, try to comment this line.",1522740560.0
bwllc,"I can see some advantages to remaking scikit-learn models in TensorFlow, if a few conditions are true: 1) the training of such models can demonstrably benefit from massive parallelization, and 2) you are using the GPU version of TensorFlow.

I have read the abstracts of a few papers which suggest that there are ways that parallel processing could be used to speed up some of the older machine learning strategies, but it seems like an underexplored field to me.",1522744975.0
wild_thunder,"I'm not sure about efficiency, but I'd guess the scikit models are fairly optimized. If not, the C++ backend of tensorflow would probably give better performance if you reimplemented the models. More than anything, this would probably be a good programming exercise to learn tensorflow and get a better understanding of the math behind the scikit implementations.",1522725192.0
pie_oh_my_,Look at scikit-flow. ,1522770180.0
4ong_dev,"You can check this:
https://github.com/MrGemy95/Tensorflow-Project-Template

Also take a look on the projects like Magenta
https://github.com/tensorflow/magenta
https://github.com/tensorflow/magenta-demos",1522609671.0
Olao99,"The parameter server is supposed to keep track of the weights while the workers do the heavy lifting. The workers would compute the gradients and send them to the parameter server.
    
   
If I understand the question correctly, you don't want the parameter server to have the weights but instead keep them in the workers?",1522602005.0
deepaksuresh,Did you take a look at the official documentation [here](https://www.tensorflow.org/install/install_sources),1522504954.0
lookmasilverone,Just gotta use the --config=opt argument,1522582339.0
manganime1,"Could you reformat your question? As it stands, it's kinda incoherent. Regarding name_scope, take a look at [this](https://stackoverflow.com/questions/35919020/whats-the-difference-of-name-scope-and-a-variable-scope-in-tensorflow). ",1522554044.0
Brudaks,"Quite the contrary, since everything requires specific versions to work, people *will* want to manage it themselves.

We're using docker containers for that, so if no matter if we deploy it on our own or a rented system (say, AWS) it gets the expected versions.  

You might want to provide one or two ""standard preinstalled"" configurations for new projects, but I'd assume that many of the clients would bring in all the dependencies together with their code.",1522232327.0
Maleficus187,How many neurons are in your hidden layer? I don’t see anything inherently costly in your network. It’s possible the memcopy from CPU to GPU to run and then back to the CPU is costing as much as you save by using the GPU. Have you used the profiling tool to see which ops are the most expensive?,1522152630.0
Brudaks,"You're using a tiny network with tiny (one item!) batches. I don't see anything that could be taking a large amount of time there - how much does it take?

GPU will give you a boost if you'll be using larger matrixes. Try doing minibatches of, say, 100 items and see where that gets you.",1522158304.0
moreAndMoreBees,How many is a lot?,1521724464.0
markov01,"I'm interested in that too, I'm having quadratic optimization problem with linear constraints, number of which are equals the number of data points",1521792072.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/learnmachinelearning] [\[QUESTION\] Tensorflow classification and subclassifications of text](https://www.reddit.com/r/learnmachinelearning/comments/86nlvu/question_tensorflow_classification_and/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1521835175.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/learnmachinelearning] [\[x-post\] Building first TensorFlow model, checking if I'm understanding\/interpreting the process correctly (Questions on rank\/dimension\/shape)](https://www.reddit.com/r/learnmachinelearning/comments/863fr4/xpost_building_first_tensorflow_model_checking_if/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1521649751.0
hegman12,"Some other way to do this - you can train on one thread. This train thread also writes checkpoint to a log directory. The second thread scans the log directory imports the graph, restores the variables into session and runs inference. But I am not aware of efficient way to do this other than this.",1521739272.0
alhparsa,Run it as sudo ,1521608645.0
earmountain,Try getting TF installed in a Conda environment. ,1521607555.0
nathan_drak3,You can just do pip install tensorflow and it will work in your mac. No need to install a virtual environment.,1521799061.0
Roots91,Looks like you need admin permissions to install/upgrade it on your system.,1521838040.0
rigabigadiga,"2 solutions
you can write this instead:

    sess.run(train_step, feed_dict=np.reshape(train_data, [-1, 28, 28, 1]))

or you can make these changes
    
    x = tf.placeholder(tf.float32, [None, 28, 28])
    ...
    Y0 = tf.nn.relu(tf.nn.conv2d(tf.reshape(x, [-1, 28, 28, 1]), W0, strides=[1, stride, stride, 1], padding='SAME')+B0)

",1521594915.0
itsklaushere,"x = tf.placeholder(tf.float32, [None, 28, 28, 1])
change to 
x = tf.placeholder(tf.float32, [None, 28, 28])
or reshape your x_data",1521594524.0
marvpaul,"You could use a conv network with all your pixels on the screen as input and the position with should be touched as an output. An alternative would be to just use some special gestures like “swiping left”, “swiping right” ..., this makes the network a lot more simple but it depends on the kind of game you wanna to play.
You could use an optimization algorithm like neat to optimize your network. You’ll need sth like a score function which will measure how good your network performs in the current game. So in this approach you have to write your own score function for each game. ",1521534601.0
ewilderj,"Hi! Really glad to hear this. I work on open source collaboration on TensorFlow, and am trying to bring together everyone interested in working on the Java API to see if we can work together better. Feel free to drop me a line - my username @ google. There are a few people working on this already and some issues in Github I can point you at.

[ edit: try this issue, for example: https://github.com/tensorflow/tensorflow/issues/17390 ]",1521495940.0
tu_tan,"You can use either sess.run(logits, feed_dict) or logits.eval(feed_dict, sess).

To save your network, use tf.train.Saver if you wanna save the checkpoint and maybe continue the training, or otherwise use tf.train.write_graph",1521437622.0
terrrp,"Just have another class for anything else and train real images that don't meet any of the other categories to map to it. 

You could also not do that and just ensure the top scored category meets a certain threshold, I.e. the softmaxed score is > .9 or something, but this would be very unreliable and awful against adversarial examples.",1521303183.0
itsklaushere,But your bottleneck doesn't contain value for your new training set.,1521271317.0
truthseeker1990,"There is no way anyone can help with this. Not here. Google the actual error, ""ValueError : axis = 0, not in [0,0)"" along with some context like what library and model you were building and see what comes up. Just copying an error message especially when its something as generic as this one, is impossible to debug because theres a lot of things that can trigger that. Also this is a library or model specific issue, not a conceptual one. You are unlikely to find a solution to this problem in this subreddit. Try IRC channel for tensorflow if Google doesnt help. Try stackoverflow.com with the right tags. Try a mailing list if the library developers have one.",1521226125.0
SArham,"Try to put the complete path for the input variables. It should have given you dimensions of the images instead of the 0,0 dim error. Is this the object detection training script. Shouldn't there be a --logtostderr input too ",1521282480.0
patopeking,"2 gigs isn’t enough if you’re doing any decent model training.

I’d suggest getting a small desktop for training, and laptop for coding.  When your resources are pegged when training a new model, work isn’t really possible and you don’t want to crash after 90 minutes of training trying to run photoshop.",1521169022.0
SArham,Just get a decent PC with a good GPU for the same price. Install a Linux OS and ssh into it from anywhere. A shit Windows laptop with PuTTy will work for remote work. TeamViewer works too.,1521282689.0
Mabb_reddit,"Exist the C++ version:
https://www.tensorflow.org/api_guides/cc/guide
I don't If It will be easier to merge C# with C++ than with Python.",1521129747.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/csharp] [C Bindings and TensorFlowSharp Questions](https://www.reddit.com/r/csharp/comments/84nqq3/c_bindings_and_tensorflowsharp_questions/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1521131200.0
itsmerandymarch,"This is a complete shot in the dark but try replacing ""python"" in the command with ""python3"" since tensorflow might be installed on python3 and by default python calls python2.7",1521148327.0
hamburgerandhotdog,"Take a look at Andrew Ng's deeplearning.ai course on coursera . I highly recommend it as a great primer on the basics of machine learning. It starts out teaching how to build deep neural nets from scratch using python and numpy. You'll be learning from one of the best. 
https://www.coursera.org/",1521078309.0
NatoBoram,"> * $1691 worth of digital content
* Pay what you want
* DRM-free
* Multi-format
* 18,095 Bundles Sold

Do we gain digital copies unlocked into an account form where we can download it anytime, like on Steam?
",1521067866.0
augenblik,"I wondered this myself just a few weeks ago.

If you’re making the same mistake as me, then you’re probably thinking of the conv and pool layers’ filters as 2D, but they are actually (kind of) 3D, they just ‘slide’ in two dimensions.

So for example if you have input of [whatever, 14, 14, 32] and 64 filters of say size [5, 5], it actually applies each of those 64 filters to ALL 32 input channels, not just one of them as the 2D filter size might suggest. So the actual size of each filter is in fact [5, 5, 32]. This then creates one output channel per filter.",1520993585.0
anti-Casta,"I finally found a good explanation. For those new into this: 

http://machinelearninguru.com/computer_vision/basics/convolution/convolution_layer.html",1521147747.0
AspiringGuru,"Tensorflow is fast becoming yesterday. learn Pytorch.

plus: those authors aren't exactly prime choice. Budget yes, but there are better authors.",1520980589.0
tweettranscriberbot,"The linked tweet was tweeted by [@savedsoyoumoney](https://twitter.com/savedsoyoumoney) on Mar 13, 2018 17:35:42 UTC

-------------------------------------------------

Humble Book Bundle: A.I. by Packt.
Get titles like Unreal Engine 4 AI Programming Essentials, Machine Learning with R, Deep Learning with TensorFlow &amp; many more (partner) [https://ej.uz/2v9q](https://ej.uz/2v9q) 

[Attached photo](https://pbs.twimg.com/media/DYL4YyQWkAYduby.png:orig)

-------------------------------------------------

^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •",1520963544.0
Maleficus187,Probably a better question for /r/learnmachinelearning or /r/MLQuestions. But can you explain what you mean by “data quality”? How is quantity vs quality a trade-off in your situation?,1520887050.0
hamburgerandhotdog,"It really depends on the initial performance of your train/dev/test set distribution. A general rule of thumb is that if there's a large discrepancy between the train and dev set then you have a high variance. For high variance problems you may want to consider adding more data, try regularization to reduce overfitting or try a different architecture. If you have a high train set and dev set error then you have a high bias. In that case adding more data may not fix the problem. A better approach would be to try a bigger network, train longer, or again try a different architecture. Google bias-variance tradeoff for more information on the subject.",1520982977.0
Maleficus187,You should include the whole stack trace for the error. It will point out exactly which line is giving you trouble.,1520822944.0
deefunkt420,"You need to navigate to where u installed Anaconda. Probably in AppData\local\continuum if its the default. 
For future ease, maybe add the directory to PATH.",1520799739.0
C0inMaster,"Hi all,

I wonder if this such a naive and basic question that nobody wants to bother to help with it or maybe nobody else ever had this problem?
I googled and found multiple reference in various threads of people talking about the need to create subdirectories for versions of checkpoints and some other discussions mentioning of a new “SavedModel” format, but never found an answer in those threads. 

Anybody had the same issue? Ever? Help :)



",1520930905.0
Thomas-K,"What are you trying to train, a CNN?
I'll just throw some code at you, that usually helps me a lot. For colour-images you'd do something like:

// input dimensions: batchsize, imgx, imgy, colour channels

x = tf.placeholder(tf.float32,[batchsize,10,10,3])

// fan_in is 9 in this case, kernel size * colour channels, ignore what that means if you don't know already

initializer = tf.random_normal_initializer(stddev = 2/fan_in)

//kernel size, kernel size, colour channels, number of feature maps

kernels_1 = tf.Variable(initializer([3,3,3,5]))

convolved = tf.nn.conv2d(x, kernels_1, strides = [1, 1, 1, 1], padding = ""SAME"")

Does that help you already?",1520564542.0
an-allen,"Sounds like you need to do some preprocessing. Its going to be very difficult for your network to converge with that much input data. Start with some preprocessing to reduce the size of the image, scale it, filter out extraneous information, etc. Then i would look for ways to partition the data. Im not certain exactly what kind of information a fMRI outputs but id attempt to hold some dimension of that 3-d pixel constant so you are just processing one layer of the output at a time. 
",1520551627.0
SamStringTheory,"What is your cost function? How much data do you have?

The input variable dimensionality isn't terrible, image classification is done routinely on 128x128 or 224x224 images. But it requires the right architecture, and sufficient data. If the data is more like an image, then I would recommend looking into basic convolutional networks.",1520555802.0
kopita,"Not everything will be available on anaconda, just pip install it.",1520522604.0
continue_stocking,"When I've installed in Anaconda/Miniconda, I've used pip to install everything.",1520544931.0
rigabigadiga,"tf.random_normal() is what is slowing down over time. Even with

    tf.random_normal([action_dims], stddev=.1)

It still slows down. I doubt that can be fixed, but I think it's not critical.

I tested tf.random_normal, tf.truncated_normal, and tf.random_uniform
like this:
    
    import tensorflow as tf
    import numpy as np

    with tf.Session() as sess:
        while True:
            print(sess.run(tf.random_uniform([5])))
They all slowed down.",1520575452.0
terminator557,"Running it on my School's cluster

    21800049 function calls (21600045 primitive calls) in 33.680 seconds
And then when I run it on my mac

    20700047 function calls (20700044 primitive calls) in 24.373 seconds 
I'm still relatively new to this, so I hope this helps.",1520496029.0
RRumpleTeazzer,"How about tf.einsum instead of matmul?
Also matmul will work if you patch some tf.reshape around (probably also with perm), it looks ugly in code but this way you can contract any dimension of any tank tensors.",1525562188.0
letsmachinelearnguy,"Can you post your code so someone else can try to run it?  Going to be hard to help much more without seeing what exactly you're doing.  This is the #1 best way to get help.  Without that, we can only speculate. 

Q1000M essentially a 4GB GTX 950M die with fewer shader cores enabled and 4GB VRAM.  Not a screamer, but it should work and absolutely destroy the CPU on FLOP rate.  Some quick googling shows ~35GFLOP for the 6820HQ vs ~250GFLOP from the Q1000M depending on which benchmark is used.  Almost an order of magnitude.  

That CPU is 4 *core*, 8 *thread*.  They still don't put any more than 6 cores into any mobile part. 

I believe there is some overhead to spin up Cuda from Tensorflow and pass data back and forth to the GPU.  You may be experiencing that.  Longer running work may show the GPU screams past the CPU after a longer startup time.  

Are you sure all your training is done with 32bit single precision float?  Nvidia has a habit of wrecking 16bit and 64bit float performance in all but its new class of uber-tier compute parts.  Not sure how that specific Quadro card is hobbled, but you could probably look it up.  I'm fairly certain the Quadro does not get a pass on this sort of hobbling. Some newer parts have a 1/64th speed for double precision vs. single precision.  That would probably mean a CPU is better for double precision floating point math, though I haven't tested this. 


",1520442658.0
daviddisco,"Make sure you are actually running on the gpu.  You have to pip install tensorflow-gpu rather than just ""tensorflow""",1520443633.0
mikaelhg,"I used to have a similar ZBook setup, with a slightly better Quadro, and GPU beat the pants off CPU.",1520440090.0
ctorresmx,"Quadro cards aren’t optimized for ML, so yeah, your CPU is better suited a these kind of tasks. GeForce cards (I got a 1060 6GB) are way better at this.",1520439283.0
Murflaw7424,These were all deleted.  Are you going to repost them?,1521811593.0
Murflaw7424,Thanks for this but the videos are in reverse order.  If this is your list can you fix them?,1520353372.0
specialpatrol,"In windows you can set environment variables (that's what $PYTHONPATH is), in Control Panel -> system -> advanced settings -> environment variables. That will set the env var system wide.

Depending on how / where you're running your script from you can set your env var more locally. 

Do you have this models/slim folder somewhere?",1520344573.0
naska_678,Parameters are based on requirement which u will know after some more practice. ..and for activation function u can go https://youtu.be/-7scQpJT7uo  ,1520314337.0
Beazlebubba,I like https://pythonprogramming.net/ a lot particularly https://pythonprogramming.net/machine-learning-tutorials/ Lots of good tutorials and examples.  https://www.youtube.com/watch?v=j_pJmXJwMLA Siraj has some good content as well.,1520320288.0
nschejtman,"Check out these slides:

[https://docs.google.com/presentation/d/1SJMsa4BdOFVRCPD9uwaAqDBYYfgbQcbOm7HaxRVpaaY/edit?usp=sharing](https://docs.google.com/presentation/d/1SJMsa4BdOFVRCPD9uwaAqDBYYfgbQcbOm7HaxRVpaaY/edit?usp=sharing)

In particular there is a section called ""Structure your TensorFlow model"" which you might find useful, it was useful to me. These were taken from this Stanford class: [http://web.stanford.edu/class/cs20si/](http://web.stanford.edu/class/cs20si/)",1533150517.0
specialpatrol,It has a [c api] (https://www.tensorflow.org/extend/language_bindings) ,1520162443.0
muntoo,"Have you tried doing this without tensorflow first?

e.g. good old numpy or ML packages",1522813795.0
FIeabus,"It's best to think of a recurrent net as running a standard network repeatedly in sequence. In a standard network you have a number of inputs that are sent through to the output layer.

For a standard network you would set the data up as [batch, inputs].

RNN's add a sequential element known as time steps which specifies how many times you run that network in a sequence. The rnn then remembers the previous time step by passing a state from the previous time step to the current time step.

To do this, you need to specify it in the matrix: [batch, steps, inputs]",1519893803.0
Brudaks,"Usually each real-life element in the sequence can not be represented with a single value, so you'd want to use a vector of values.

I.e. the 2D situation when you would have a batch of (for example) 10 sequences, where each sequence is a chain of (for example) 100 floating point measurements is a simplified exception;  Actually you're likely to have a batch of sequences where each sequence element is, for example, a set of measurements from *many* sensors at that time point; or each element is a vector describing multiple features of that measurement, or each element is a one-hot representation of some multiple-choice value; or each element is an embedding vector of a word in the sequence of words, etc, etc. So the ""default"" case is 3D.  If you really have the case where you have simple sequences of scalar values, which is common in toy examples but rare in real world (even e.g. pure financial time series analysis for separate values often needs to bundle extra features from outside sources in addition to the ""main"" measurement""), then you'd need to create a new dimension showing that yes, your element vector has a length of 1.",1519935832.0
DeligtfulDemon,"The 3d tensor should be seen as follows. every element of 1st dimensions is a training instance of t steps. What's t ? t is the dimension 2. Now at each time step , we have something. What's that ? The d dimensional input at a single point in time. That d should be dimension 3. You have b*t*d. 3d tensor.",1519904351.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/learnmachinelearning] [Cross post from TF (Need help with SVM implementation)](https://www.reddit.com/r/learnmachinelearning/comments/80to3a/cross_post_from_tf_need_help_with_svm/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1519796818.0
ragekge,"I don't have access to the book, but I noticed a few things. Your link points to the non-linear SVM, and some of the quoted code snippets do appear in the non-linear SVM code, but not on the linear. So I was wondering if you're looking for the intercept in the non-linear SVM version, maybe? 

If that's the case, think of the linear kernel as being something like wT x + b - reason why it's called linear. In this case, b is the intercept. It is updated in line ~86, where train_step is evaluated (optimization on top of the model_output variable).

In the non-linear version, [Radial Basis Functions (RBFs)](https://en.wikipedia.org/wiki/Radial_basis_function) are used as kernel. In this case, there is no intercept. This is not the only possible non-linear kernel but it is the most frequently used (by far!). They are evaluated close to line 43 in the file from your link.",1519799975.0
oopsleon,"Can you provide more info? For example, _are_ you running this within the TF source directory? The more info you provide regarding the complete set of steps you executed before receiving the error message, and about your overall setup, the easier it is to help. ",1519774463.0
ajmssc,"You can write c++ to define your custom operation.
 https://www.tensorflow.org/extend/adding_an_op

What exactly are you unable to do?",1519547647.0
ZodiacKiller20,"I can help! I have the android app running as well as custom trained models for the android tensorflow detector. Check out my github - 

https://github.com/Zod20

If you clone and import the tensorflow android example, gradle will sort out everything for you so you really don't need to do much. Only change the .pb model to point to your trained model in the asset folder.",1519566800.0
fuzzball_b,"Google is your friend :-)

http://nilhcem.com/android/custom-tensorflow-classifier",1519668962.0
Evander12345,r/titlesthatrhyme,1519535419.0
Henry4athene,I,1519433625.0
cjalmeida,A comprehensive post and github project about using the Dataset API. I find official docs somewhat lacking and I hope this can be useful for those learning TF.,1519362307.0
chef1957,"Pi magazine has actually made an article about the aiyprojects voicekit. You can download it for free so it might be a good place to start. Not sure if they use Tensorflow though. 

https://www.raspberrypi.org/magpi/issues/essentials-aiy-v1/ 
https://aiyprojects.withgoogle.com/voice#list-of-materials",1519359245.0
Franck_Dernoncourt,you may want to look at https://github.com/mozilla/DeepSpeech,1519359303.0
ZodiacKiller20,"https://www.tensorflow.org/versions/master/tutorials/audio_recognition

This tutorial shows you how to train audio using tensorflow. I have tested it out and have even used for successful token word detection on android devices (instead of 'ok google' to trigger google services, it gets triggered by 'hey jarvis'.) 

The downside is the device gets very hot since I have to use a service to do the detection on android devices. Maybe in the future I will compile android operating system from source and then I can replace the 'ok google' feature without using hacky services.",1519567343.0
doktorneergaard,Why would you use TensorFlow for this kind of problem?,1519343447.0
Maleficus187,"Sorry this will probably be long-winded because I have a tendency to do that. 

The easiest way I can think to do this off the top of my head would be if the coded matrix were actually of shape (100,1000,2) where you put [row, column] pair indices into the matrix instead of just the column indices. Then reshape the coded matrix to be 100000x2. Then you can use tf.gather_nd to gather the values from the lookup table, which will give you a 1D matrix of shape (100000). Then just reshape that back to (100,1000) and you will have your decoded matrix. To sum along the row use tf.reduce_sum and pass it the axis you want to sum along.

Without knowing how you get the coded matrix in the first place, to add the row index to the coded matrix you can use tf.range(100) since everything is in order anyway. This gives you a tensor of shape (100) of [0, 1, 2, ...., 99]. Use tf.expand_dims to then make that tensor be shape (100,1) and then you can use tf.tile to get a tensor of shape (100,1000). So now you would have a tensor of the row indices. Use tf.stack to stack this with your coded matrix where the new axis will be the last dimension. Make sure you feed this row indices matrix to stack first as tf.gather_nd assumes the indices are in order of axis. Once you stack them you now have the coded matrix I described above which you can reshape, use gather_nd, reshape and then reduce_sum.

I typically prefer to avoid using tf.tile unless absolutely necessary because it’s always been pretty slow. In fact I think I’ve just done a broadcast multiply of a tf.ones matrix and it’s been faster. If tf.tile is the slowest part you could try using tf.ones to make a matrix of size (1000) and after you expanded the dimensions of tf.range to (100,1) then just multiply by this ones matrix and that would do the same thing as the tf.tile.

Really though, the faster way to do this would likely be somewhere earlier in your code depending on how you create the coded matrix in the first place.",1519357650.0
Maleficus187,"What kind of cpu and/or gpu are you using? What is the datatype of the coded matrix and the lookup table? I assume the coded matrix is ints. Are they 32 bit or 64 bit? Is the lookup table floats? 32 bit or 64 bit? The gpu version should be faster most likely if you are using a cpu but have a cuda capable gpu available to you. Reducing the data sizes could make it faster too (using 32 bit instead of 64 bit).

Other than that, is there any other kind of order to the coded matrix and lookup table besides the rows corresponding? Is there any kind of ordering of the columns? I’m guessing the reason gather\_nd is taking so long is because it has to grab 100000 values individually. If you can reduce it to grabbing a row or a column at a time that would speed it up quite a bit.

You could try to do this using scatter\_add instead of gather\_nd. I typically find gathers are much faster than scatters in my experience, but as I recall scatter\_add is quite fast but I can never use it because it doesn’t have a gradient for the auto-differentiation.

You could try throwing the code inside of an XLA-JIT scope. The XLA-JIT compilation tries to make things run faster by fusing operations if it can. I have seen a significant speed up myself using it before, but typically it doesn’t run faster, and some operations it doesn’t seem to like and tensorflow will just hang. Last I knew XLA-JIT was still “experimental” so you should verify the results it gives you are the same to within floating point precision. Also the compilation takes some time itself, so you can’t really compare it to a single run I’ve found. When training a network I would compare the time of epochs after the first epoch.

Last thing, it sounds like you’re using the profiling tool to do some of the timing. I believe everything runs faster with the profiling turned off. You won’t be able to get individual operation times without it, but make sure you time it without profiling to see how fast it actually runs.",1519436051.0
barnett9,"This will be worse than a standard cpu. '

The Pi's are great for small workloads in seperate systems, but you're not going to get an increase in FLOPS due to communication time. 

These Pi clusters are useful for prototyping and testing working environments only, they will never scale the way you want them to.

If you *really* want to try it out just set up MPI on the pi's and use tensorflow's built in MPI libraries. ",1519153455.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/deeplearning] [Can anyone with tensorflow experience please help me with this??](https://www.reddit.com/r/deeplearning/comments/80jpsn/can_anyone_with_tensorflow_experience_please_help/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1519706985.0
Geeks_sid,"You got a big ass system to start Tensorflow on that, what are you trying to build? A mini space program? Anyway, make sure you are on Ubuntu and I would avoid the virtual machine and mini system work, instead keep one project at a time and get faster results. I have got a 16 gig and a p5000 and it takes 2 days to produce results. Best of luck, if any help, DM me",1519017481.0
szpaceSZ,"So, is the advice to wait for a build for the price of the components to revert to historically more same prices, or do you expect them to ~~stay high~~ remain elevated?


EDIT: We are not talking psychotropics. ",1519020768.0
khashei,"in your input placeholder use None for batch size calculate the batch size in your graph using tf.shape. this way you can pass anything to your model. like this:
tf.placeholder(tf.int32, shape=(None, time, features))
",1518892354.0
algaweek,Are all observations the same length during a episode?,1518769585.0
btyh17mxy,TensorFlow is like black magic to me...,1532402429.0
btyh17mxy,I found this https://stackoverflow.com/questions/49774035/how-to-classify-a-quickdraw-doodle-using-tensorflows-sketch-rnn-tutorial?rq=1,1532682510.0
kzgrey,"Keras is just a higher-level wrapper for Tensorflow that enables one-liners like the one you provided.  The actual Tensorflow APIs aren't all that difficult to perform the equivalent: https://www.tensorflow.org/programmers_guide/using_gpu

The harder part is getting the right GPU driver installed so that the GPUs share memory properly (this is my experience with AWS EC2 anyways).",1518664181.0
specialpatrol,"You never start a Session! Put;

    sess = tf.Session()

before calling any tf setup. You get a load of other errors after that but at least they concern what you're trying to do!",1518626442.0
Mabb_reddit,"You can try to play with the Tensorflow Object Detection API:
https://github.com/tensorflow/models/tree/master/research/object_detection

I hope this helps you!
",1518625197.0
algaweek,Hands-On Machine Learning with Scikit-Learn and TensorFlow,1518596919.0
jojek,How about the book by Aurelian Geron?,1518594456.0
BoltzmannMachine,Sorry to be “that guy” but can you define practical? ,1518589154.0
patopeking,Nope just a product they will abandon soon and leave you with no support.,1518390110.0
coffeesippingbastard,"these are basically just gaming PCs.

In fact I think this is just a rebranded ASUS laptop

https://www.newegg.com/Product/Product.aspx?Item=N82E16834234653

It even has the same orange stripe.

Their lambda quad is a corsair air chassis with 4x 1080s inside. 

I don't see anything that particularly separates them from something you could either build yourself or buy online. If these were shipping with Google TPUs built in it would be a different story.",1518392522.0
pythomad,colab.research.google.com,1518362085.0
k9thedog,Have you tried floydhub? it has a free tier and they can even host your model for you.,1518358537.0
JustinQueeber,"Firstly, you say that the labels are floats in the range [0,1] and that they represent the ratio of the number black to white pixels - if there are more black than white pixels, this ratio will be greater than 1. I presume you mean that each label represents the number of black (or white) pixels as a fraction of 1024, the total number of pixels.

Secondly, I don't understand exactly what your input data is. Does each array contain 1024 numbers which are strictly 0 or 1, where each represents that the pixel is either black (0) or white (1). Or does each array contain 1024 floats in the range [0,1]? If it is the latter, what do these numbers represent?",1518295805.0
Amphagory,"Here is a blog I made to build TF 1.5 and Cuda 9.1 on Linux from source: https://github.com/Michael-Yee/Build_Tensorflow-GPU

What OS are you install upon?

",1518145507.0
,[deleted],1518148146.0
doktorneergaard,"Maybe I am not understanding your problem correctly, but wouldn’t this be much easier to solve with more classical methods instead of LSTM? Or is it because you are using this as a warm-up exercise? Do you only have time as a feature or do you have more in your ‘real’ problem?

I should think it definitely doable to implement, but maybe a bit overshooting?",1518145826.0
MrAcurite,I'd be interested to look into collecting the training dataset,1518153416.0
danielg00,Tensorflow is only a library for developing machine learning algorithms. You could code it from scratch if you wanted. ,1518142643.0
toastjam,Make deepfakes via GAN and then you get both a generator and fake-detector at the same time...?,1520031514.0
k9thedog,"Is the 10~20% in time or GPU memory usage?

If it's time, maybe some CPU-heavy operations are taking long and are keeping the GPU waiting? Are you resizing images during training? Try training on already resized images. 

If it's GPU memory, try increasing batch size.",1518137982.0
ZodiacKiller20,"object_detection is not included in the default tensorflow installation. All the research models and experimental features are included in a different github - 

https://github.com/tensorflow/models

Clone this repo and you can find the Object detection folder within the research folder. 

 ",1518008616.0
LoveOfProfit,Can we stop with these threads?,1517924456.0
fuzzball_b,"Was having the same issue with this tutorial. 

https://youtu.be/srPndLNMMpk

The only solution i see is training a lot of diffferent items, so it also knows that there are other things it could be. This would be a lot of work though. Maybe this could be a joint effort, or maybe someone has access to the original trained model images and coordinate files",1518019704.0
fgutierr,"You can’t train in Java yet, if that’s what you meant. 

It’s possible to train with python and deploy the trained models with java. The API is straightforward https://www.tensorflow.org/api_docs/java/reference. 

There’s also an example available https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java",1517852832.0
goomba870,Could you please explain a bit of how you did this?,1517835205.0
hope2882,That's pretty cool! Any tutorial or resource you can link please?,1517898973.0
kontekisuto,Source code?,1517754996.0
aristizabal95,"This is so weird and creepy.... I love it.
Is there any link to a research paper to learn more about implementation?",1517713919.0
baka_vela,"Download tensorflow source and use the summarize_graph tool to find inputs, outputs and layers. 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/summarize_graph_main.cc",1517805077.0
chuiy,"That's awesome, are you the original uploader?

If so, how did you accomplish this?",1517684499.0
baDoxx,yes i am :) it took about 20 hours of computing to get results like that :),1517691227.0
mikaelhg,"If you're not able to reveal more about what you wish to accomplish, please take a look at these resources:

https://github.com/tensorflow/models/tree/master/research/object_detection

https://github.com/facebookresearch/Detectron

https://www.tensorflow.org/tutorials/image_retraining

Depending on your application, it's possible that you can augment your training set with synthetic images.",1517441150.0
numpad0,Essentially /r/ deepfakesSFW?,1517481298.0
ScienceLion,I hope this subreddit doesn't become a copy of deepfakes.,1517694929.0
algaweek,"Yes, unless you explicitly store your trained model using something like tf.train.Saver().",1517407957.0
codythecoder,"I've just found [this](https://www.tensorflow.org/versions/r0.12/how_tos/variable_scope/), so I'll read over it and report back once I'm done.",1517379863.0
Siennebjkfsn,"Is it really effective performance? I dont have the time to look through all your code but it seems that you are mapping f(t) to f(t+1) which may converge to the same graph but with one time-step translation between observed and predicted, consequently training an autoencoder.

Edit: You might want to try regularizing against learning an output that simply shifts the graph along the t-axis",1517372651.0
mikaelhg,"If you want to play around with depth cameras, but can't get a Kinect anymore, https://software.intel.com/en-us/realsense/d400 might be a good bet.",1517346393.0
jmf1sh,"Absolutely, _yes_. Tensorflow is exactly what its name says it is: a framework for building data flow graphs involving tensors (multidimensional arrays). Pretty much anything you can do in numpy you can do in tensorflow, and most (but not all) operations can be easily offloaded to GPU if you have the hardware available. Depending on exactly what you are doing, you could also check out PyTorch which is (by design) much closer to numpy in its API. The tensorflow low-level API definitely has a learning curve if you are not used to thinking about computation in terms of data flow graphs. But IMO it's worth learning, because for example it lets you compute analytic derivatives automatically. ",1517341763.0
PedanticPendant,"[We're through the looking glass here, people...](https://i.imgur.com/atG8biN.gif)",1517332585.0
baDoxx,a quite funny way to use that technology isnt it,1517301919.0
bosondediego,"I had the same problem, just leave it on jupyter notebook you can import it twice and problem finished",1517094008.0
bosondediego,Thanks for the input!,1517092284.0
cranq,"TF is good at finding correlations in data... How much training data do you have?  Also, just out of curiosity, how many dimensions are you going to have as inputs?",1517069239.0
bwllc,"There are too many similar package names in deep learning software, and the software is also changing very quickly.

When you say TFLearn, do you mean the [third-party package](http://tflearn.org/) which is meant to provide a scikit-learn API for TensorFlow?  Or, do you mean the almost-identical API that TensorFlow bundles in the [tf.contrib.learn namespace](https://www.tensorflow.org/api_guides/python/contrib.learn)?

I went down the TFLearn rabbit hole for a while. I ran into some problems almost two months ago.  I got some initial assistance on [the TFLearn GitHub page](https://github.com/tflearn/tflearn), and then silence.  I think that the TFLearn community is no longer large enough to sustain development and bug fixes.  I would love to be shown that is not the case, because I already know and like scikit-learn.  Also, the direct tf.estimator API was giving me a headache.

If you're not committed to the TFLearn way of doing things, try another API.  You can write straight TensorFlow.  I've succeeded in making everything I've tried work, except for the aforementioned tf.estimator.

You can also try Keras.  This is what I'm trying now.  I'm making some progress.  My model's behavior changed when I rewrote it in Keras.  I don't yet know whether that's my fault.  Also, like TFLearn, there seems to be multiple ways of accessing Keras: You can get the Keras package independently, or access the tf.keras namespace.

There's also a tf.contrib.keras namespace, which the TensorFlow docs say that they provide ""for backwards compatibility.""  That gives me an indirect warning about the TFLearn: ONLY the ""backwards compatibility"" namespace is offered, which makes me think that the TensorFlow team no longer considers TFLearn to be as important.

I know that this is not a direct answer to your questions.  But I'm trying to suggest to you that it's easy to choose software in this field for which, unfortunately, you won't get answers to your questions.",1517132303.0
jojek,"Try 
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'",1517351770.0
aotus_trivirgatus,"> what is with reduce_sum in my err calc? (or reduce_mean, or similiar). 

You have many training values in a batch.  If I'm reading your code correctly, your model has one output value per input.  You also have target values, which should have the same number of values as your output.

Your error calculation starts by taking the *element-wise* squared difference of the model's output and the target, so you'll get a vector.  The error value needs to be a scalar. For some models you might want to do something more complicated, but reduce_sum simply sums the individual errors, and reduce_mean divides by the number of terms.  I tend to use reduce_mean because then I can compare the error values across multiple runs no matter what size training set I'm using.

Now, you say:

>it just... implodes.

How does it implode?  You don't show any output.  

I will say one thing, I was taught that using a sigmoid activation function doesn't work well with values that are outside of a narrow range.  It is customary to have some kind of normalizing transform that scales your input to have a mean of roughly 0 and a standard deviation of about 1.  You should ""freeze"" this transform once you design it for a given training set.  If you are training on a uniform distribution of numbers 0-100, you could just multiply the inputs by about 0.035 (more precisely, sqrt(12) / 100), then subtract 1.75.

I was also taught that the ReLU activation function can handle unscaled data more easily.  I have built a few successful models around ReLU without scaling my data first.

Finally: are you sending 10,000 training values to the network on every single iteration?  Are you doing that 10,000 times?  And you're only checking your progress every 100 iterations, which means every 1,000,000 training values?  I know we need big data for these models, but this seems to be far too much.  Generate less data and monitor your results more often.",1517049052.0
,[deleted],1516975142.0
jayjaymz,"After spending almost an entire a month 2 years ago to setup everything regarding tensorflow, I'm ok with this hitting the front page of the internet.",1516884141.0
jojek,"When 1.5 is due to be released?
I can see that version number was already changed in the commit:
https://github.com/tensorflow/tensorflow/compare/v1.5.0-rc1...r1.5
",1516885296.0
marvpaul,I guess you have to convert to numeric input first.,1516694331.0
xd009642,"I'm pretty sure you'll need to parse the PDF in some way. If it's just text there's python libraries to get strings, if you want to work on the actual appearance of the PDF or it has images you can use something like https://github.com/Belval/pdf2image ",1516732250.0
0xdeadf001,"It all depends on what you want to accomplish. What are you expecting the ""features"" of a PDF to be? Are you looking for a text stream?  Rendered bitmaps (images) of pages?

If you're looking for a coherent text stream, then PDF is possibly one of the worst formats you can use. There is no guarantee of a correspondence between the order of characters (in the PDF file) and the visual order of those same characters in the rendered output. PDF is a technology for describing page layouts; chunks of the page (such as sequences of characters) can be ""drawn"" in any order.",1516753857.0
DelosBoard2052,"PDF often contains more formatting code than the text and images they display.  If you're wanting to use the human-readable info in a pdf, you'll have to do some heavy-duty translation and coding conversion.  Unless you plan to input hundreds of pdfs, you'd probably find it easier to hand transcribe!  Alternately, pdfs can be opened in photoshop, saved as jpg, and read by ocr software.  This process can be fully automated.",1516765196.0
,"As a foreign speaker I must say that unfortunately there are a damn lot of probably great videos that I have trouble understanding because the speaker is really hard to understand and to add to that audio quality is terrible too. I totally understand that not everyone can speak fluent and clear English, I probably don't either, but please... if you have a rather strong accent, please make sure that at least the audio quality is good enough to not make things worse. Thanks!",1516524924.0
labelbox,"Hi all,

We recently started open beta for Labelbox (https://www.labelbox.io/). You can simply connect your data, choose or customize an open source labeling interface, invite team members and start labeling. Our labeling interfaces are open source, meaning, that you can customize it to work with any kind of data such as images, videos, point clouds, medical DICOM and many more (as long as your data can be loaded in the browser). We'd love to hear your feedback and ideas to improve this further.

-- Labelbox team",1516495059.0
mikaelhg,"Cool, this has been missing. I assume the simple CRUD code is on GitHub?",1516551510.0
EXOQ,"Is this like a fancy UI for creating models in Tensorflow removing the coding aspect or is this itself a ML library?

Looks really neat tho! ",1516559732.0
mikko_i,"Just tried the demo and it works super smoothly! If I upload CSVs/data, will it be used by labelbox in some way/shape/form? How do you benefit from this?",1516561602.0
k9thedog,"Your question is very broad, it might be easier to to answer if you give us your point of reference. What's your experience with OpenCV and computer vision in general? ",1516177991.0
app_kumar,"Hi i actually made an android app (<12mb) with tensorflow cnn model to detect memes in phone and help clear them, it is amazing to see the results, i hope devlopers start taking full advantage of tensorflow image classification(cnn), this would have not been possible using openCV... at least accuracy wise.
btw check my app out at: https://play.google.com/store/apps/details?id=com.slitwire.memecleaner ",1516305000.0
,[deleted],1516111930.0
,[deleted],1516108194.0
pythomad,"Unlike keras, the model Is not an object you can`t save a single object and call it a model you have to save all tensorflow variables __Just the tensorflow ones__ and this can be done by:
    
    session=tf.InteractiveSession()
    saver=tf.train.Saver()
    saver.save(session,'model.ckpt')

and can be recovered using
    
    saver.restore(session,'model.ckpt')
",1515956418.0
IanShow15,"yes.
https://research.googleblog.com/2017/05/efficient-smart-reply-now-for-gmail.html",1515986189.0
theredknight,Shameless self promotion?,1516219954.0
Geeks_sid,"Sorry to offend anyone in any kind, I am just trying to reach people like me out there. Again , really sorry.",1516220025.0
AspiringGuru,"probably need to ask that question in the git issues.

My guess is never. Keras is a simplified interface to tensorflow. the backend can easily be swapped between the existing options in .keras/config, or a couple of python lines at start of your script.

[correct me if I'm wrong]",1515800841.0
caffeine_potent,There's always a sale on Udemy so don't assume that there is a rush. ,1515694750.0
gabi_dk,"Thanks a lot!! I will take it. I can give feedback if anybody is interested (but it will be in a while, I am still at the Getting Started of tensorflow)",1515694191.0
MrAcurite,"Just bought it. It seems to be only 20 hours of lectures, so I'll be done in a few* days once I get back to school. I'll make a post at the end describing it.

EDIT: ""fee"" to ""few""",1515703732.0
pilipolio,"https://www.tensorflow.org/serving is the official way to go, although I haven't used it yet, it should seamlessly let you train a model, serialize it and expose it through an API to score input examples. For a POC, a flask webserver holding a reference to a local TF graph can be an option. This blog post seems to cover pros and cons of both approaches https://guillaumegenthial.github.io/serving.html. ",1515666337.0
eleitl,Sockets?,1515660046.0
seankhliao,"    Step 1: train discriminator on real images
    Step 2: generate images with generator
    Step 3: train discriminator on fake images
    Step 4: lock discriminator weights
    Step 5: join generator and discriminator and train (label = real)

Repeat until you have satisfactory results",1515659404.0
Maleficus187,Why don’t you try asking for help instead of asking for someone to throw you a pity party?,1515644289.0
cappie,"""No, I will never give up. I will have to be dead or completely incapacitated."" -- Elon Musk",1516349057.0
,"My real question tho was if I needed any sort of knowledge or background with writing code or performing commands. When trying to install tensorflow was the first time I discovered the command prompt😬

I was hoping I could learn as I went but things weren’t looking great.",1515649754.0
OutOfApplesauce,If you can’t find or seek help to fix your problem then yes.,1515647049.0
aevyian,"I don’t know how to go about answering your question, because it is too vague. Would you please give an example of what you would like it to create?

My understanding is that you need a starting point and an end point for the machine to learn. If you question is to give it a starting condition and have it simply create arbitrarily, then no. There has to be some guidance, and a well-stated request. ",1515643776.0
Arisngr,"A lot of machine learning is indeed about classification, broadly called ""discriminatory"". However, a large and increasingly researched group of ""generative"" networks exist. A popular example [are Generative Adversarial Networks](https://www.analyticsvidhya.com/blog/2017/06/introductory-generative-adversarial-networks-gans/), that generate e.g. images that are meant to fool a classifier into thinking they're real. Another interesting architecture for generation are Variational Autoencoders. 

",1515644453.0
Jreddd1,"https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0

This is a real great Tensorflow tutorial. It shows them the power of deep learning in just about an hour. 

The programming side is somewhat easy. I am a mechanical engineer with beginner programming knowledge and I figured it out. 

",1515634512.0
seankhliao,tf.concat ?,1515604971.0
andyspl,"Do you not have a supervisor for this project? Because the folks on here are definitely a good resource, but probably shouldn't be your first go-to for an academic project like this.",1515437071.0
_JayJohn,"Hi,
I would like to classify mushrooms based on their features.
However, neither Tensorflow nor Sci-kit learn use csv. (Not that I know of)
How do I import the data into any one of these libraries and train on it?

>Assuming the data is split up into 5 columns (including Y ), and 1000 rows...

* What values do I use for x and Y? 
* Which type of neural network would work best for this type of data and why?
* How do i assess dropout and overfitting? (Remember, the dataset has many more rows and columns that we have assumed here)



Dataset can be found at https://www.kaggle.com/uciml/mushroom-classification/downloads/mushroom-classification.zip
",1515340416.0
_JayJohn,"Hi,
I would like to classify mushrooms based on their features.
However, neither Tensorflow nor Sci-kit learn use csv. (Not that I know of)
How do I import the data into any one of these libraries and train on it?

>Assuming the data is split up into 5 columns (including Y ), and 1000 rows...

* What values do I use for x and Y? 
* Which type of neural network would work best for this type of data and why?
* How do i assess dropout and overfitting? (Remember, the dataset has many more rows and columns that we have assumed here)


",1515340070.0
grubberlang,"This belongs in one of the ""learn ML"" subreddits. A title in actual English wouldn't hurt either! ",1515314502.0
Altourus,You might need to use something [along these lines](https://facebook.github.io/react-native/docs/native-modules-ios.html),1515188670.0
baka_vela,Write your TF code in C++ -> wrap the functions you want to use in Java/Objective C -> call these through react native. ,1515369836.0
gianpaj,https://github.com/reneweb/react-native-tensorflow works for me,1527356164.0
sputknick,"I can't help, but I'd love to hear your reasons for switching.",1515128200.0
seankhliao,Feed [[x]] instead of [x],1515068510.0
_JayJohn,"Here's what i think are the problems with your code:

* line 14 is not required. Since you are predicting the value of x in 'y', you do not need to explicitly declare y a placeholder

* line 15: change :
>y = product + b 
 
to 

>y = tf.nn.softmax(product + b)
(This is because you need an activation function to compute the node.)

* line 19: change:

>cost = tf.reduce_mean(tf.square(y_-y))

to

>cost = -tf.reduce_sum(tf.log(y) * y_)

the minus is there to ensure that cost returns a positive output

* line 22: your learning rate for the GradientDescentOptimizer is too high, set it to something like 0.003 or the model will take too long to learn and will require additional amount of data

*  line 25: use tf.global_variables_initializer instead

And as for your main issue, you will have to use tf.reshape to reshape the y_prediction matrix size",1515339004.0
numpad0,"If tensorflow**-gpu** works and uses CUDA/cuDNN, I see no problem.  

If only **tensorflow**(without “-gpu”) is available then might as well do it on a phone because DNN on CPU is a genuine crawl.  

If tensorflow-gpu works but it’s resorting to CPU or OpenCL^(1), then I’d be pissed for the same reason.  

If your box is meant to be run headless, also make sure the GPU is ventilated properly, as NVIDIA driver is known to neglect fan control when X is not running on the card.   

^(1) last time I checked the latter isn’t implemented yet though  ",1515032945.0
crosstechguy,"Yes, all variables initializors will be run, overriding the previous values.
You can run tf.initialize_variables with a list of the new variables instead",1514894205.0
Maleficus187,I’m not totally sure. Is there a reason you can’t initialize all of the variables at the start? Do the second set of variables depend on the first set somehow? Could you initialize the second set on a separate graph with a separate tf.Session() object by returning the first variables with sess.run and then use them to define the seconds graph?,1514876633.0
,Are you running a virtual environment by any chance? Also wondering why you used homebrew and not [pip](https://www.tensorflow.org/install/install_mac)?,1514740103.0
sunbeamclouds,"ran into this problem briefly.

i've found the best solution for me is:

download atom, download scripts (this will allow you to run python from atom). then in bash or w/e locate the tensorflow library then source ./bin/activate, then cd into your repository where you will start your work and type ""atom ."" which will open up an atom session from your directory. as you've activated atom with bash you'll be able to run programs that are from your path. ",1514781803.0
RSchaeffer,Maybe you're just reading the wrong repos? I had to read [this repo](https://github.com/deepmind/dnc) and the comments seem fine to me.,1514657065.0
amebaspugnosa,"I have same mixed feelings of OP about Tensorflow documentation in general. While the low level API are pretty stable, high level API has changed along latest releases.

To me was very hard to find the proper way to do easy things (e.g. monitor validation loss during training using tf.learn) and led me to sail towards a more documented framework like Keras.

Of course YMMV.",1514664242.0
muntoo,"I thought it was good practice to write good code which did not need to be commented.

Though, in the case of domain-specific *examples*, comments wouldn't hurt.",1514618784.0
amebaspugnosa,"The cleanest path is:

* export the model in Protobuffer and define its interface https://www.tensorflow.org/serving/serving_basic#train_and_export_tensorflow_model
* launch a local Tensorflow-Serving server which will expose your model via gRPC protocol https://www.tensorflow.org/serving/
* using gRPC tools, generate a Java stub that is able to communicate with the Tensorflow-Serving backend https://grpc.io/
* once in production, ensure to lock down the gRPC interface to avoid to be called outside the localhost

Once in place, it works. But good luck, there are just a few tutorials (I did that for Python webapp).",1514666529.0
kzgrey,"I’m in bumblefuck Peru with limited internet access so I can’t verify it but this error sounds familiar in context of the mnist data and some example tensorflow code.  I think your M or N dimension needs to be +1.  I forget why.

I was thinking about writing a tensorflow example app that’ll approximate a well know function.  For example: estimate the date of Easter given the Year and phase of the moon and DOW on January 1st.",1514594795.0
spline_reticulator,Can you post your code and the actual error you're getting? Use pastebin.,1514999248.0
,[deleted],1515165743.0
pie_oh_my_,"You should look into maxout activation. 

tf.nn.maxout

You can do any multiple really 

Mobile is making it a link, it’s not a link just what to look up in the API",1514609065.0
seankhliao,"> normalizer_fn: If not None, a function that can be used to normalize the value of the tensor after default_value is applied for parsing. Normalizer function takes the input Tensor as its argument, and returns the output Tensor. (e.g. lambda x: (x - 3.0) / 4.2). Please note that even though the most common use case of this function is normalization, it can be used for any kind of Tensorflow transformations.


So basically any function with one input and one output, example mean shifting:

    lambda x: tf.subtract(x, tf.reduce_mean(x))
",1514560521.0
,this is too high level for you... sorry ,1514576772.0
Maleficus187,"Nope, pretty easy to do on a GPU. The only thing I can think of is you probably won’t have as much RAM on your GPU as your system RAM, so depending on your batch size, image size, etc. you may have to tweak things to fit on the GPU.

Otherwise, you’ll be able to play around with which ops go on CPU vs GPU. Generally any preprocessing ops are best put on the CPU and the training and inference on the GPU. I always put pretty much every thing on the GPU, but my preprocessing is a bit different as I’m a chemist and not doing things quite like most comp sci are.",1514515664.0
Maleficus187,"No. The problem with that is you have to copy memory back and forth between system and GPU too much, and the memcpy would be incredibly slow. I’m not sure CUDA can handle something to that affect anyway. 

Frankly 6 GB RAM is quite a bit anyway. I have the same GPU in my laptop, and I train 3 fully connected hidden layers with 512 neurons each, input vector size of 700 per training case, with minibatch sizes of 400 all in single precision, and typically at least two loss functions (the gradients for each loss are what makes it real expensive memory-wise, so two is much worse). The real problem for me is the preprocessing can get very expensive in terms of memory, but like I said my preprocessing is very different since I’m a chemist.",1514528307.0
Amphagory,"The following is a good article on GPUs and machine learning:  http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/.  I am unsure of your budget, but it might be cheaper to find a used 980ti. 

As for things to watch out, be careful with the version of CUDA you use with TF.  I think version TF1.4 can use the latest version of CUDA, but TF1.3 can not.  

One thing people forget is the feature engineer stuff mostly happens on the CPU and depending on your dataset, might need a lot of RAM.",1514563742.0
alluriharikishan,Tensorflow on GPU in insanely fast. The more CUDA cores higher the insanity is. I bought a titan xp recently. It took 10 min for it to train a deep CNN with 3CNN layers and 3FC layers. It used to take couple hours on Ryzen 1700X cpu. ,1514572440.0
,It will work just fine. One warning though: if you're doing it because you expect a speedup you might be disappointed. I bought a 1060 hoping for a speed increase over my 780. I got about a 10% speed increase only.,1514611749.0
aremdonuts,"Out of curiousity, were you able to make it work? I bought a 1060 6GB as well, but installing tensorflow-gpu always breaks on my Ubuntu 16.04 machine.",1514987884.0
aremdonuts,It worked! ,1515542747.0
doodle911,"Have a look at a YouTube channel named sentdex, it may help you :)

https://www.youtube.com/playlist?list=PLQVvvaa0QuDcNK5GeCQnxYnSSaar2tpku",1514507723.0
GreekGodSly,"He also uses Ubuntu for custom objects , thank you tho ;)",1514509492.0
Mabb_reddit,"The most naive solution could be:

1- Multiply all the elements in B

2- The result of 1(a scalar) multiplied to A

The code can be something like this

matrixB_prod = tf.reduce_prod(matrixB)

Output = A*matrixB_prod",1514549991.0
crosstechguy,"Tensorflow does not support .NET right now. It does support  c++, so maybe it is possible to link with it's c++ api, however the easiest way will probably run the model on another process and expose an API for the asp.net code to use.",1514486759.0
seankhliao,"Mine works fine, passing in ([batch, None, 64], [batch, 1])

I'm using a function not a lambda and I don't quite remember why I return 2 elements even though I only need one (might have been something with the shapes?)",1514403391.0
o-rka,I would just remove it and use the data only.  TensorFlow is for numerical computations so the labels can be added later. ,1514337317.0
,javascript ,1514576782.0
seankhliao,"multiclass classification, easiest way is a binary classification loss per label, eg. with [sigmoid cross entropy](https://www.tensorflow.org/api_docs/python/tf/losses/sigmoid_cross_entropy)",1514442510.0
Maleficus187,There is an uninstall script inside of the cuda directory. Alternatively you could compile tensorflow from source and keep 9.1. It’s not very difficult.,1514320810.0
Supermaxman1,"The only reason from the sample you provided is if you actually want access to that temp\_cost result of the sess.run. You are correct in that you do not need to specify the cost if you do not want the value returned in the tuple of sess.run. When you call sess.run you will run the tensorflow graph and the function will return a tuple of the value of the variables or ops you specified in the list input. The optimizer returns nothing, and so the first tuple value is \_, while the cost returns as the second tuple value in temp\_cost. You can ask for any value in the tensorflow graph anywhere along the way if you want to get the value of an intermediate layer output. Just add that op or variable to the input list to sess.run. 

If you do not want the value of cost returned and stored in temp\_cost then you can remove cost from the input list.

TLDR: Your intuition is correct. Only put ops or variables in the input list if you want to run them and/or get their value.",1514251895.0
seankhliao,"Note the capitalization on your `Conv1D`, capitals = class/object, lowercase = function

You probably want `tf.layers.conv1d`",1514172560.0
pie_oh_my_,"Had that problem. 

First I would recommend running mnist_deep.py on your computer. It should be located in the tensorflow directory. Tensorflow/tensorflow/examples/tutorials/mnist/......

Try restarting your Jupyter notebook and trying again.

If that doesn’t work; try a forward pass with one image and see if it crashes. 

It could just be too computationally expensive for your computer. Seems unlikely. 

And if all else fails, get $300 for signing up for GCE and run your code there. And see if that fixes it ",1514172162.0
Altourus,"Am I missing something, I thought conv2d and max_pooling2d only take lists of 2 values. I believe it skips the batch and channel dimensions.",1514218152.0
Altourus,Is it possible the type of your input is different in 2 vs 3? Like instead of a float32 it's being cast as an int32? Or a similar type cast issue in your graph?,1513917258.0
Maleficus187,Not really enough info here to help. Is your code on github? If you share it others can look over it for places that could cause the discrepancy.,1513917332.0
kleer001,How many times have you run your models? ,1513918305.0
BeatLeJuce,"Add the following import to the beginning of your file, and see if the results are still different:

    from __future__ import division",1513946257.0
mario-the-champion,"in case someone googles this later, i just spent 5 or 6 hours twiddling different versions of stdout / stdin / communicate() in
    subprocess.Popen()

finally to discover a google groups post noting that tensorflow's logging function
    tf.logging.info()

prints to **stderr** not stdout, and so the ability to capture it as a simple as three character change to:


    training_results = Popen(cmds,shell=False,stderr=PIPE,bufsize=1,executable=""python"")
    for line in iter(training_results.stderr.readline, b''):
      print line
      if line.startswith(""INFO:tensorflow:Final test accuracy""):
        tf_final_acc = line
    training_results.wait() # wait for the subprocess to exit

and then using the tf_final_acc as needed.

hope this helps someone! ",1517589330.0
seankhliao,"From your stack overflow question, I see you've used Batch Norm, so it is probably this:

> Note: when training, the moving_mean and moving_variance need to be updated. By default the update ops are placed in tf.GraphKeys.UPDATE_OPS, so they need to be added as a dependency to the train_op. For example:

    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
        train_op = optimizer.minimize(loss)",1513817604.0
Altourus,"From what I understand, but may be incorrect.

Contrib is prior to the implementation being adopted as part of the core tensorflow library. Usually developed by a third party that is contributing to the library.

Layer will handle all the specific details of implementation (such as setting up an variables and applying activation functions where appropriate)

nn will require more fine tuning on your own, but will give you more access to the underlying calculations, allowing you to do more complex interactions.",1513724204.0
TotesMessenger,"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/learnmachinelearning] [Which Tensorflow batch normalization implementation to use?](https://www.reddit.com/r/learnmachinelearning/comments/7kvcci/which_tensorflow_batch_normalization/)

&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*",1513709822.0
seankhliao,looking at the source for [tf.layers.batch_normalization](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/layers/normalization.py#L459) and [tf.contrib.layers.batch_norm](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/contrib/layers/python/layers/layers.py#L821) they both use `tf.nn.batch_normalization` under the hood,1513772350.0
dave992,"Recently had the same question as I tried using the layer in a DDPG network. The `tf.nn` version is the most simplistic implementation. It really only does the normalization, somewhat in the sense of: `scale*(input - mean)/sqrt(variance)`. You need to provide all inputs yourself. If you use `tf.layers` you do not have to keep track of most of these variables. It keeps track of the mean and variance using a exponential moving average as recommended in the paper that introduced the batch norm method. Finally, the`tf.contrib`version somewhat a pre-release version. It is still developed, sometimes by a other party. This can mean the API can rapidly change between TensorFlow versions. At the moment it looks very similar to `tf.layers`.

I would recommend using the `tf.layers` version, as it provides an easy and reliable way to implement the batch norm layer. Do keep in mind you have to provide a boolean to indicate to the layer if it is training or not! ",1513858202.0
elslooo,"I think it’s just MSE, with both sides multiplied by nf. What you get is $$(nf * a - nf * b)^2$$. You can rewrite that as $$(nf * (a - b))^2$$, and subsequently $$nf^2 * (a - b)^2$$.  It divides your loss by $$1^-2$$. This acts like a ‘learning rate’ but you should adjust the real learning rate (first parameter given to the optimizer) instead of adding this multiplier. I think if you divide your current learning rate by 100, you won’t need the multiplier anymore.",1513638483.0
mdepristo,"You can look at the encoder function itself right here: https://github.com/google/deepvariant/blob/r0.4/deepvariant/pileup_image_native.cc#L174

There's no one-hotting; the entire tensor (width x height x 7 data channels) is rescaled using standard image processing steps (exact code here: https://github.com/google/deepvariant/blob/r0.4/deepvariant/modeling.py#L265).

We do not know the best encoding for any data channel; it's an open research question if an alternative representation or preprocessing steps would improve the accuracy. There was a significant boost in accuracy moving from the 3-channel representation in the 2016 version of DeepVariant (described in the preprint) to the 7-channel version (implemented in the code in GitHub).",1513632766.0
chiraqe,Training should continue.,1513626076.0
ppwwyyxx,It depends on how you write your distributed code. Tensorflow is flexible enough to implement different behaviors.,1513660569.0
jpdowlin,"If you lose the chief worker, you have to restart from your latest checkpoint (you are writing periodic checkpoints, i hope?).",1513855529.0
tgaz,"This is just FUD. Even a Google Translate-version (yeah, ok, some irony there) of the linked source contains no discussion of what any actual hole is.",1513588503.0
Altourus,"My profile picture is set by my organizations Azure Active Directory, maybe something similar is happening for you?",1513548349.0
seankhliao,"the 5th paragraph says:
> Make sure that your hard disk has at least 500 GB of free space for downloading and storing the data.",1513530575.0
seankhliao,"Copy the mnist input bit in main.py

Change the first 2 lines to your own way of reading the data

Change the next 2 to use tf.train.batch

Change the last 2 lines to fit your data",1513387696.0
seabass,"Hi Friend - 

Here is as good a place as any.  The message volume is low enough that your questions have a high chance of getting answered.

In case you were looking for other places TF people hang out and ask/answer questions, here are some of the ones that I've found:

* https://github.com/tensorflow/tensorflow/issues
* https://www.reddit.com/r/tensorflow/  [here]
* https://stackoverflow.com/questions/tagged/tensorflow
* https://datascience.stackexchange.com/questions/tagged/tensorflow
* https://gitter.im/tensorflow/
* https://medium.com/tag/tensorflow/latest
* https://www.reddit.com/r/MachineLearning/search?q=tensorflow&sort=new&restrict_sr=on
* https://www.reddit.com/r/learnmachinelearning/search?q=tensorflow&sort=new&restrict_sr=on&t=all
* https://tensorflowtalk.slack.com
* https://hn.algolia.com/?query=tensorflow&sort=byDate&prefix=false&page=0&dateRange=all&type=all

PyTorch has a discuss forum https://discuss.pytorch.org that TensorFlow might take up someday, but for now, we can only hope :)",1513343949.0
txrxfx,Following ,1513340253.0
countasone,I seem to remember having seen this issue. It's been caused by an incorrect cudnn and/or toolkit. Like updating tensorflow without matching the dependencies. ,1513323291.0
AlaskanWilson,"I would recommend using Rodeo from yhat, it’s basically Rstudio for Python. I was having problems with Pycharm and Anaconda Spyder as well but had success with Rodeo (although Jupyter Notebooks on Anaconda did work too).",1513618032.0
oopsleon,"Try launching PyCharm via the command-line (`charm`). That allows me to, for example, run the PyCharm debugger when tensorflow programs are being used. Otherwise, I get that same `_pywrap_tensorflow_internal` error as you. Might be related.",1514263705.0
Fhy40,Hey did you ever figure out the problem that caused it to not work?,1518492105.0
wild_thunder,"A few things:

* If your softmax outputs don't sum to one you have a bug. 
* 80% accuracy isn't terrible if you have 100 labels. If randomly guessing, you'd expect only 1% accuracy. This is a pretty simple network so don't beat yourself up if you don't get state of the art accuracy out of it.
* You could try dividing your input pixels by 255 to change your input values back to the [0, 1] domain. I'd recommend this since it should help avoid numerical precision issues with your trained weight vector.",1513225292.0
seabass,"Hi Friends- so I made this video tutorial because I ran into this issue a couple of days ago and just couldn't figure it out.  Because TensorFlow does global variable initialization in a non-deterministic way sometimes the program would work just fine.  Otherwise, the thing would fall over and have errors all over the place.  I couldn't figure it out.  Finally after looking through some GitHub issues, I realized that I was defining some variables that were using other variables.  So when I ran
```
sess.run(tf.global_variables_initializer())
```
every so often it would try to initialize some variables that depended on other variables already being initialized.",1513198267.0
oopsleon,"Just an FYI: TensorFlow's Variables Programmer's Guide mentions usage of `myvar.initialized_value()` for this use case [here in Initializing Variables](https://www.tensorflow.org/programmers_guide/variables#initializing_variables)

Their example: 

`v = tf.get_variable(""v"", shape=(), initializer=tf.zeros_initializer())`
`w = tf.get_variable(""w"", initializer=v.initialized_value() + 1)`
",1514263863.0
Mabb_reddit,"In order to collect from a queue, slice_input_producer is a queue, you need to start the coordinators and the queue.

https://www.tensorflow.org/versions/r0.12/api_docs/python/train/coordinator_and_queuerunner

Code:

    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    while Training:
        sess.run(train_op)

    #When training finished
    # Stop the threads
    coord.request_stop()

    # Wait for threads to stop
    coord.join(threads)

",1513241989.0
goomba870,"I may have done something similar just today. I had my array of `x_values` and an array of `y_values` that were huge, yet I wanted random smaller samples. The tricky part was keeping the random x and y values aligned with each other.

[This post](https://play.pixelblaster.ro/blog/2017/01/20/how-to-shuffle-two-arrays-to-the-same-order/) brought me to the solution.

> It takes advantage of the fact that numpy arrays can be indexed with other arrays

So if you shuffle an ordered array of indices, then slice it to the length you want, you can use that to pluck values at specific places from 1 or more arrays.

Hope that helps.",1513217645.0
alekhka,"TensorFlow isn't an OCR tool. It's a Python *library* which helps you *code* NNs. You can train NN to recognise text in images yes, but you will need large amount of data and good amount of knowledge to design, train and evaluate the model. You can probably get scripts off GitHub and be done with it too.

On the other hand, you can use trained models in tesseract or openCV and make your life simple. You'll get better results as they are carefully trained by experts.

Seeing your image gives me chills in my spine. It is of such low quality!(or am I seeing it wrong?) I can't even make out if it is a text or not! I don't think tesseract or opencv stand a chance. :(",1513112580.0
szpaceSZ,"I'm not an expert either, but maybe openCV could be an alternative? ",1513092529.0
Brudaks,"Perhaps Tesseract open source OCR tools can somehow be leveraged for this?
",1513103632.0
marvpaul,"Looks hard to analyze, even for me it’s impossible to read. Would be awesome if a machine would get it, but I‘m not sure about. 
Perhaps you have to do some preprocessing like sharpening before processing the image with an OCR tool.",1513114697.0
alekhka,"TF doesn't compute convolutions at all. What it calculates is cross correlation which is not a problem as the kernel is learned in CNN and all the values are real.

I am not really sure how TF implements cross corr, it probably leaves the computation to the BLAS library.

Hope it helps.",1513160500.0
TenuousStoneRake,Follow the directions here: https://www.tensorflow.org/install/install_sources,1513007836.0
seankhliao,"Keras:

Embedding -> RNN -> Dense

Search for RNN classification",1512912658.0
Mabb_reddit,"There is an issue open; https://github.com/jmiller656/EDSR-Tensorflow/issues/17. It's from 15 days ago and no answer.

It seams is not problem of your installation. 
It's of a code implementation problem. You can try to search the error in the code.",1513007364.0
GeForceKawaiiyo,"Well, I just changed to firefox and it worked... I have no idea why...",1512734475.0
Mabb_reddit,"Hi, you are using wrong the function, tf.estimator.Estimator(). If you look to the tensorflow page: https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator.

The initializer take 1 obligatory argument the model_fn, and 3 additional arguments, as you don't specify that the variable model_params is a params argument It detects as a model_dir. and when tries to load the model detects that a dictionary is not a acceptable path.

The correct call should be:

model = tf.estimator.Estimator(model_fn, params=model_params)",1512654129.0
TenuousStoneRake,"It sounds like you have two solid heuristics, at least, for why jobs should run long, why not use those? You certainly could use tf for a problem like this but I don't see why simpler options wouldn't suffice.",1512417608.0
fuckme,"So first. 
I’d try to frame the problem without a framework. 
For example 
Given times of sub jobs and amount of data can I predict the time based on the size of Data., potentially also using the times of completed predecessors as well. 

Now once you do this, you can look at what kind of algorithms/models would work best for these. 
My guess would be regression or ltsm would be a good first start as others have suggested. 

Then with that in mind, would tensorflow be good, as opposed to other tools like R or keras ? 
Would regular stats/machine learning approaches work or is deep learning a better approach ???

Personally if you don’t have billions of lines I’d look at R. 
It has tons of things which are good for exploration. 

Once you’ve figured out the algorithm and have a good enough accuracy then you could look at productionilizing it would be then when you look at tensorflow. 

Saying that tf is pretty cool once you get the hang of it, but it’s a lower level language imho than keras or R. ",1512489636.0
seankhliao,What are you doing to not make this easy?,1512434208.0
baka_vela,"You can use a lambda layer to wrap tensorflow vanilla methods. Some time ago I succesfully used this to call tf dropout rather than keras dropout. 

https://keras.io/layers/core/#lambda

",1512538216.0
MWatson,"The Keras documentation has a good description for writing custom layers.

Things to try:

I assume you have a test program that uses your customer layer. Copy the the test program and switch the copy to not use your custom layer and make sure that works. Company running summary() on your layer and a standard layer. ",1512350130.0
seankhliao,"Not familiar with TFLearn

contrib is experimental (and third party), may get changed/updated/removed between versions, when stable, it is moved to its own space with tf, example:
r1.3 had tf.contrib.data, r1.4 has both tf.contrib.data and tf.data

As for estimators, tf.estimator works",1512221449.0
o-rka,I've been using tf.keras and In really into it .  I can prototype stuff so quickly now.  There is also a fit and predict method like scikitkearn. ,1512233850.0
bwllc,"Thanks for your replies, seankhiao and o-rka.

Actually I decided against using Keras.  If I'm going to abandon scikit-learn, as it appears that I must, I might as well work directly with TensorFlow's own estimator.

And here's one more bit of information:

""Note: TensorFlow also includes a deprecated Estimator class at tf.contrib.learn.Estimator, which you should not use.""

https://www.tensorflow.org/programmers_guide/estimators
",1512293008.0
seankhliao,set `tf.Variable(validate_shape=False)` ?,1512149799.0
